npm warn Unknown user config "always-auth". This will stop working in the next major version of npm.

> test-app@0.0.0 test:e2e
> playwright test --config=tests/playwright.config.mjs

[dotenv@17.2.3] injecting env (4) from ../.env -- tip: âœ… audit secrets and track compliance: https://dotenvx.com/ops
Playwright baseURL: http://localhost:5173
PW_ENABLE_AUDIO: false
[1A[2K[WebServer] npm warn Unknown env config "always-auth". This will stop working in the next major version of npm.

[1A[2K[WebServer] npm warn Unknown user config "always-auth". This will stop working in the next major version of npm.

[1A[2K[WebServer] 
[WebServer] > test-app@0.0.0 test:proxy:server
[WebServer] > node scripts/mock-proxy-server.js
[WebServer] 

[1A[2K[WebServer] ğŸš€ Mock Backend Proxy Server starting...

[1A[2K[WebServer]    Proxy endpoint: ws://localhost:8080/deepgram-proxy
[WebServer]    Deepgram endpoint: wss://agent.deepgram.com/v1/agent/converse
[WebServer]    API Key: bc0b50fb92...

[1A[2K[WebServer] âœ… Mock Backend Proxy Server running on port 8080

[1A[2K[WebServer]    WebSocket endpoint: ws://localhost:8080/deepgram-proxy
[WebServer] 
[WebServer]    To use in test-app, set:
[WebServer]    VITE_PROXY_ENDPOINT=ws://localhost:8080/deepgram-proxy
[WebServer] 
[WebServer]    Press Ctrl+C to stop
[WebServer] 


Running 178 tests using 5 workers

[1A[2K[1/178] [chromium] â€º tests/e2e/audio-interruption-timing.spec.js:40:8 â€º Audio Interruption Timing â€º should interrupt audio within 50ms when interruptAgent() is called
[1A[2K[2/178] [chromium] â€º tests/e2e/audio-interruption-timing.spec.js:103:8 â€º Audio Interruption Timing â€º should handle rapid interrupt clicks without errors
[1A[2K[3/178] [chromium] â€º tests/e2e/audio-interruption-timing.spec.js:129:3 â€º Audio Interruption Timing â€º should respond to button click and change state (basic functionality)
[1A[2K[4/178] [chromium] â€º tests/e2e/audio-interruption-timing.spec.js:204:3 â€º Audio Interruption Timing â€º should persist mute state and prevent future audio
[1A[2K[5/178] [chromium] â€º tests/e2e/audio-interruption-timing.spec.js:271:3 â€º Audio Interruption Timing â€º should persist audio blocking across agent response turns (Issue #223)
[1A[2K[6/178] [chromium] â€º tests/e2e/audio-interruption-timing.spec.js:398:3 â€º Audio Interruption Timing â€º should interrupt and allow audio repeatedly
[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: âš™ï¸  suppress all logs with { quiet: true }

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:57904) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: âš™ï¸  load multiple .env files with { path: ['.env.local', '.env'] }

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:57908) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: ğŸ—‚ï¸ backup and recover secrets: https://dotenvx.com/ops

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:57905) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[7/178] [chromium] â€º tests/e2e/backend-proxy-authentication.spec.js:26:3 â€º Backend Proxy Authentication â€º should include auth token in proxy connection when provided
[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: ğŸ› ï¸  run anywhere with `dotenvx run -- yourcommand`

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: ğŸ› ï¸  run anywhere with `dotenvx run -- yourcommand`

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2K(node:57907) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:57906) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[8/178] [chromium] â€º tests/e2e/backend-proxy-mode.spec.js:35:3 â€º Backend Proxy Mode â€º should connect through proxy endpoint when proxyEndpoint prop is provided
[1A[2K[9/178] [chromium] â€º tests/e2e/api-key-validation.spec.js:16:5 â€º API Key Validation â€º should show error when API key is missing
[1A[2K[10/178] [chromium] â€º tests/e2e/agent-state-transitions.spec.js:45:3 â€º Agent State Transitions â€º should transition: idle â†’ speaking â†’ idle (user types message and clicks send)
[1A[2K[11/178] [chromium] â€º tests/e2e/agent-options-resend-issue311.spec.js:50:3 â€º Agent Options Re-send Test - Issue #311 â€º should re-send Settings when agentOptions changes after connection (Issue #311)
[1A[2K[chromium] â€º tests/e2e/agent-options-resend-issue311.spec.js:50:3 â€º Agent Options Re-send Test - Issue #311 â€º should re-send Settings when agentOptions changes after connection (Issue #311)
ğŸ§ª Testing agentOptions re-send scenario (Issue #311)...

[1A[2Kâ³ Waiting for initial connection and Settings...

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] ğŸ”§ [Component] Proceeding with initialization {isFirstMount: true, needsInitialization: true, isReady: false, transcriptionOptionsChanged: true, agentOptionsChanged: true}

[1A[2K[BROWSER] ğŸ”§ [Component] DeepgramVoiceInteraction initialized {services: agent, mountId: 1767045876958-0.6448099181810149, isStrictModeReInvoke: false}

[1A[2K[BROWSER] ğŸ”§ [INIT] Service configuration details: {transcriptionOptions: undefined, agentOptions: Object, isTranscriptionConfigured: false, isAgentConfigured: true, apiKeyPresent: false}

[1A[2K[WebServer] [Proxy] New client connection from ::1

[1A[2K[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: undefined, isFirstRender: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] First render - skipping change detection

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”§ [AGENT] Creating agent manager lazily

[1A[2K[BROWSER] ğŸ”§ [AGENT] Creating WebSocketManager with URL: ws://localhost:8080/deepgram-proxy

[1A[2K[BROWSER] ğŸ”§ [AGENT] Connection mode: proxy

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []

[1A[2K[BROWSER] ğŸ”§ [AGENT] Proxy endpoint: ws://localhost:8080/deepgram-proxy

[1A[2K[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2K[BROWSER] ğŸ”§ [AGENT] API key present: false

[1A[2K[BROWSER] ğŸ”§ [AGENT] Auth token present: false

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connecting Previous: undefined

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent state: connecting

[1A[2K[BROWSER] ğŸ”§ [Component] useEffect cleanup running {mountId: 1767045876958-0.6448099181810149, transcriptionManagerExists: false, agentManagerExists: true, isMounted: true}

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup stack trace:     at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17482:13)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListUnmount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8500:117)
    at commitHookPassiveUnmountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8519:60)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045876958-0.6448099181810149}

[1A[2K[BROWSER] ğŸ”§ [Component] Proceeding with initialization {isFirstMount: true, needsInitialization: true, isReady: false, transcriptionOptionsChanged: true, agentOptionsChanged: true}

[1A[2K[BROWSER] ğŸ”§ [Component] DeepgramVoiceInteraction initialized {services: agent, mountId: 1767045876961-0.30042724120186826, isStrictModeReInvoke: true}

[1A[2K[BROWSER] ğŸ”§ [INIT] Service configuration details: {transcriptionOptions: undefined, agentOptions: Object, isTranscriptionConfigured: false, isAgentConfigured: true, apiKeyPresent: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connecting, isConnected: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true}

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connecting Previous: connecting

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state unchanged, skipping: connecting

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connected Previous: connecting

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent state: connected

[1A[2K[BROWSER] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[BROWSER] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K[BROWSER] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K[WebServer] [Proxy] New client connection from ::1

[1A[2K[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent
[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []

[1A[2K[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connected Previous: connected

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state unchanged, skipping: connected

[1A[2K[BROWSER] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K[BROWSER] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K[BROWSER] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K[BROWSER] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Called

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions: undefined

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!
[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message
[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 0

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Settings message sent, waiting for SettingsApplied confirmation

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Flags set immediately after successful send (StrictMode protection)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[BROWSER] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K[BROWSER] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Called

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions: undefined

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 0

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Settings already sent (via ref or global), skipping

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] globalSettingsSent: true

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup detected StrictMode re-invocation - preserving connections and state

[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[chromium] â€º tests/e2e/agent-state-transitions.spec.js:45:3 â€º Agent State Transitions â€º should transition: idle â†’ speaking â†’ idle (user types message and clicks send)
âœ… TTS is already unmuted

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SettingsApplied message

[1A[2K[WebServer] [Proxy] âœ… SettingsApplied received from Deepgram, forwarding to client

[1A[2K[chromium] â€º tests/e2e/agent-options-resend-issue311.spec.js:50:3 â€º Agent Options Re-send Test - Issue #311 â€º should re-send Settings when agentOptions changes after connection (Issue #311)
[BROWSER] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (10 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[12/178] [chromium] â€º tests/e2e/api-key-validation.spec.js:16:5 â€º API Key Validation â€º should show error when API key is placeholder
[1A[2K[13/178] [chromium] â€º tests/e2e/backend-proxy-mode.spec.js:61:3 â€º Backend Proxy Mode â€º should work with agent responses through proxy
[1A[2K[14/178] [chromium] â€º tests/e2e/backend-proxy-authentication.spec.js:53:3 â€º Backend Proxy Authentication â€º should work without auth token (optional authentication)
[1A[2Kâš ï¸ WebSocket capture data not available - this is expected in proxy mode

[1A[2Kâš ï¸ Skipping WebSocket message verification, but SettingsApplied was received

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[15/178] [chromium] â€º tests/e2e/agent-options-resend-issue311.spec.js:218:3 â€º Agent Options Re-send Test - Issue #311 â€º should show entry point logs on component mount
[1A[2K[chromium] â€º tests/e2e/agent-options-resend-issue311.spec.js:218:3 â€º Agent Options Re-send Test - Issue #311 â€º should show entry point logs on component mount
ğŸ§ª Testing entry point logs on mount...

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[16/178] [chromium] â€º tests/e2e/api-key-validation.spec.js:16:5 â€º API Key Validation â€º should show error when API key is test-prefix
[1A[2K[17/178] [chromium] â€º tests/e2e/baseurl-test.spec.js:3:1 â€º baseURL test
[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[chromium] â€º tests/e2e/baseurl-test.spec.js:3:1 â€º baseURL test
Navigating to http://localhost:5173

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []
[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2KPage loaded, title: Vite + React + TS

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!

[1A[2K[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message
[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[18/178] [chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SettingsApplied message

[1A[2K[WebServer] [Proxy] âœ… SettingsApplied received from Deepgram, forwarding to client

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
ğŸ§ª Testing onTranscriptUpdate callback with existing audio sample...

[1A[2KğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] 22:04:38 - Component is not ready

[1A[2K[BROWSER] 22:04:38 - Agent state changed: idle

[1A[2K[BROWSER] 22:04:38 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045878445-0.21551122702023506}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:38 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:38 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] 22:04:38 - Component is ready

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] ğŸ¤ [APP] toggleMicrophone called

[1A[2K[BROWSER] ğŸ¤ [APP] micEnabled: false

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K[BROWSER] 22:04:38 - Starting audio capture (lazy initialization)

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K[WebServer] [DEBUG] Service type detected: transcription (from query: transcription, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing transcription service to wss://api.deepgram.com/v1/listen

[1A[2K[BROWSER] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K[BROWSER] 22:04:38 - Starting agent and transcription services...

[1A[2K[BROWSER] VAD: utterance_end_ms set to 1000ms

[1A[2K[BROWSER] 22:04:38 - transcription connection state: connecting

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): [
[WebServer]   [ 'model', 'nova-3' ],
[WebServer]   [ 'language', 'en-US' ],
[WebServer]   [ 'smart_format', 'true' ],
[WebServer]   [ 'interim_results', 'true' ],
[WebServer]   [ 'diarize', 'true' ],
[WebServer]   [ 'channels', '1' ],
[WebServer]   [ 'vad_events', 'true' ],
[WebServer]   [ 'utterance_end_ms', '1000' ],
[WebServer]   [ 'sample_rate', '16000' ],
[WebServer]   [ 'encoding', 'linear16' ]
[WebServer] ]

[1A[2K[WebServer] [Proxy] Connecting to Deepgram transcription service at wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (408 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[BROWSER] 22:04:38 - transcription connection state: connected

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[BROWSER] 22:04:38 - agent connection state: connecting

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []

[1A[2K[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2K[BROWSER] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[BROWSER] 22:04:38 - agent connection state: connected

[1A[2K[BROWSER] ğŸ¤ [APP] Services started (or already connected)

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!

[1A[2K[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message
[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[BROWSER] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[BROWSER] ğŸ“¤ [Component] Has functions? false

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocket URL: ws://localhost:8080/deepgram-proxy

[1A[2K[BROWSER] ğŸ“¤ [Component] Before sendJSON call:

[1A[2K[BROWSER] ğŸ“¤ [Component] - agentManagerRef.current exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket URL: ws://localhost:8080/deepgram-proxy?service=agent

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing binary message

[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K[BROWSER] 22:04:38 - Audio capture started successfully

[1A[2K[19/178] [chromium] â€º tests/e2e/api-key-validation.spec.js:22:3 â€º API Key Validation â€º should show setup instructions in error banner
[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SettingsApplied message

[1A[2K[WebServer] [Proxy] âœ… SettingsApplied received from Deepgram, forwarding to client

[1A[2K[BROWSER] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[BROWSER] ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K[BROWSER] 22:04:38 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] 22:04:38 - Agent said: Hello! How can I assist you today?

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from idle to speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:38 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:38 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:38 - Audio playback: started

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[chromium] â€º tests/e2e/agent-options-resend-issue311.spec.js:218:3 â€º Agent Options Re-send Test - Issue #311 â€º should show entry point logs on component mount

ğŸ“Š Entry Point Logs on Mount: 4

[1A[2K  - [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: undefined, isFirstRender: true}

[1A[2K  - [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] First render - skipping change detection

[1A[2K  - [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K  - [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K
âœ… Entry point logs appearing on mount - useEffect is running

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
ğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Connected to Deepgram transcription service
[WebServer] [Proxy] Client â†’ Deepgram (queued): binary message (320 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[20/178] [chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (408 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[BROWSER] ğŸ”Š [AGENT EVENT] AgentAudioDone received

[1A[2K[BROWSER] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue

[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
ğŸ”§ Testing component remounting behavior during transcript updates...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[21/178] [chromium] â€º tests/e2e/api-key-validation.spec.js:31:3 â€º API Key Validation â€º should NOT show error with valid API key
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: InjectUserMessage message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message

[1A[2K[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
ğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2Kâœ… Connection established and settings applied

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[22/178] [chromium] â€º tests/e2e/backend-proxy-mode.spec.js:121:3 â€º Backend Proxy Mode â€º should handle reconnection through proxy
[1A[2K[BROWSER] ğŸµ [AUDIO] Loading WAV file: hello.wav

[1A[2K[BROWSER] âœ… [AUDIO] Loaded WAV file: 636 bytes

[1A[2K[BROWSER] âš ï¸ [AUDIO] Could not find data chunk, assuming 44-byte header

[1A[2K[BROWSER] âœ… [AUDIO] Extracted PCM data: 592 bytes from data chunk (skipped 44 byte header)

[1A[2K[BROWSER] âš ï¸ [AUDIO] Extracted WAV data is too short (592 bytes < 32000 bytes minimum). Falling back to JSON.

[1A[2K[BROWSER] ğŸ”„ [AUDIO] WAV not available, loading JSON: hello

[1A[2K[BROWSER] âœ… [AUDIO] Loaded JSON sample: 84418 bytes

[1A[2K[BROWSER] ğŸ“Š [STREAMING] Audio duration: 2.64s (84418 bytes at 32000 bytes/s)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[BROWSER] ğŸŒŠ [STREAMING] Sending 21 chunks of 4096 bytes each with 125ms intervals (real-time: 2.64s total)...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[23/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:34:5 â€º Declarative Props API - Issue #305 â€º userMessage prop (replaces injectUserMessage) â€º should send message when userMessage prop changes
[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message

[1A[2K[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message
[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
[BROWSER] ğŸ¯ [AUDIO] Playback state changed: NOT PLAYING, current agent state: speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback finished - transitioning agent from speaking to idle

[1A[2K[BROWSER] 22:04:40 - Agent state changed: listening

[1A[2K[BROWSER] 22:04:40 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] 22:04:40 - User message from server: Hello?

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[BROWSER] ğŸ§  [AGENT] User stopped speaking (speech_final=true) - transitioning to thinking state

[1A[2K[BROWSER] [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Hello?, transcriptLength: 6}

[1A[2K[BROWSER] 22:04:40 - [TRANSCRIPT] "Hello?" (final)

[1A[2K[BROWSER] [TRANSCRIPT-CAPTURE] Stored final (speech_final) transcript: "Hello?..." (is_final: true, speech_final: true)

[1A[2K[BROWSER] 22:04:40 - Agent state changed: thinking

[1A[2K[24/178] [chromium] â€º tests/e2e/backend-proxy-mode.spec.js:146:3 â€º Backend Proxy Mode â€º should handle proxy server unavailable gracefully
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[25/178] [chromium] â€º tests/e2e/agent-state-transitions.spec.js:104:8 â€º Agent State Transitions â€º should transition: idle â†’ thinking â†’ speaking â†’ idle (tool trigger with text input)
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[26/178] [chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:16:3 â€º Deepgram Instructions File Configuration â€º should load instructions from environment variable override
[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:16:3 â€º Deepgram Instructions File Configuration â€º should load instructions from environment variable override
ğŸ§ª Testing environment variable override...

[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and settings applied

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:16:3 â€º Deepgram Instructions File Configuration â€º should load instructions from environment variable override
âœ… Environment variable override test passed

[1A[2K[27/178] [chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:34:3 â€º Deepgram Instructions File Configuration â€º should display instructions preview in UI
[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:34:3 â€º Deepgram Instructions File Configuration â€º should display instructions preview in UI
ğŸ§ª Testing instructions preview display...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2Kâœ… Instructions preview display test passed

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UtteranceEnd message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[28/178] [chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:56:3 â€º Deepgram Instructions File Configuration â€º should integrate instructions with DeepgramVoiceInteraction component
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:56:3 â€º Deepgram Instructions File Configuration â€º should integrate instructions with DeepgramVoiceInteraction component
ğŸ§ª Testing instructions integration with component...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
ğŸ“Š Initial mounts detected: 2

[1A[2KğŸ“Š Initial mount IDs: 

[1A[2KğŸ¤ Loading and streaming pre-recorded audio sample: shopping-concierge-question...

[1A[2K   This will generate transcripts and trigger parent re-renders...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:48:3 â€º Callback Test Suite â€º should test onTranscriptUpdate callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[BROWSER] 22:04:41 - Agent said: Hi there!

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: thinking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from thinking to speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:41 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:41 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:41 - Audio playback: started

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (828 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (2498 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (2498 bytes)

[1A[2K[BROWSER] âœ… [STREAMING] Audio streaming completed: 21 chunks sent over 2.63s (real-time)

[1A[2Kâœ… onTranscriptUpdate callback working - transcript displayed: Speaker 0: Hello?

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[29/178] [chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
ğŸ§ª Testing onUserStartedSpeaking callback with existing audio sample...

[1A[2KğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] 22:04:42 - Component is not ready

[1A[2K[BROWSER] 22:04:42 - Agent state changed: idle

[1A[2K[BROWSER] 22:04:42 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045882196-0.5058462739700395}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:42 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:42 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:42 - Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2K[BROWSER] ğŸ¤ [APP] toggleMicrophone called

[1A[2K[BROWSER] ğŸ¤ [APP] micEnabled: false

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K[BROWSER] 22:04:42 - Starting audio capture (lazy initialization)

[1A[2K[BROWSER] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K[BROWSER] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K[BROWSER] 22:04:42 - Starting agent and transcription services...

[1A[2K[BROWSER] VAD: utterance_end_ms set to 1000ms

[1A[2K[BROWSER] 22:04:42 - transcription connection state: connecting

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[WebServer] [DEBUG] Service type detected: transcription (from query: transcription, pathname: /deepgram-proxy)
[WebServer] [DEBUG] Routing transcription service to wss://api.deepgram.com/v1/listen

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): [
[WebServer]   [ 'model', 'nova-3' ],
[WebServer]   [ 'language', 'en-US' ],
[WebServer]   [ 'smart_format', 'true' ],
[WebServer]   [ 'interim_results', 'true' ],
[WebServer]   [ 'diarize', 'true' ],
[WebServer]   [ 'channels', '1' ],
[WebServer]   [ 'vad_events', 'true' ],
[WebServer]   [ 'utterance_end_ms', '1000' ],
[WebServer]   [ 'sample_rate', '16000' ],
[WebServer]   [ 'encoding', 'linear16' ]
[WebServer] ]
[WebServer] [Proxy] Connecting to Deepgram transcription service at wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16...

[1A[2K[BROWSER] 22:04:42 - transcription connection state: connected

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[BROWSER] 22:04:42 - agent connection state: connecting

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []

[1A[2K[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2K[BROWSER] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[BROWSER] 22:04:42 - agent connection state: connected

[1A[2K[BROWSER] ğŸ¤ [APP] Services started (or already connected)

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K[BROWSER] 22:04:42 - Audio capture started successfully

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!
[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message
[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[BROWSER] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[BROWSER] ğŸ“¤ [Component] Has functions? false

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocket URL: ws://localhost:8080/deepgram-proxy

[1A[2K[BROWSER] ğŸ“¤ [Component] Before sendJSON call:

[1A[2K[BROWSER] ğŸ“¤ [Component] - agentManagerRef.current exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket URL: ws://localhost:8080/deepgram-proxy?service=agent

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing binary message

[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[WebServer] [Proxy] Connected to Deepgram transcription service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): binary message (320 bytes)

[1A[2K[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SettingsApplied message

[1A[2K[WebServer] [Proxy] âœ… SettingsApplied received from Deepgram, forwarding to client

[1A[2K[BROWSER] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[BROWSER] ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K[BROWSER] 22:04:42 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] 22:04:42 - Agent said: Hello! How can I assist you today?

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from idle to speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:42 - Agent state changed: speaking

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] 22:04:42 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:42 - Audio playback: started

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (408 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[BROWSER] ğŸ”Š [AGENT EVENT] AgentAudioDone received

[1A[2K[BROWSER] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2Kâœ… Connection established and settings applied

[1A[2KğŸ“Š Initial user-started-speaking state: Not detected

[1A[2KğŸ¤ Using TTS-generated audio sample to trigger VAD events...

[1A[2K[BROWSER] ğŸµ [AUDIO] Loading WAV file: hello.wav

[1A[2K[BROWSER] âœ… [AUDIO] Loaded WAV file: 636 bytes

[1A[2K[BROWSER] âš ï¸ [AUDIO] Could not find data chunk, assuming 44-byte header

[1A[2K[BROWSER] âœ… [AUDIO] Extracted PCM data: 592 bytes from data chunk (skipped 44 byte header)

[1A[2K[BROWSER] âš ï¸ [AUDIO] Extracted WAV data is too short (592 bytes < 32000 bytes minimum). Falling back to JSON.

[1A[2K[BROWSER] ğŸ”„ [AUDIO] WAV not available, loading JSON: hello

[1A[2K[BROWSER] âœ… [AUDIO] Loaded JSON sample: 84418 bytes

[1A[2K[BROWSER] ğŸ“Š [STREAMING] Audio duration: 2.64s (84418 bytes at 32000 bytes/s)

[1A[2K[BROWSER] ğŸŒŠ [STREAMING] Sending 21 chunks of 4096 bytes each with 125ms intervals (real-time: 2.64s total)...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:56:3 â€º Deepgram Instructions File Configuration â€º should integrate instructions with DeepgramVoiceInteraction component
âœ… Instructions integration test passed

[1A[2K[30/178] [chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:83:3 â€º Deepgram Instructions File Configuration â€º should support different instruction sources
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:83:3 â€º Deepgram Instructions File Configuration â€º should support different instruction sources
ğŸ§ª Testing different instruction sources...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/deepgram-instructions-file.spec.js:83:3 â€º Deepgram Instructions File Configuration â€º should support different instruction sources
âœ… Instruction sources test passed

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[31/178] [chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[32/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message

[1A[2K[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: NOT PLAYING, current agent state: speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback finished - transitioning agent from speaking to idle

[1A[2K[BROWSER] 22:04:43 - Agent state changed: listening

[1A[2K[BROWSER] 22:04:43 - Audio playback: stopped - Agent playback completed

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message
[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[BROWSER] 22:04:43 - User message from server: Hello?

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ” Testing echo cancellation detection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] ğŸ§  [AGENT] User stopped speaking (speech_final=true) - transitioning to thinking state

[1A[2K[BROWSER] [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Hello?, transcriptLength: 6}

[1A[2K[BROWSER] 22:04:44 - [TRANSCRIPT] "Hello?" (final)

[1A[2K[BROWSER] [TRANSCRIPT-CAPTURE] Stored final (speech_final) transcript: "Hello?..." (is_final: true, speech_final: true)

[1A[2K[BROWSER] 22:04:44 - Agent state changed: thinking

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
ğŸ” Starting diagnostic test...

[1A[2KStep 1: Checking initial component state...

[1A[2KInitial connection status: closed

[1A[2KInitial mic status: Disabled

[1A[2KStep 2: Clicking microphone button...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UtteranceEnd message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¤ [APP] toggleMicrophone called

[1A[2K[LOG] ğŸ¤ [APP] micEnabled: false

[1A[2K[LOG] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K[LOG] 22:04:44 - Starting audio capture (lazy initialization)

[1A[2K[LOG] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K[LOG] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K[LOG] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K[LOG] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K[LOG] 22:04:44 - Starting agent and transcription services...

[1A[2K[LOG] [DeepgramVoiceInteraction] Start method called with options: {"agent":true,"transcription":true}

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] start() - Fresh connection detected, resetting allowAgentRef from true to true

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ”„ Fresh connection starting - resetting audio blocking state

[1A[2K[LOG] [DeepgramVoiceInteraction] Service start flags: transcription=true, agent=true

[1A[2K[LOG] [DeepgramVoiceInteraction] Creating transcription manager lazily...

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ”§ [TRANSCRIPTION] Creating transcription manager lazily

[1A[2K[LOG] VAD: utterance_end_ms set to 1000ms

[1A[2K[LOG] VAD: interim_results set to true

[1A[2K[LOG] [DeepgramVoiceInteraction] Not using keyterm prompting. Building queryParams object excluding array types.

[1A[2K[LOG] [WebSocketManager:transcription] WebSocketManager created

[1A[2K[LOG] [DeepgramVoiceInteraction] Creating agent manager lazily...

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ”§ [AGENT] Creating agent manager lazily

[1A[2K[LOG] ğŸ”§ [AGENT] Creating WebSocketManager with URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K[LOG] ğŸ”§ [AGENT] Connection mode: direct

[1A[2K[LOG] ğŸ”§ [AGENT] Proxy endpoint: undefined

[1A[2K[LOG] ğŸ”§ [AGENT] API key present: true

[1A[2K[LOG] ğŸ”§ [AGENT] Auth token present: false

[1A[2K[LOG] [WebSocketManager:agent] WebSocketManager created

[1A[2K[LOG] [DeepgramVoiceInteraction] AudioManager not configured, skipping initialization

[1A[2K[LOG] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K[LOG] [WebSocketManager:transcription] Connecting to WebSocket...

[1A[2K[LOG] ğŸ”§ [DEBUG] Transcription state event: connecting Previous: undefined

[1A[2K[LOG] [DeepgramVoiceInteraction] Transcription state: connecting

[1A[2K[LOG] 22:04:44 - transcription connection state: connecting

[1A[2K[LOG] [WebSocketManager:transcription] Built URL with params: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[LOG] [WebSocketManager:transcription] Connecting to wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] URL: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] Service: transcription

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [WebSocketManager:transcription] Initial readyState: 0

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [WebSocketManager:transcription] WebSocket connected

[1A[2K[LOG] ğŸ”§ [DEBUG] Transcription state event: connected Previous: connecting

[1A[2K[LOG] [DeepgramVoiceInteraction] Transcription state: connected

[1A[2K[LOG] 22:04:44 - transcription connection state: connected

[1A[2K[LOG] ğŸ”§ [TRANSCRIPTION] Starting periodic keepalive audio to prevent timeout

[1A[2K[LOG] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[LOG] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K[LOG] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[LOG] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K[LOG] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K[LOG] [WebSocketManager:agent] Connecting to WebSocket...

[1A[2K[LOG] ğŸ”§ [DEBUG] Agent state event: connecting Previous: undefined

[1A[2K[LOG] [DeepgramVoiceInteraction] Agent state: connecting

[1A[2K[LOG] 22:04:44 - agent connection state: connecting

[1A[2K[LOG] [WebSocketManager:agent] Built URL with params: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[LOG] [WebSocketManager:agent] Connecting to wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] Service: agent

[1A[2K[LOG] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K[LOG] [WebSocketManager:agent] Initial readyState: 0

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K[LOG] ğŸ”§ [TRANSCRIPTION] Periodic keepalive audio sent

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [WebSocketManager:agent] WebSocket connected

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] ğŸ”§ [DEBUG] Agent state event: connected Previous: connecting

[1A[2K[LOG] [DeepgramVoiceInteraction] Agent state: connected

[1A[2K[INFO] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[LOG] [DeepgramVoiceInteraction] Agent WebSocket connected for first time

[1A[2K[LOG] 22:04:45 - agent connection state: connected

[1A[2K[LOG] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K[LOG] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K[LOG] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K[LOG] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[LOG] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K[LOG] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[LOG] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K[LOG] [DeepgramVoiceInteraction] AudioManager not available - this is expected for text-only agent interactions

[1A[2K[LOG] [DeepgramVoiceInteraction] Start method completed successfully

[1A[2K[LOG] ğŸ¤ [APP] Services started (or already connected)

[1A[2K[LOG] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K[LOG] [DeepgramVoiceInteraction] startAudioCapture called - initializing audio manager lazily

[1A[2K[LOG] [AudioManager] AudioManager created

[1A[2K[LOG] [AudioManager] Initializing AudioManager

[1A[2K[LOG] [AudioManager] Created audio analyzer for volume normalization

[1A[2K[LOG] [AudioManager] Created Object URL for AudioWorklet: blob:http://localhost:5173/56de6920-d249-47f0-9fd0-046ee25cec04

[1A[2K[LOG] ğŸ¤ [MOCK] AudioWorklet.addModule called - simulating success

[1A[2K[LOG] [AudioManager] AudioWorklet loaded using Object URL

[1A[2K[LOG] [DeepgramVoiceInteraction] Audio manager ready

[1A[2K[LOG] [AudioManager] Revoking Object URL: blob:http://localhost:5173/56de6920-d249-47f0-9fd0-046ee25cec04

[1A[2K[LOG] [DeepgramVoiceInteraction] AudioManager initialized

[1A[2K[LOG] [DeepgramVoiceInteraction] Agent service already connected, skipping connection

[1A[2K[LOG] [AudioManager] Requesting microphone access

[1A[2K[LOG] ğŸ¤ [MOCK] getUserMedia called - returning mock MediaStream

[1A[2K[LOG] [AudioManager] Echo cancellation support: {supported: true, active: false, browser: Chrome, version: 141, limitations: Array(1)}

[1A[2K[LOG] [AudioManager] âš ï¸ Echo cancellation requested but not active

[1A[2K[LOG] ğŸ¤ [MOCK] createMediaStreamSource called - simulating success

[1A[2K[LOG] ğŸ¤ [MOCK] AudioWorkletNode constructor called - simulating success

[1A[2K[LOG] ğŸ¤ [MOCK] AudioWorkletNode port.postMessage called with: {type: start}

[1A[2K[LOG] [AudioManager] Recording started

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[LOG] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[LOG] ğŸ¯ [DEBUG] Started polling for idle timeout conditions

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=startAudioCapture, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[LOG] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[LOG] ğŸ¯ [DEBUG] Timeout started with timeoutId: 14

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[LOG] [DeepgramVoiceInteraction] Audio capture started successfully

[1A[2K[LOG] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K[LOG] 22:04:45 - Audio capture started successfully

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Welcome","request_id":"567aae35-6958-47d2-bf5e-78d8a175d28f"}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Welcome, request_id: 567aae35-6958-47d2-bf5e-78d8a175d28f}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Welcome

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: Welcome): {type: Welcome, request_id: 567aae35-6958-47d2-bf5e-78d8a175d28f}

[1A[2K[INFO] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[LOG] [DeepgramVoiceInteraction] Welcome message received - dual mode connection established

[1A[2K[LOG] [DeepgramVoiceInteraction] New connection - triggering greeting flow

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Welcome

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K[LOG] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] Called

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] agentOptions.functions: undefined

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 0

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: false

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] Settings message sent, waiting for SettingsApplied confirmation

[1A[2K[LOG] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[LOG] ğŸ” [DEBUG] Full Settings message structure: {
  "type": "Settings",
  "audio": {
    "input": {
      "encoding": "linear16",
      "sample_rate": 16000
    },
    "output": {
      "encoding": "linear16",
      "sample_rate": 24000
    }
  },
  "agent": {
    "language": "en",
    "think": {
      "provider": {
        "type": "open_ai",
        "model": "gpt-4o-mini"
      },
      "prompt": "You are a helpful voice assistant. Keep your responses concise and informative."
    },
    "speak": {
      "provider": {
        "type": "deepgram",
        "model": "aura-asteria-en"
      }
    },
    "greeting": "Hello! How can I assist you today?"
  }
}

[1A[2K[LOG] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[LOG] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[LOG] ğŸ“¤ [Component] Has functions? false

[1A[2K[LOG] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K[LOG] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K[LOG] ğŸ“¤ [Component] Before sendJSON call:

[1A[2K[LOG] ğŸ“¤ [Component] - agentManagerRef.current exists? true

[1A[2K[LOG] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K[LOG] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K[LOG] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: Settings

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=Settings, isSettings=true

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… ENTERED Settings block!

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] Setting window variables...

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Window variables set successfully

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Settings message detected!

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (exact JSON string): {"type":"Settings","audio":{"input":{"encoding":"linear16","sample_rate":16000},"output":{"encoding":"linear16","sample_rate":24000}},"agent":{"language":"en","think":{"provider":{"type":"open_ai","model":"gpt-4o-mini"},"prompt":"You are a helpful voice assistant. Keep your responses concise and informative."},"speak":{"provider":{"type":"deepgram","model":"aura-asteria-en"}},"greeting":"Hello! How can I assist you today?"}}

[1A[2K[LOG] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (parsed): {type: Settings, audio: Object, agent: Object}

[1A[2K[LOG] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K[LOG] [WebSocketManager:agent] Started keepalive interval

[1A[2K[LOG] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K[LOG] ğŸ”§ [sendAgentSettings] Flags set immediately after successful send (StrictMode protection)

[1A[2K[LOG] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[LOG] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: SettingsApplied): {type: SettingsApplied}

[1A[2K[INFO] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[LOG] [DeepgramVoiceInteraction] SettingsApplied received - settings are now active

[1A[2K[LOG] ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K[LOG] 22:04:45 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"ConversationText","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: ConversationText

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: ConversationText): {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[LOG] ğŸ’¬ [AGENT EVENT] ConversationText received role= assistant

[1A[2K[LOG] 22:04:45 - Agent said: Hello! How can I assist you today?

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: ConversationText

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"History","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: History

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: History): {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[LOG] ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: History

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045883781-0.39112621399972447}

[1A[2K[LOG] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connected, isConnected: true}

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true}

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 0, startTimeRef.current = 0

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.11733333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 1

[1A[2K[LOG] [DeepgramVoiceInteraction] Playing state: true

[1A[2K[LOG] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle

[1A[2K[LOG] ğŸ¯ [AGENT] Audio playback started - transitioning from idle to speaking

[1A[2K[LOG] [SLEEP_CYCLE][CORE] Dispatching AGENT_STATE_CHANGE to speaking (from playback start, previous state: idle)

[1A[2K[LOG] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[LOG] 22:04:45 - Agent state changed: speaking

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 1, startTimeRef.current = 0.13733333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.137s, current time: 0.117s, active sources: 1

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 1, startTimeRef.current = 0.13733333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.13733333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 2

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 2, startTimeRef.current = 0.15733333333333333

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.157s, current time: 0.117s, active sources: 2

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 2, startTimeRef.current = 0.15733333333333333

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.15733333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 3

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 3, startTimeRef.current = 0.17733333333333332

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.177s, current time: 0.117s, active sources: 3

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 3, startTimeRef.current = 0.17733333333333332

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.17733333333333332 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 4

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 4, startTimeRef.current = 0.1973333333333333

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.197s, current time: 0.117s, active sources: 4

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 4, startTimeRef.current = 0.1973333333333333

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.1973333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 5

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 5, startTimeRef.current = 0.2173333333333333

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.217s, current time: 0.117s, active sources: 5

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 5, startTimeRef.current = 0.2173333333333333

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.2173333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 6

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 6, startTimeRef.current = 0.23733333333333329

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.237s, current time: 0.117s, active sources: 6

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 6, startTimeRef.current = 0.23733333333333329

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.2373333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 7

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 7, startTimeRef.current = 0.2573333333333333

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.257s, current time: 0.117s, active sources: 7

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: true, isPlayingChanged: true, isUserSpeakingChanged: false}

[1A[2K[LOG] [useIdleTimeoutManager] Emitting AGENT_STATE_CHANGED: idle -> speaking

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: false, isDisabled: false}

[1A[2K[LOG] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[LOG] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: 14

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 14

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[LOG] ğŸ¯ [DEBUG] Timeout cleared successfully

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[LOG] [useIdleTimeoutManager] Emitting PLAYBACK_STATE_CHANGED: false -> true

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[LOG] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[LOG] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[LOG] [DeepgramVoiceInteraction] Notifying parent: agentState changed to speaking

[1A[2K[LOG] 22:04:45 - Agent state changed: speaking

[1A[2K[LOG] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to true

[1A[2K[LOG] 22:04:45 - Audio playback: started

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 7, startTimeRef.current = 0.2573333333333333

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.2573333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 8

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 8, startTimeRef.current = 0.2773333333333333

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.277s, current time: 0.128s, active sources: 8

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 8, startTimeRef.current = 0.2773333333333333

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.2773333333333333 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 9

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 9, startTimeRef.current = 0.29733333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.297s, current time: 0.128s, active sources: 9

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 9, startTimeRef.current = 0.29733333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.29733333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 10

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 10, startTimeRef.current = 0.31733333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.317s, current time: 0.128s, active sources: 10

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 10, startTimeRef.current = 0.31733333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.31733333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 11

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 11, startTimeRef.current = 0.3373333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.337s, current time: 0.128s, active sources: 11

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 10

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 10, startTimeRef.current = 0.3373333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.3373333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 11

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 11, startTimeRef.current = 0.3573333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.357s, current time: 0.155s, active sources: 11

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 11, startTimeRef.current = 0.3573333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.3573333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 12

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 12, startTimeRef.current = 0.3773333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.377s, current time: 0.155s, active sources: 12

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 12, startTimeRef.current = 0.3773333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.3773333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 13

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 13, startTimeRef.current = 0.3973333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.397s, current time: 0.155s, active sources: 13

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 13, startTimeRef.current = 0.3973333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.3973333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 14

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 14, startTimeRef.current = 0.41733333333333344

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.417s, current time: 0.155s, active sources: 14

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 14, startTimeRef.current = 0.41733333333333344

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.41733333333333344 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 15

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 15, startTimeRef.current = 0.43733333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.437s, current time: 0.155s, active sources: 15

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 15, startTimeRef.current = 0.43733333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.43733333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 16

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 16, startTimeRef.current = 0.4573333333333335

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.457s, current time: 0.155s, active sources: 16

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 16, startTimeRef.current = 0.4573333333333335

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.4573333333333335 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 17

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 17, startTimeRef.current = 0.4773333333333335

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.477s, current time: 0.155s, active sources: 17

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 17, startTimeRef.current = 0.4773333333333335

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.4773333333333335 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 18

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 18, startTimeRef.current = 0.4973333333333335

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.497s, current time: 0.155s, active sources: 18

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 18, startTimeRef.current = 0.4973333333333335

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.4973333333333335 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 19

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 19, startTimeRef.current = 0.5173333333333335

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.517s, current time: 0.155s, active sources: 19

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 19, startTimeRef.current = 0.5173333333333335

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.5173333333333335 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 20

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 20, startTimeRef.current = 0.5373333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.537s, current time: 0.155s, active sources: 20

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 20, startTimeRef.current = 0.5373333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.5373333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 21

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 21, startTimeRef.current = 0.5573333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.557s, current time: 0.155s, active sources: 21

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 21, startTimeRef.current = 0.5573333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.5573333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 22

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 22, startTimeRef.current = 0.5773333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.577s, current time: 0.155s, active sources: 22

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 22, startTimeRef.current = 0.5773333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.5773333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 23

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 23, startTimeRef.current = 0.5973333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.597s, current time: 0.155s, active sources: 23

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 23, startTimeRef.current = 0.5973333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.5973333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 24

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 24, startTimeRef.current = 0.6173333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.617s, current time: 0.155s, active sources: 24

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 24, startTimeRef.current = 0.6173333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.6173333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 25

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 25, startTimeRef.current = 0.6373333333333336

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.637s, current time: 0.155s, active sources: 25

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 25, startTimeRef.current = 0.6373333333333336

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.6373333333333336 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 26

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 26, startTimeRef.current = 0.6573333333333337

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.657s, current time: 0.155s, active sources: 26

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 26, startTimeRef.current = 0.6573333333333337

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.6573333333333337 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 27

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 27, startTimeRef.current = 0.6773333333333337

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.677s, current time: 0.155s, active sources: 27

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 27, startTimeRef.current = 0.6773333333333337

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.6773333333333337 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 28

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 28, startTimeRef.current = 0.6973333333333337

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.697s, current time: 0.155s, active sources: 28

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 28, startTimeRef.current = 0.6973333333333337

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.6973333333333337 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 29

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 29, startTimeRef.current = 0.7173333333333337

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.717s, current time: 0.155s, active sources: 29

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 29, startTimeRef.current = 0.7173333333333337

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.7173333333333337 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 30

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 30, startTimeRef.current = 0.7373333333333337

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.737s, current time: 0.155s, active sources: 30

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 30, startTimeRef.current = 0.7373333333333337

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.7373333333333337 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 31

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 31, startTimeRef.current = 0.7573333333333337

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.757s, current time: 0.160s, active sources: 31

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 31, startTimeRef.current = 0.7573333333333337

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.7573333333333337 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 32

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 32, startTimeRef.current = 0.7773333333333338

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.777s, current time: 0.160s, active sources: 32

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 32, startTimeRef.current = 0.7773333333333338

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.7773333333333338 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 33

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 33, startTimeRef.current = 0.7973333333333338

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.797s, current time: 0.160s, active sources: 33

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 32

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 32, startTimeRef.current = 0.7973333333333338

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.7973333333333338 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 33

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 33, startTimeRef.current = 0.8173333333333338

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.817s, current time: 0.160s, active sources: 33

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 33, startTimeRef.current = 0.8173333333333338

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.8173333333333338 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 34

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 34, startTimeRef.current = 0.8373333333333338

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.837s, current time: 0.160s, active sources: 34

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 34, startTimeRef.current = 0.8373333333333338

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.8373333333333338 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 35

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 35, startTimeRef.current = 0.8573333333333338

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.857s, current time: 0.160s, active sources: 35

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 35, startTimeRef.current = 0.8573333333333338

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.8573333333333338 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 36

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 36, startTimeRef.current = 0.8773333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.877s, current time: 0.160s, active sources: 36

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 36, startTimeRef.current = 0.8773333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.8773333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 37

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 37, startTimeRef.current = 0.8973333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.897s, current time: 0.160s, active sources: 37

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 37, startTimeRef.current = 0.8973333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.8973333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 38

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 38, startTimeRef.current = 0.9173333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.917s, current time: 0.165s, active sources: 38

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 38, startTimeRef.current = 0.9173333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.9173333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 39

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 39, startTimeRef.current = 0.9373333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.937s, current time: 0.165s, active sources: 39

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 38

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 38, startTimeRef.current = 0.9373333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.9373333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 39

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 39, startTimeRef.current = 0.9573333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.957s, current time: 0.192s, active sources: 39

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 39, startTimeRef.current = 0.9573333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.9573333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 40

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 40, startTimeRef.current = 0.9773333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.977s, current time: 0.192s, active sources: 40

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 40, startTimeRef.current = 0.9773333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.9773333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 41

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 41, startTimeRef.current = 0.997333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 0.997s, current time: 0.192s, active sources: 41

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 41, startTimeRef.current = 0.997333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 0.9973333333333338 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 42

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 42, startTimeRef.current = 1.0173333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.017s, current time: 0.192s, active sources: 42

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 42, startTimeRef.current = 1.0173333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.0173333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 43

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 43, startTimeRef.current = 1.0373333333333339

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.037s, current time: 0.192s, active sources: 43

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 43, startTimeRef.current = 1.0373333333333339

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.0373333333333339 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 44

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 44, startTimeRef.current = 1.057333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.057s, current time: 0.192s, active sources: 44

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 44, startTimeRef.current = 1.057333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.057333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 45

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 45, startTimeRef.current = 1.077333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.077s, current time: 0.192s, active sources: 45

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 45, startTimeRef.current = 1.077333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.077333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 46

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 46, startTimeRef.current = 1.097333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.097s, current time: 0.192s, active sources: 46

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 46, startTimeRef.current = 1.097333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.097333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 47

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 47, startTimeRef.current = 1.117333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.117s, current time: 0.192s, active sources: 47

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 47, startTimeRef.current = 1.117333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.117333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 48

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 48, startTimeRef.current = 1.137333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.137s, current time: 0.192s, active sources: 48

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ“ [TEST] Console log: [AudioManager] Echo cancellation support: {supported: true, active: false, browser: Chrome, version: 141, limitations: Array(1)}

[1A[2KğŸ“ [TEST] Console log: [AudioManager] âš ï¸ Echo cancellation requested but not active

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 48, startTimeRef.current = 1.137333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.137333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 49

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 49, startTimeRef.current = 1.157333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.157s, current time: 0.192s, active sources: 49

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 49, startTimeRef.current = 1.157333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.157333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 50

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 50, startTimeRef.current = 1.177333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.177s, current time: 0.192s, active sources: 50

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 50, startTimeRef.current = 1.177333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.177333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 51

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 51, startTimeRef.current = 1.197333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.197s, current time: 0.192s, active sources: 51

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 51, startTimeRef.current = 1.197333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.197333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 52

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 52, startTimeRef.current = 1.217333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.217s, current time: 0.192s, active sources: 52

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 52, startTimeRef.current = 1.217333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.217333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 53

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 53, startTimeRef.current = 1.237333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.237s, current time: 0.192s, active sources: 53

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 53, startTimeRef.current = 1.237333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.237333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 54

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 54, startTimeRef.current = 1.257333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.257s, current time: 0.192s, active sources: 54

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 54, startTimeRef.current = 1.257333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.257333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 55

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 55, startTimeRef.current = 1.277333333333334

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.277s, current time: 0.197s, active sources: 55

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 55, startTimeRef.current = 1.277333333333334

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.277333333333334 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 56

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 56, startTimeRef.current = 1.2973333333333341

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.297s, current time: 0.197s, active sources: 56

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 56, startTimeRef.current = 1.2973333333333341

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.2973333333333341 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 57

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 57, startTimeRef.current = 1.3173333333333341

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.317s, current time: 0.197s, active sources: 57

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 57, startTimeRef.current = 1.3173333333333341

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.3173333333333341 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 58

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 58, startTimeRef.current = 1.3373333333333342

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.337s, current time: 0.197s, active sources: 58

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 58, startTimeRef.current = 1.3373333333333342

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.3373333333333342 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 59

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 59, startTimeRef.current = 1.3573333333333342

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.357s, current time: 0.197s, active sources: 59

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 59, startTimeRef.current = 1.3573333333333342

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.3573333333333342 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 60

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 60, startTimeRef.current = 1.3773333333333342

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.377s, current time: 0.197s, active sources: 60

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 60, startTimeRef.current = 1.3773333333333342

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.3773333333333342 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 61

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 61, startTimeRef.current = 1.3973333333333342

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.397s, current time: 0.197s, active sources: 61

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 61, startTimeRef.current = 1.3973333333333342

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.3973333333333342 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 62

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 62, startTimeRef.current = 1.4173333333333342

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.417s, current time: 0.197s, active sources: 62

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 62, startTimeRef.current = 1.4173333333333342

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.4173333333333342 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 63

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 63, startTimeRef.current = 1.4373333333333342

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.437s, current time: 0.197s, active sources: 63

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 63, startTimeRef.current = 1.4373333333333342

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.4373333333333342 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 64

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 64, startTimeRef.current = 1.4573333333333343

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.457s, current time: 0.197s, active sources: 64

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 64, startTimeRef.current = 1.4573333333333343

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.4573333333333343 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 65

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 65, startTimeRef.current = 1.4773333333333343

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.477s, current time: 0.197s, active sources: 65

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 65, startTimeRef.current = 1.4773333333333343

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.4773333333333343 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 66

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 66, startTimeRef.current = 1.4973333333333343

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.497s, current time: 0.197s, active sources: 66

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 66, startTimeRef.current = 1.4973333333333343

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.4973333333333343 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 67

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 67, startTimeRef.current = 1.5173333333333343

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.517s, current time: 0.197s, active sources: 67

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 67, startTimeRef.current = 1.5173333333333343

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.5173333333333343 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 68

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 68, startTimeRef.current = 1.5373333333333343

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.537s, current time: 0.197s, active sources: 68

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 68, startTimeRef.current = 1.5373333333333343

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.5373333333333343 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 69

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 69, startTimeRef.current = 1.5573333333333343

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.557s, current time: 0.197s, active sources: 69

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 69, startTimeRef.current = 1.5573333333333343

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.5573333333333343 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 70

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 70, startTimeRef.current = 1.5773333333333344

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.577s, current time: 0.197s, active sources: 70

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 70, startTimeRef.current = 1.5773333333333344

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.5773333333333344 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 71

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 71, startTimeRef.current = 1.5973333333333344

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.597s, current time: 0.197s, active sources: 71

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 71, startTimeRef.current = 1.5973333333333344

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.5973333333333344 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 72

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 72, startTimeRef.current = 1.6173333333333344

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.617s, current time: 0.197s, active sources: 72

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 72, startTimeRef.current = 1.6173333333333344

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.6173333333333344 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 73

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 73, startTimeRef.current = 1.6373333333333344

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.637s, current time: 0.197s, active sources: 73

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 73, startTimeRef.current = 1.6373333333333344

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.6373333333333344 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 74

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 74, startTimeRef.current = 1.6573333333333344

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.657s, current time: 0.197s, active sources: 74

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 74, startTimeRef.current = 1.6573333333333344

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.6573333333333344 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 75

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 75, startTimeRef.current = 1.6773333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.677s, current time: 0.197s, active sources: 75

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 75, startTimeRef.current = 1.6773333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.6773333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 76

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 76, startTimeRef.current = 1.6973333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.697s, current time: 0.197s, active sources: 76

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 76, startTimeRef.current = 1.6973333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.6973333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 77

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 77, startTimeRef.current = 1.7173333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.717s, current time: 0.197s, active sources: 77

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 77, startTimeRef.current = 1.7173333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.7173333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 78

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 78, startTimeRef.current = 1.7373333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.737s, current time: 0.197s, active sources: 78

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 78, startTimeRef.current = 1.7373333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.7373333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 79

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 79, startTimeRef.current = 1.7573333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.757s, current time: 0.197s, active sources: 79

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 79, startTimeRef.current = 1.7573333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.7573333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 80

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 80, startTimeRef.current = 1.7773333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.777s, current time: 0.197s, active sources: 80

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 80, startTimeRef.current = 1.7773333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.7773333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 81

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 81, startTimeRef.current = 1.7973333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.797s, current time: 0.203s, active sources: 81

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 81, startTimeRef.current = 1.7973333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.7973333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 82

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 82, startTimeRef.current = 1.8173333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.817s, current time: 0.203s, active sources: 82

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 82, startTimeRef.current = 1.8173333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.8173333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 83

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 83, startTimeRef.current = 1.8373333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.837s, current time: 0.203s, active sources: 83

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 83, startTimeRef.current = 1.8373333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.8373333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 84

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 84, startTimeRef.current = 1.8573333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.857s, current time: 0.203s, active sources: 84

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 84, startTimeRef.current = 1.8573333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.8573333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 85

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 85, startTimeRef.current = 1.8773333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.877s, current time: 0.203s, active sources: 85

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 85, startTimeRef.current = 1.8773333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.8773333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 86

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 86, startTimeRef.current = 1.8973333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.897s, current time: 0.203s, active sources: 86

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 85

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[LOG] [WebSocketManager:agent] Received Blob binary data (size: 408), converting to ArrayBuffer...

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[LOG] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"AgentAudioDone"}

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: AgentAudioDone}

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[LOG] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[LOG] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[LOG] ğŸ¯ [DEBUG] Timeout started with timeoutId: 20

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[LOG] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: AgentAudioDone

[1A[2K[LOG] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: AgentAudioDone): {type: AgentAudioDone}

[1A[2K[LOG] ğŸ”Š [AGENT EVENT] AgentAudioDone received

[1A[2K[LOG] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue

[1A[2K[LOG] [SLEEP_CYCLE][CORE] AgentAudioDone received - audio generation complete, but playback may continue

[1A[2K[LOG] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: AgentAudioDone

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 85, startTimeRef.current = 1.8973333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.8973333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 86

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 86, startTimeRef.current = 1.9173333333333347

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.917s, current time: 0.203s, active sources: 86

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 86, startTimeRef.current = 1.9173333333333347

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.9173333333333347 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 87

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 87, startTimeRef.current = 1.9373333333333347

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.937s, current time: 0.203s, active sources: 87

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 87, startTimeRef.current = 1.9373333333333347

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.9373333333333347 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 88

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 88, startTimeRef.current = 1.9573333333333347

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.957s, current time: 0.203s, active sources: 88

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 88, startTimeRef.current = 1.9573333333333347

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.9573333333333347 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 89

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 89, startTimeRef.current = 1.9773333333333347

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.977s, current time: 0.203s, active sources: 89

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 89, startTimeRef.current = 1.9773333333333347

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.9773333333333347 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 90

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 90, startTimeRef.current = 1.9973333333333347

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 1.997s, current time: 0.203s, active sources: 90

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 90, startTimeRef.current = 1.9973333333333347

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 1.9973333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 91

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 91, startTimeRef.current = 2.0173333333333345

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.017s, current time: 0.203s, active sources: 91

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 91, startTimeRef.current = 2.0173333333333345

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 2.0173333333333345 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 92

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 92, startTimeRef.current = 2.0373333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.037s, current time: 0.203s, active sources: 92

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 92, startTimeRef.current = 2.0373333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 2.0373333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 93

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 93, startTimeRef.current = 2.0573333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.057s, current time: 0.203s, active sources: 93

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 93, startTimeRef.current = 2.0573333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 2.0573333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 94

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 94, startTimeRef.current = 2.0773333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.077s, current time: 0.203s, active sources: 94

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 94, startTimeRef.current = 2.0773333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 2.0773333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 95

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 95, startTimeRef.current = 2.0973333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.097s, current time: 0.203s, active sources: 95

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 95, startTimeRef.current = 2.0973333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 2.0973333333333346 (duration: 0.02)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 96

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 96, startTimeRef.current = 2.1173333333333346

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.117s, current time: 0.203s, active sources: 96

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 408), emitting binary event...

[1A[2K[LOG] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 408

[1A[2K[LOG] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 408 bytes

[1A[2K[LOG] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[LOG] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[LOG] ğŸµ [AUDIO] Audio context state: running

[1A[2K[LOG] [AudioManager] ğŸµ [queueAudio] Received audio data: 408 bytes

[1A[2K[LOG] [AudioManager] Processing audio data (408 bytes)...

[1A[2K[LOG] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 96, startTimeRef.current = 2.1173333333333346

[1A[2K[LOG] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[LOG] [AudioManager] [queueAudio] Created audio buffer (0.009s)

[1A[2K[LOG] [AudioManager] [queueAudio] Scheduled source to start at 2.1173333333333346 (duration: 0.0085)

[1A[2K[LOG] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 97

[1A[2K[LOG] [AudioManager] [queueAudio] After: activeSourceNodes.length = 97, startTimeRef.current = 2.125833333333335

[1A[2K[LOG] [AudioManager] Audio scheduled to play at 2.126s, current time: 0.203s, active sources: 97

[1A[2K[LOG] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 96

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 95

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 94

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 93

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 92

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 91

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:36:3 â€º Echo Cancellation Detection and Configuration â€º should detect echo cancellation support when microphone is enabled
ğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Echo cancellation detection path executed (2 related logs)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 90

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 89

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 88

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 87

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[33/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 86

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 85

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 84

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 83

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 82

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 81

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 80

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
ğŸ” Testing default audio constraints...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 79

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] 22:04:45 - Agent said: Hello!

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 78

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: thinking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from thinking to speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:45 - Agent state changed: speaking

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[34/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:81:5 â€º Declarative Props API - Issue #305 â€º userMessage prop (replaces injectUserMessage) â€º should trigger onUserMessageSent callback after message is sent
[1A[2K[BROWSER] 22:04:45 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:45 - Audio playback: started

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 77

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (398 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 76

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 75

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 74

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 73

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 72

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 71

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 70

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 69

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 68

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (2498 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (2498 bytes)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:87:3 â€º Callback Test Suite â€º should test onUserStartedSpeaking callback with existing audio sample
[BROWSER] âœ… [STREAMING] Audio streaming completed: 21 chunks sent over 2.63s (real-time)

[1A[2Kâœ… onUserStartedSpeaking callback working - UserStartedSpeaking detected: 22:04:43

[1A[2KğŸ“Š Events detected count: [33m1[39m

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 67

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 66

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 

[1A[2K[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[35/178] [chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 65

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 64

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 63

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 62

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
ğŸ§ª Testing onUserStoppedSpeaking callback with existing audio sample...

[1A[2KğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 61

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] 22:04:45 - Component is not ready

[1A[2K[BROWSER] 22:04:45 - Agent state changed: idle

[1A[2K[BROWSER] 22:04:45 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045885982-0.4646496559417218}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:45 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:45 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:45 - Component is ready

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 60

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
ğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 59

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ¤ [APP] toggleMicrophone called

[1A[2K[BROWSER] ğŸ¤ [APP] micEnabled: false

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K[BROWSER] 22:04:46 - Starting audio capture (lazy initialization)

[1A[2K[BROWSER] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K[BROWSER] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K[BROWSER] 22:04:46 - Starting agent and transcription services...

[1A[2K[BROWSER] VAD: utterance_end_ms set to 1000ms

[1A[2K[BROWSER] 22:04:46 - transcription connection state: connecting

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[WebServer] [DEBUG] Service type detected: transcription (from query: transcription, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing transcription service to wss://api.deepgram.com/v1/listen

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): [
[WebServer]   [ 'model', 'nova-3' ],
[WebServer]   [ 'language', 'en-US' ],
[WebServer]   [ 'smart_format', 'true' ],
[WebServer]   [ 'interim_results', 'true' ],
[WebServer]   [ 'diarize', 'true' ],
[WebServer]   [ 'channels', '1' ],
[WebServer]   [ 'vad_events', 'true' ],
[WebServer]   [ 'utterance_end_ms', '1000' ],
[WebServer]   [ 'sample_rate', '16000' ],
[WebServer]   [ 'encoding', 'linear16' ]
[WebServer] ]

[1A[2K[WebServer] [Proxy] Connecting to Deepgram transcription service at wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 58

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 57

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] 22:04:46 - transcription connection state: connected

[1A[2K[BROWSER] 22:04:46 - agent connection state: connecting

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []

[1A[2K[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2K[BROWSER] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[BROWSER] 22:04:46 - agent connection state: connected

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ¤ [APP] Services started (or already connected)

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 56

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
ğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K[BROWSER] 22:04:46 - Audio capture started successfully

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 55

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 54

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!

[1A[2K[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message
[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[BROWSER] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[BROWSER] ğŸ“¤ [Component] Has functions? false

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocket URL: ws://localhost:8080/deepgram-proxy

[1A[2K[BROWSER] ğŸ“¤ [Component] Before sendJSON call:

[1A[2K[BROWSER] ğŸ“¤ [Component] - agentManagerRef.current exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket URL: ws://localhost:8080/deepgram-proxy?service=agent

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 53

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 52

[1A[2K[WebServer] [Proxy] Connected to Deepgram transcription service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (320 bytes)

[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 51

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 50

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SettingsApplied message
[WebServer] [Proxy] âœ… SettingsApplied received from Deepgram, forwarding to client

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 49

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[BROWSER] ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K[BROWSER] 22:04:46 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[BROWSER] 22:04:46 - Agent said: Hello! How can I assist you today?

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 48

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from idle to speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:46 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:46 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:46 - Audio playback: started

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 47

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 46

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 45

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 44

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (408 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ”Š [AGENT EVENT] AgentAudioDone received

[1A[2K[BROWSER] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 43

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 42

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 41

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 40

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 39

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
ğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 38

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 37

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 36

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 35

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 34

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 33

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 32

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 31

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 30

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 29

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 28

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 27

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 26

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 25

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 24

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 23

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 22

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 21

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 20

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 19

[1A[2KMic status after click: Enabled

[1A[2KConnection status after click: connected

[1A[2KStep 3: Simulating speech...

[1A[2K[LOG] ğŸ¤ [TEST] Sending simulated audio data to Deepgram: diagnostic test speech

[1A[2K[LOG] ğŸµ [sendAudioData] Called with data size: 8192

[1A[2K[LOG] ğŸµ [sendAudioData] hasSentSettingsRef.current: true

[1A[2K[LOG] ğŸµ [sendAudioData] state.hasSentSettings: true

[1A[2K[LOG] ğŸµ [sendAudioData] agentManagerRef.current?.getState(): connected

[1A[2K[LOG] ğŸµ [sendAudioData] transcriptionManagerRef.current?.getState(): connected

[1A[2K[LOG] ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K[LOG] [WebSocketManager:transcription] Sending binary data: 8192 bytes

[1A[2K[LOG] ğŸµ [sendAudioData] âœ… Settings confirmed, sending to agent service

[1A[2K[LOG] [WebSocketManager:agent] Sending binary data: 8192 bytes

[1A[2K[LOG] ğŸµ [AUDIO] Audio data sent to Deepgram agent service

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 18

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 17

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 16

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 15

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 14

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 13

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 12

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 11

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 10

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
ğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 9

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 8

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
ğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2Kâœ… Connection established and settings applied

[1A[2K[BROWSER] ğŸµ [AUDIO] Loading WAV file: hello.wav

[1A[2K[BROWSER] âœ… [AUDIO] Loaded WAV file: 636 bytes

[1A[2K[BROWSER] âš ï¸ [AUDIO] Could not find data chunk, assuming 44-byte header

[1A[2K[BROWSER] âœ… [AUDIO] Extracted PCM data: 592 bytes from data chunk (skipped 44 byte header)

[1A[2K[BROWSER] âš ï¸ [AUDIO] Extracted WAV data is too short (592 bytes < 32000 bytes minimum). Falling back to JSON.

[1A[2K[BROWSER] ğŸ”„ [AUDIO] WAV not available, loading JSON: hello

[1A[2K[BROWSER] âœ… [AUDIO] Loaded JSON sample: 84418 bytes

[1A[2K[BROWSER] ğŸ“Š [STREAMING] Audio duration: 2.64s (84418 bytes at 32000 bytes/s)

[1A[2K[BROWSER] ğŸŒŠ [STREAMING] Sending 21 chunks of 4096 bytes each with 125ms intervals (real-time: 2.64s total)...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 7

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 6

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 5

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 4

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
âœ… Audio sample streamed: shopping-concierge-question

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 3

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 2

[1A[2K[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 1

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] [AudioManager] [onended] Audio source playback ended

[1A[2K[LOG] [AudioManager] [onended] Source removed. activeSourceNodes.length = 0

[1A[2K[LOG] [AudioManager] [onended] No more active sources, setting playing state to false

[1A[2K[LOG] [DeepgramVoiceInteraction] Playing state: false

[1A[2K[LOG] ğŸ¯ [AUDIO] Playback state changed: NOT PLAYING, current agent state: speaking

[1A[2K[LOG] ğŸ¯ [AGENT] Audio playback finished - transitioning agent from speaking to idle

[1A[2K[LOG] [SLEEP_CYCLE][CORE] Audio playback finished - transitioning agent to idle

[1A[2K[LOG] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: true, isPlayingChanged: true, isUserSpeakingChanged: false}

[1A[2K[LOG] [useIdleTimeoutManager] Emitting AGENT_STATE_CHANGED: speaking -> idle

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[LOG] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[LOG] [useIdleTimeoutManager] Emitting PLAYBACK_STATE_CHANGED: true -> false

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[LOG] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[LOG] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[LOG] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[LOG] [DeepgramVoiceInteraction] Notifying parent: agentState changed to idle

[1A[2K[LOG] 22:04:47 - Agent state changed: idle

[1A[2K[LOG] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to false

[1A[2K[LOG] 22:04:47 - Audio playback: stopped - Agent playback completed

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message

[1A[2K[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] ğŸ¯ [AUDIO] Playback state changed: NOT PLAYING, current agent state: speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback finished - transitioning agent from speaking to idle

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[BROWSER] 22:04:47 - User message from server: Hello?

[1A[2K[BROWSER] 22:04:47 - Agent state changed: listening

[1A[2K[BROWSER] 22:04:47 - Audio playback: stopped - Agent playback completed

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[BROWSER] ğŸ§  [AGENT] User stopped speaking (speech_final=true) - transitioning to thinking state

[1A[2K[BROWSER] [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Hello?, transcriptLength: 6}

[1A[2K[BROWSER] 22:04:47 - [TRANSCRIPT] "Hello?" (final)

[1A[2K[BROWSER] [TRANSCRIPT-CAPTURE] Stored final (speech_final) transcript: "Hello?..." (is_final: true, speech_final: true)

[1A[2K[BROWSER] 22:04:47 - Agent state changed: thinking

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
Step 4: Checking for VAD events...

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:76:3 â€º Echo Cancellation Detection and Configuration â€º should apply default audio constraints when none specified
âš ï¸ Constraints not captured (likely due to mocks), but code path executed

[1A[2K[36/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
ğŸ” Testing custom audio constraints...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UtteranceEnd message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/component-remount-detection.spec.js:28:3 â€º Component Remount Detection (Issue #276) â€º should not remount on transcript updates
ğŸ“Š Final mounts detected: 2

[1A[2KğŸ“Š All mount IDs: 

[1A[2KğŸ“Š Unique mount IDs: 0

[1A[2KğŸ“Š Remounts during transcription: 0

[1A[2Kâœ… Component remained stable - no excessive remounting detected

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[37/178] [chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ§ª Testing connection closure with extended silence (>10 seconds)...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] 22:04:49 - Agent said: Hello!

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: thinking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from thinking to speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:49 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:49 - Agent state changed: speaking

[1A[2K[BROWSER] 22:04:49 - Audio playback: started

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (398 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:128:3 â€º Callback Test Suite â€º should test onUserStoppedSpeaking callback with existing audio sample
[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (2498 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (2498 bytes)

[1A[2K[BROWSER] âœ… [STREAMING] Audio streaming completed: 21 chunks sent over 2.63s (real-time)

[1A[2Kâœ… onUserStoppedSpeaking callback working - UtteranceEnd detected: Channel: [0,1], Last word end: 1.9200001s

[1A[2Kâœ… User stopped speaking detected: 22:04:48

[1A[2KğŸ“Š Events detected count: [33m2[39m

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[BROWSER] [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging
[LOG] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[LOG] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[38/178] [chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
ğŸ§ª Testing onPlaybackStateChange callback...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] 22:04:49 - Component is not ready

[1A[2K[BROWSER] 22:04:49 - Agent state changed: idle

[1A[2K[BROWSER] 22:04:49 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045889785-0.3704177974559282}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:49 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:49 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:49 - Component is ready

[1A[2K[BROWSER] [vite] connecting...

[1A[2K[BROWSER] [vite] connected.

[1A[2K[BROWSER] %cDownload the React DevTools for a better development experience: https://react.dev/link/react-devtools font-weight:bold

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Creating new IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] About to create IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService constructor - debug: true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService created successfully

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: false, isPlayingChanged: false, isUserSpeakingChanged: false}

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] ğŸ”§ [Component] Proceeding with initialization {isFirstMount: true, needsInitialization: true, isReady: false, transcriptionOptionsChanged: true, agentOptionsChanged: true}

[1A[2K[BROWSER] ğŸ”§ [Component] DeepgramVoiceInteraction initialized {services: transcription + agent, mountId: 1767045889811-0.37519297808237495, isStrictModeReInvoke: false}

[1A[2K[BROWSER] ğŸ”§ [INIT] Service configuration details: {transcriptionOptions: Object, agentOptions: Object, isTranscriptionConfigured: true, isAgentConfigured: true, apiKeyPresent: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription and agent services are configured (managers will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent service is configured (manager will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio manager will be created lazily when audio access is requested

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: undefined, isFirstRender: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] First render - skipping change detection

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isReady changed to false

[1A[2K[BROWSER] 22:04:49 - Component is not ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: agentState changed to idle

[1A[2K[BROWSER] 22:04:49 - Agent state changed: idle

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to false

[1A[2K[BROWSER] 22:04:49 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Destroying IdleTimeoutService (cleanup)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ”§ [Component] useEffect cleanup running {mountId: 1767045889811-0.37519297808237495, transcriptionManagerExists: false, agentManagerExists: false, isMounted: true}

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup stack trace:     at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17482:13)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListUnmount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8500:117)
    at commitHookPassiveUnmountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8519:60)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Creating new IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] About to create IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService constructor - debug: true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService created successfully

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: false, isPlayingChanged: false, isUserSpeakingChanged: false}

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045889811-0.37519297808237495}

[1A[2K[BROWSER] ğŸ”§ [Component] Proceeding with initialization {isFirstMount: false, needsInitialization: true, isReady: false, transcriptionOptionsChanged: true, agentOptionsChanged: true}

[1A[2K[BROWSER] ğŸ”§ [Component] DeepgramVoiceInteraction initialized {services: transcription + agent, mountId: 1767045889812-0.5723119029724728, isStrictModeReInvoke: true}

[1A[2K[BROWSER] ğŸ”§ [INIT] Service configuration details: {transcriptionOptions: Object, agentOptions: Object, isTranscriptionConfigured: true, isAgentConfigured: true, apiKeyPresent: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription and agent services are configured (managers will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent service is configured (manager will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio manager will be created lazily when audio access is requested

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false, connectionState: undefined, isConnected: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:49 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:49 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] ğŸ”§ [Component] useEffect cleanup running {mountId: 1767045889812-0.5723119029724728, transcriptionManagerExists: false, agentManagerExists: false, isMounted: true}

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup stack trace:     at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17482:13)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListUnmount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8500:117)
    at commitHookPassiveUnmountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8519:60)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045889812-0.5723119029724728}

[1A[2K[BROWSER] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false, connectionState: undefined, isConnected: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isReady changed to true

[1A[2K[BROWSER] 22:04:49 - Component is ready

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:13:3 â€º Diagnostic VAD Tests â€º should provide detailed logging for manual debugging

ğŸ“Š DIAGNOSTIC SUMMARY:

[1A[2KVAD Events found: [33m2[39m

[1A[2K  - VAD: utterance_end_ms set to 1000ms

[1A[2K  - VAD: interim_results set to true

[1A[2K
AudioContext Events found: [33m102[39m

[1A[2K  - ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K  - [AudioManager] [queueAudio] AudioContext state: running

[1A[2K
Settings Events found: [33m38[39m

[1A[2K  - ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K  - ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K  - [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K  - ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K  - ğŸ”§ [sendAgentSettings] Called

[1A[2K  - ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K  - ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K  - ğŸ”§ [sendAgentSettings] agentOptions.functions: undefined

[1A[2K  - ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 0

[1A[2K  - ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K  - ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: false

[1A[2K  - ğŸ”§ [sendAgentSettings] Settings message sent, waiting for SettingsApplied confirmation

[1A[2K  - ğŸ” [DEBUG] Full Settings message structure: {
  "type": "Settings",
  "audio": {
    "input": {
      "encoding": "linear16",
      "sample_rate": 16000
    },
    "output": {
      "encoding": "linear16",
      "sample_rate": 24000
    }
  },
  "agent": {
    "language": "en",
    "think": {
      "provider": {
        "type": "open_ai",
        "model": "gpt-4o-mini"
      },
      "prompt": "You are a helpful voice assistant. Keep your responses concise and informative."
    },
    "speak": {
      "provider": {
        "type": "deepgram",
        "model": "aura-asteria-en"
      }
    },
    "greeting": "Hello! How can I assist you today?"
  }
}

[1A[2K  - ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K  - ğŸ“¤ [Component] Settings message type: Settings

[1A[2K  - ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: Settings

[1A[2K  - ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=Settings, isSettings=true

[1A[2K  - ğŸ“¤ [WEBSOCKET.sendJSON] âœ… ENTERED Settings block!

[1A[2K  - ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Settings message detected!

[1A[2K  - ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (exact JSON string): {"type":"Settings","audio":{"input":{"encoding":"linear16","sample_rate":16000},"output":{"encoding":"linear16","sample_rate":24000}},"agent":{"language":"en","think":{"provider":{"type":"open_ai","model":"gpt-4o-mini"},"prompt":"You are a helpful voice assistant. Keep your responses concise and informative."},"speak":{"provider":{"type":"deepgram","model":"aura-asteria-en"}},"greeting":"Hello! How can I assist you today?"}}

[1A[2K  - ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (parsed): {type: Settings, audio: Object, agent: Object}

[1A[2K  - [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K  - [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K  - ğŸ”§ [sendAgentSettings] Flags set immediately after successful send (StrictMode protection)

[1A[2K  - ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K  - ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K  - [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K  - [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K  - [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K  - [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: SettingsApplied): {type: SettingsApplied}

[1A[2K  - âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K  - [DeepgramVoiceInteraction] SettingsApplied received - settings are now active

[1A[2K  - ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K  - 22:04:45 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K  - [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K  - ğŸµ [sendAudioData] hasSentSettingsRef.current: true

[1A[2K  - ğŸµ [sendAudioData] state.hasSentSettings: true

[1A[2K  - ğŸµ [sendAudioData] âœ… Settings confirmed, sending to agent service

[1A[2K
Final mic status: Enabled

[1A[2KFinal connection status: connected

[1A[2Kâœ… Diagnostic test completed

[1A[2K[39/178] [chromium] â€º tests/e2e/diagnostic-vad.spec.js:133:3 â€º Diagnostic VAD Tests â€º should track WebSocket connection timing
[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[BROWSER] ğŸ”§ [Component] Cleanup detected StrictMode re-invocation - preserving connections and state

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[BROWSER] âœ… AudioContext already running

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
ğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2KğŸµ Loading proven audio sample with extended silence...

[1A[2KğŸ“Š Audio sample info: {
  phrase: [32m'Hello there'[39m,
  sampleRate: [33m16000[39m,
  totalDuration: [33m2.87025[39m,
  speechDuration: [90mundefined[39m,
  audioDataLength: [33m91848[39m
}

[1A[2Kâ³ Waiting for audio to be processed...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[BROWSER] ğŸ¤ [APP] toggleMicrophone called

[1A[2K[BROWSER] ğŸ¤ [APP] micEnabled: false

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K[BROWSER] 22:04:50 - Starting audio capture (lazy initialization)

[1A[2K[BROWSER] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K[BROWSER] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K[BROWSER] 22:04:50 - Starting agent and transcription services...

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Start method called with options: {"agent":true,"transcription":true}

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] start() - Fresh connection detected, resetting allowAgentRef from true to true

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”„ Fresh connection starting - resetting audio blocking state

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Service start flags: transcription=true, agent=true

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Creating transcription manager lazily...

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”§ [TRANSCRIPTION] Creating transcription manager lazily

[1A[2K[BROWSER] VAD: utterance_end_ms set to 1000ms

[1A[2K[BROWSER] VAD: interim_results set to true

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Not using keyterm prompting. Building queryParams object excluding array types.

[1A[2K[BROWSER] [WebSocketManager:transcription] WebSocketManager created

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Creating agent manager lazily...

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”§ [AGENT] Creating agent manager lazily

[1A[2K[BROWSER] ğŸ”§ [AGENT] Creating WebSocketManager with URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K[BROWSER] ğŸ”§ [AGENT] Connection mode: direct

[1A[2K[BROWSER] ğŸ”§ [AGENT] Proxy endpoint: undefined

[1A[2K[BROWSER] ğŸ”§ [AGENT] API key present: true

[1A[2K[BROWSER] ğŸ”§ [AGENT] Auth token present: false

[1A[2K[BROWSER] [WebSocketManager:agent] WebSocketManager created

[1A[2K[BROWSER] [DeepgramVoiceInteraction] AudioManager not configured, skipping initialization

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K[BROWSER] [WebSocketManager:transcription] Connecting to WebSocket...

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Transcription state event: connecting Previous: undefined

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription state: connecting

[1A[2K[BROWSER] 22:04:50 - transcription connection state: connecting

[1A[2K[BROWSER] [WebSocketManager:transcription] Built URL with params: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] [WebSocketManager:transcription] Connecting to wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] URL: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Service: transcription

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K[BROWSER] [WebSocketManager:transcription] Initial readyState: 0

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:133:3 â€º Diagnostic VAD Tests â€º should track WebSocket connection timing
ğŸ” Starting WebSocket timing test...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[BROWSER] [WebSocketManager:transcription] WebSocket connected

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Transcription state event: connected Previous: connecting

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription state: connected

[1A[2K[BROWSER] 22:04:51 - transcription connection state: connected

[1A[2K[BROWSER] ğŸ”§ [TRANSCRIPTION] Starting periodic keepalive audio to prevent timeout

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[BROWSER] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K[BROWSER] [WebSocketManager:agent] Connecting to WebSocket...

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connecting Previous: undefined

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent state: connecting

[1A[2K[BROWSER] 22:04:51 - agent connection state: connecting

[1A[2K[BROWSER] [WebSocketManager:agent] Built URL with params: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] [WebSocketManager:agent] Connecting to wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Service: agent

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K[BROWSER] [WebSocketManager:agent] Initial readyState: 0

[1A[2K[WebServer] [Proxy] Deepgram transcription connection closed: 1001 

[1A[2K[WebServer] [Proxy] Deepgram transcription connection closed: 1001 

[1A[2K[BROWSER] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K[BROWSER] ğŸ”§ [TRANSCRIPTION] Periodic keepalive audio sent

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:138:3 â€º Echo Cancellation Detection and Configuration â€º should apply custom audio constraints when provided
âš ï¸ Constraints not captured (likely due to mocks), but verifying code path

[1A[2Kâœ… Custom constraints code path executed (mic enabled successfully)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[BROWSER] [WebSocketManager:agent] WebSocket connected

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connected Previous: connecting

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent state: connected

[1A[2K[BROWSER] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent WebSocket connected for first time

[1A[2K[BROWSER] 22:04:51 - agent connection state: connected

[1A[2K[BROWSER] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K[BROWSER] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[BROWSER] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] AudioManager not available - this is expected for text-only agent interactions

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Start method completed successfully

[1A[2K[BROWSER] ğŸ¤ [APP] Services started (or already connected)

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K[BROWSER] [DeepgramVoiceInteraction] startAudioCapture called - initializing audio manager lazily

[1A[2K[BROWSER] [AudioManager] AudioManager created

[1A[2K[BROWSER] [AudioManager] Initializing AudioManager

[1A[2K[BROWSER] [AudioManager] Created audio analyzer for volume normalization

[1A[2K[BROWSER] [AudioManager] Created Object URL for AudioWorklet: blob:http://localhost:5173/57fa4c99-c4a4-408b-9b36-051034c4e45a

[1A[2K[BROWSER] ğŸ¤ [MOCK] AudioWorklet.addModule called - simulating success

[1A[2K[BROWSER] [AudioManager] AudioWorklet loaded using Object URL

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio manager ready

[1A[2K[BROWSER] [AudioManager] Revoking Object URL: blob:http://localhost:5173/57fa4c99-c4a4-408b-9b36-051034c4e45a

[1A[2K[BROWSER] [DeepgramVoiceInteraction] AudioManager initialized

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent service already connected, skipping connection

[1A[2K[BROWSER] [AudioManager] Requesting microphone access

[1A[2K[BROWSER] ğŸ¤ [MOCK] getUserMedia called - returning mock MediaStream

[1A[2K[BROWSER] [AudioManager] Echo cancellation support: {supported: true, active: false, browser: Chrome, version: 141, limitations: Array(1)}

[1A[2K[BROWSER] [AudioManager] âš ï¸ Echo cancellation requested but not active

[1A[2K[BROWSER] ğŸ¤ [MOCK] createMediaStreamSource called - simulating success

[1A[2K[BROWSER] ğŸ¤ [MOCK] AudioWorkletNode constructor called - simulating success

[1A[2K[BROWSER] ğŸ¤ [MOCK] AudioWorkletNode port.postMessage called with: {type: start}

[1A[2K[BROWSER] [AudioManager] Recording started

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Started polling for idle timeout conditions

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=startAudioCapture, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout started with timeoutId: 14

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio capture started successfully

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K[BROWSER] 22:04:51 - Audio capture started successfully

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Welcome","request_id":"b25efef4-05ca-4456-83d6-15cb71da7207"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Welcome, request_id: b25efef4-05ca-4456-83d6-15cb71da7207}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Welcome

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: Welcome): {type: Welcome, request_id: b25efef4-05ca-4456-83d6-15cb71da7207}

[1A[2K[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Welcome message received - dual mode connection established

[1A[2K[BROWSER] [DeepgramVoiceInteraction] New connection - triggering greeting flow

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Welcome

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[40/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:227:3 â€º Echo Cancellation Detection and Configuration â€º should verify microphone remains active during agent playback
[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[WebServer] [Proxy] Deepgram transcription connection closed: 1001 

[1A[2K[BROWSER] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K[BROWSER] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Called

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions: undefined

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 0

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Settings message sent, waiting for SettingsApplied confirmation

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[BROWSER] ğŸ” [DEBUG] Full Settings message structure: {
  "type": "Settings",
  "audio": {
    "input": {
      "encoding": "linear16",
      "sample_rate": 16000
    },
    "output": {
      "encoding": "linear16",
      "sample_rate": 24000
    }
  },
  "agent": {
    "language": "en",
    "think": {
      "provider": {
        "type": "open_ai",
        "model": "gpt-4o-mini"
      },
      "prompt": "You are a helpful voice assistant. Keep your responses concise and informative."
    },
    "speak": {
      "provider": {
        "type": "deepgram",
        "model": "aura-asteria-en"
      }
    },
    "greeting": "Hello! How can I assist you today?"
  }
}

[1A[2K[BROWSER] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[BROWSER] ğŸ“¤ [Component] Has functions? false

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K[BROWSER] ğŸ“¤ [Component] Before sendJSON call:

[1A[2K[BROWSER] ğŸ“¤ [Component] - agentManagerRef.current exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: Settings

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=Settings, isSettings=true

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… ENTERED Settings block!

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Setting window variables...

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Window variables set successfully

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Settings message detected!

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (exact JSON string): {"type":"Settings","audio":{"input":{"encoding":"linear16","sample_rate":16000},"output":{"encoding":"linear16","sample_rate":24000}},"agent":{"language":"en","think":{"provider":{"type":"open_ai","model":"gpt-4o-mini"},"prompt":"You are a helpful voice assistant. Keep your responses concise and informative."},"speak":{"provider":{"type":"deepgram","model":"aura-asteria-en"}},"greeting":"Hello! How can I assist you today?"}}

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (parsed): {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K[BROWSER] [WebSocketManager:agent] Started keepalive interval

[1A[2K[BROWSER] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Flags set immediately after successful send (StrictMode protection)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: SettingsApplied): {type: SettingsApplied}

[1A[2K[BROWSER] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[BROWSER] [DeepgramVoiceInteraction] SettingsApplied received - settings are now active

[1A[2K[BROWSER] ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K[BROWSER] 22:04:51 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"ConversationText","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: ConversationText

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: ConversationText): {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] ğŸ’¬ [AGENT EVENT] ConversationText received role= assistant

[1A[2K[BROWSER] 22:04:51 - Agent said: Hello! How can I assist you today?

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: ConversationText

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"History","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: History

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: History): {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: History

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045889812-0.5723119029724728}

[1A[2K[BROWSER] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connected, isConnected: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true}

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 0, startTimeRef.current = 0

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.112 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 1

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Playing state: true

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from idle to speaking

[1A[2K[BROWSER] [SLEEP_CYCLE][CORE] Dispatching AGENT_STATE_CHANGE to speaking (from playback start, previous state: idle)

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:51 - Agent state changed: speaking

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 1, startTimeRef.current = 0.132

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.132s, current time: 0.112s, active sources: 1

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 1, startTimeRef.current = 0.132

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.132 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 2

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 2, startTimeRef.current = 0.152

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.152s, current time: 0.112s, active sources: 2

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 2, startTimeRef.current = 0.152

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.152 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 3

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 3, startTimeRef.current = 0.172

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.172s, current time: 0.112s, active sources: 3

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 3, startTimeRef.current = 0.172

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.172 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 4

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 4, startTimeRef.current = 0.19199999999999998

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.192s, current time: 0.112s, active sources: 4

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 4, startTimeRef.current = 0.19199999999999998

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.19199999999999998 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 5

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 5, startTimeRef.current = 0.21199999999999997

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.212s, current time: 0.112s, active sources: 5

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 5, startTimeRef.current = 0.21199999999999997

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.21199999999999997 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 6

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 6, startTimeRef.current = 0.23199999999999996

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.232s, current time: 0.112s, active sources: 6

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 6, startTimeRef.current = 0.23199999999999996

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.23199999999999996 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 7

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 7, startTimeRef.current = 0.25199999999999995

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.252s, current time: 0.112s, active sources: 7

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 7, startTimeRef.current = 0.25199999999999995

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.25199999999999995 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 8

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 8, startTimeRef.current = 0.27199999999999996

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.272s, current time: 0.112s, active sources: 8

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: true, isPlayingChanged: true, isUserSpeakingChanged: false}

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting AGENT_STATE_CHANGED: idle -> speaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: 14

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 14

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout cleared successfully

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting PLAYBACK_STATE_CHANGED: false -> true

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: agentState changed to speaking

[1A[2K[BROWSER] 22:04:51 - Agent state changed: speaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to true

[1A[2K[BROWSER] 22:04:51 - Audio playback: started

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 8, startTimeRef.current = 0.27199999999999996

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.27199999999999996 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 9

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 9, startTimeRef.current = 0.292

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.292s, current time: 0.128s, active sources: 9

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 9, startTimeRef.current = 0.292

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.292 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 10

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 10, startTimeRef.current = 0.312

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.312s, current time: 0.128s, active sources: 10

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 9

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:227:3 â€º Echo Cancellation Detection and Configuration â€º should verify microphone remains active during agent playback
ğŸ” Testing microphone stays active during playback (barge-in preservation)...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:178:3 â€º Callback Test Suite â€º should test onPlaybackStateChange callback with agent response
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 9, startTimeRef.current = 0.312

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.312 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 10

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 10, startTimeRef.current = 0.332

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.332s, current time: 0.144s, active sources: 10

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 10, startTimeRef.current = 0.332

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.332 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 11

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 11, startTimeRef.current = 0.35200000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.352s, current time: 0.144s, active sources: 11

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 11, startTimeRef.current = 0.35200000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.35200000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 12

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 12, startTimeRef.current = 0.37200000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.372s, current time: 0.144s, active sources: 12

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 12, startTimeRef.current = 0.37200000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.37200000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 13

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 13, startTimeRef.current = 0.39200000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.392s, current time: 0.144s, active sources: 13

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 13, startTimeRef.current = 0.39200000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.39200000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 14

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 14, startTimeRef.current = 0.4120000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.412s, current time: 0.144s, active sources: 14

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 14, startTimeRef.current = 0.4120000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4120000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 15

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 15, startTimeRef.current = 0.4320000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.432s, current time: 0.144s, active sources: 15

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 15, startTimeRef.current = 0.4320000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4320000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 16

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 16, startTimeRef.current = 0.4520000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.452s, current time: 0.144s, active sources: 16

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 16, startTimeRef.current = 0.4520000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4520000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 17

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 17, startTimeRef.current = 0.47200000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.472s, current time: 0.144s, active sources: 17

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 17, startTimeRef.current = 0.47200000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.47200000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 18

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 18, startTimeRef.current = 0.49200000000000016

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.492s, current time: 0.144s, active sources: 18

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 18, startTimeRef.current = 0.49200000000000016

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4920000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 19

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 19, startTimeRef.current = 0.5120000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.512s, current time: 0.144s, active sources: 19

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 19, startTimeRef.current = 0.5120000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5120000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 20

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 20, startTimeRef.current = 0.5320000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.532s, current time: 0.144s, active sources: 20

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 20, startTimeRef.current = 0.5320000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5320000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 21

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 21, startTimeRef.current = 0.5520000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.552s, current time: 0.144s, active sources: 21

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 21, startTimeRef.current = 0.5520000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5520000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 22

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 22, startTimeRef.current = 0.5720000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.572s, current time: 0.144s, active sources: 22

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 22, startTimeRef.current = 0.5720000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5720000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 23

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 23, startTimeRef.current = 0.5920000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.592s, current time: 0.144s, active sources: 23

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 23, startTimeRef.current = 0.5920000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5920000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 24

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 24, startTimeRef.current = 0.6120000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.612s, current time: 0.144s, active sources: 24

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 24, startTimeRef.current = 0.6120000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6120000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 25

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 25, startTimeRef.current = 0.6320000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.632s, current time: 0.144s, active sources: 25

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 25, startTimeRef.current = 0.6320000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6320000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 26

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 26, startTimeRef.current = 0.6520000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.652s, current time: 0.144s, active sources: 26

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 26, startTimeRef.current = 0.6520000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6520000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 27

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 27, startTimeRef.current = 0.6720000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.672s, current time: 0.144s, active sources: 27

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 27, startTimeRef.current = 0.6720000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6720000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 28

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 28, startTimeRef.current = 0.6920000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.692s, current time: 0.144s, active sources: 28

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 28, startTimeRef.current = 0.6920000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6920000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 29

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 29, startTimeRef.current = 0.7120000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.712s, current time: 0.144s, active sources: 29

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 29, startTimeRef.current = 0.7120000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7120000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 30

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 30, startTimeRef.current = 0.7320000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.732s, current time: 0.144s, active sources: 30

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 30, startTimeRef.current = 0.7320000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7320000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 31

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 31, startTimeRef.current = 0.7520000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.752s, current time: 0.144s, active sources: 31

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 31, startTimeRef.current = 0.7520000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7520000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 32

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 32, startTimeRef.current = 0.7720000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.772s, current time: 0.144s, active sources: 32

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 32, startTimeRef.current = 0.7720000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7720000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 33

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 33, startTimeRef.current = 0.7920000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.792s, current time: 0.144s, active sources: 33

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 32

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 32, startTimeRef.current = 0.7920000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7920000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 33

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 33, startTimeRef.current = 0.8120000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.812s, current time: 0.165s, active sources: 33

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 33, startTimeRef.current = 0.8120000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8120000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 34

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 34, startTimeRef.current = 0.8320000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.832s, current time: 0.165s, active sources: 34

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 34, startTimeRef.current = 0.8320000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8320000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 35

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 35, startTimeRef.current = 0.8520000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.852s, current time: 0.165s, active sources: 35

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 35, startTimeRef.current = 0.8520000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8520000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 36

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 36, startTimeRef.current = 0.8720000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.872s, current time: 0.165s, active sources: 36

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 36, startTimeRef.current = 0.8720000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8720000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 37

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 37, startTimeRef.current = 0.8920000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.892s, current time: 0.165s, active sources: 37

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 37, startTimeRef.current = 0.8920000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8920000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 38

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 38, startTimeRef.current = 0.9120000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.912s, current time: 0.165s, active sources: 38

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 38, startTimeRef.current = 0.9120000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9120000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 39

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 39, startTimeRef.current = 0.9320000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.932s, current time: 0.171s, active sources: 39

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 39, startTimeRef.current = 0.9320000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9320000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 40

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 40, startTimeRef.current = 0.9520000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.952s, current time: 0.171s, active sources: 40

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 40, startTimeRef.current = 0.9520000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9520000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 41

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 41, startTimeRef.current = 0.9720000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.972s, current time: 0.171s, active sources: 41

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 40

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 40, startTimeRef.current = 0.9720000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9720000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 41

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 41, startTimeRef.current = 0.9920000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.992s, current time: 0.187s, active sources: 41

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 41, startTimeRef.current = 0.9920000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9920000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 42

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 42, startTimeRef.current = 1.0120000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.012s, current time: 0.187s, active sources: 42

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 42, startTimeRef.current = 1.0120000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0120000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 43

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 43, startTimeRef.current = 1.0320000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.032s, current time: 0.187s, active sources: 43

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 43, startTimeRef.current = 1.0320000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0320000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 44

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 44, startTimeRef.current = 1.0520000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.052s, current time: 0.187s, active sources: 44

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 44, startTimeRef.current = 1.0520000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0520000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 45

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 45, startTimeRef.current = 1.0720000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.072s, current time: 0.187s, active sources: 45

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 45, startTimeRef.current = 1.0720000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0720000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 46

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 46, startTimeRef.current = 1.0920000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.092s, current time: 0.187s, active sources: 46

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 46, startTimeRef.current = 1.0920000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0920000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 47

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 47, startTimeRef.current = 1.1120000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.112s, current time: 0.187s, active sources: 47

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 47, startTimeRef.current = 1.1120000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1120000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 48

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 48, startTimeRef.current = 1.1320000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.132s, current time: 0.187s, active sources: 48

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 48, startTimeRef.current = 1.1320000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1320000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 49

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 49, startTimeRef.current = 1.1520000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.152s, current time: 0.187s, active sources: 49

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 49, startTimeRef.current = 1.1520000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1520000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 50

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 50, startTimeRef.current = 1.1720000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.172s, current time: 0.187s, active sources: 50

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 50, startTimeRef.current = 1.1720000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1720000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 51

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 51, startTimeRef.current = 1.1920000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.192s, current time: 0.187s, active sources: 51

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 51, startTimeRef.current = 1.1920000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1920000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 52

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 52, startTimeRef.current = 1.2120000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.212s, current time: 0.187s, active sources: 52

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 52, startTimeRef.current = 1.2120000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2120000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 53

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 53, startTimeRef.current = 1.2320000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.232s, current time: 0.187s, active sources: 53

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 53, startTimeRef.current = 1.2320000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2320000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 54

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 54, startTimeRef.current = 1.2520000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.252s, current time: 0.187s, active sources: 54

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 54, startTimeRef.current = 1.2520000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2520000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 55

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 55, startTimeRef.current = 1.2720000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.272s, current time: 0.187s, active sources: 55

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 55, startTimeRef.current = 1.2720000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2720000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 56

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 56, startTimeRef.current = 1.2920000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.292s, current time: 0.192s, active sources: 56

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 56, startTimeRef.current = 1.2920000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2920000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 57

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 57, startTimeRef.current = 1.3120000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.312s, current time: 0.192s, active sources: 57

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 57, startTimeRef.current = 1.3120000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3120000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 58

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 58, startTimeRef.current = 1.3320000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.332s, current time: 0.192s, active sources: 58

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 58, startTimeRef.current = 1.3320000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3320000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 59

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 59, startTimeRef.current = 1.3520000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.352s, current time: 0.192s, active sources: 59

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 59, startTimeRef.current = 1.3520000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3520000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 60

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 60, startTimeRef.current = 1.3720000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.372s, current time: 0.192s, active sources: 60

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 60, startTimeRef.current = 1.3720000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3720000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 61

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 61, startTimeRef.current = 1.3920000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.392s, current time: 0.192s, active sources: 61

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 61, startTimeRef.current = 1.3920000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3920000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 62

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 62, startTimeRef.current = 1.4120000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.412s, current time: 0.192s, active sources: 62

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 62, startTimeRef.current = 1.4120000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4120000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 63

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 63, startTimeRef.current = 1.4320000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.432s, current time: 0.192s, active sources: 63

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 63, startTimeRef.current = 1.4320000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4320000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 64

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 64, startTimeRef.current = 1.4520000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.452s, current time: 0.192s, active sources: 64

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 64, startTimeRef.current = 1.4520000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4520000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 65

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 65, startTimeRef.current = 1.4720000000000009

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.472s, current time: 0.192s, active sources: 65

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 65, startTimeRef.current = 1.4720000000000009

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4720000000000009 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 66

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 66, startTimeRef.current = 1.4920000000000009

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.492s, current time: 0.192s, active sources: 66

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 66, startTimeRef.current = 1.4920000000000009

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4920000000000009 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 67

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 67, startTimeRef.current = 1.512000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.512s, current time: 0.192s, active sources: 67

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 67, startTimeRef.current = 1.512000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.512000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 68

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 68, startTimeRef.current = 1.532000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.532s, current time: 0.192s, active sources: 68

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 68, startTimeRef.current = 1.532000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.532000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 69

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 69, startTimeRef.current = 1.552000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.552s, current time: 0.192s, active sources: 69

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 69, startTimeRef.current = 1.552000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.552000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 70

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 70, startTimeRef.current = 1.572000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.572s, current time: 0.192s, active sources: 70

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 70, startTimeRef.current = 1.572000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.572000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 71

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 71, startTimeRef.current = 1.592000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.592s, current time: 0.192s, active sources: 71

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 71, startTimeRef.current = 1.592000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.592000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 72

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 72, startTimeRef.current = 1.612000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.612s, current time: 0.192s, active sources: 72

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 72, startTimeRef.current = 1.612000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.612000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 73

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 73, startTimeRef.current = 1.632000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.632s, current time: 0.192s, active sources: 73

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 73, startTimeRef.current = 1.632000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.632000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 74

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 74, startTimeRef.current = 1.652000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.652s, current time: 0.192s, active sources: 74

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[41/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:117:5 â€º Declarative Props API - Issue #305 â€º userMessage prop (replaces injectUserMessage) â€º should clear userMessage after onUserMessageSent is called
[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 74, startTimeRef.current = 1.652000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.652000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 75

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 75, startTimeRef.current = 1.672000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.672s, current time: 0.192s, active sources: 75

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 75, startTimeRef.current = 1.672000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.672000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 76

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 76, startTimeRef.current = 1.692000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.692s, current time: 0.192s, active sources: 76

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 76, startTimeRef.current = 1.692000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.692000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 77

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 77, startTimeRef.current = 1.712000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.712s, current time: 0.192s, active sources: 77

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 77, startTimeRef.current = 1.712000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.712000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 78

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 78, startTimeRef.current = 1.732000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.732s, current time: 0.192s, active sources: 78

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 78, startTimeRef.current = 1.732000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.732000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 79

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 79, startTimeRef.current = 1.7520000000000011

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.752s, current time: 0.192s, active sources: 79

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 79, startTimeRef.current = 1.7520000000000011

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.7520000000000011 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 80

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 80, startTimeRef.current = 1.7720000000000011

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.772s, current time: 0.197s, active sources: 80

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 80, startTimeRef.current = 1.7720000000000011

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.7720000000000011 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 81

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 81, startTimeRef.current = 1.7920000000000011

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.792s, current time: 0.197s, active sources: 81

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 80

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 80, startTimeRef.current = 1.7920000000000011

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.7920000000000011 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 81

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 81, startTimeRef.current = 1.8120000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.812s, current time: 0.203s, active sources: 81

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 81, startTimeRef.current = 1.8120000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8120000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 82

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 82, startTimeRef.current = 1.8320000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.832s, current time: 0.203s, active sources: 82

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 82, startTimeRef.current = 1.8320000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8320000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 83

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 83, startTimeRef.current = 1.8520000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.852s, current time: 0.203s, active sources: 83

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 83, startTimeRef.current = 1.8520000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8520000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 84

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 84, startTimeRef.current = 1.8720000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.872s, current time: 0.203s, active sources: 84

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 84, startTimeRef.current = 1.8720000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8720000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 85

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 85, startTimeRef.current = 1.8920000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.892s, current time: 0.203s, active sources: 85

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 85, startTimeRef.current = 1.8920000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8920000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 86

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 86, startTimeRef.current = 1.9120000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.912s, current time: 0.203s, active sources: 86

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 86, startTimeRef.current = 1.9120000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9120000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 87

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 87, startTimeRef.current = 1.9320000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.932s, current time: 0.203s, active sources: 87

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 87, startTimeRef.current = 1.9320000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9320000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 88

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 88, startTimeRef.current = 1.9520000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.952s, current time: 0.203s, active sources: 88

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 88, startTimeRef.current = 1.9520000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9520000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 89

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 89, startTimeRef.current = 1.9720000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.972s, current time: 0.203s, active sources: 89

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 89, startTimeRef.current = 1.9720000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9720000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 90

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 90, startTimeRef.current = 1.9920000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.992s, current time: 0.208s, active sources: 90

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 90, startTimeRef.current = 1.9920000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9920000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 91

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 91, startTimeRef.current = 2.0120000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.012s, current time: 0.208s, active sources: 91

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 91, startTimeRef.current = 2.0120000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0120000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 92

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 92, startTimeRef.current = 2.0320000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.032s, current time: 0.208s, active sources: 92

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 92, startTimeRef.current = 2.0320000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0320000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 93

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 93, startTimeRef.current = 2.0520000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.052s, current time: 0.208s, active sources: 93

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 93, startTimeRef.current = 2.0520000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0520000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 94

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 94, startTimeRef.current = 2.0720000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.072s, current time: 0.208s, active sources: 94

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 408), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"AgentAudioDone"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: AgentAudioDone}

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout started with timeoutId: 20

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: AgentAudioDone

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: AgentAudioDone): {type: AgentAudioDone}

[1A[2K[BROWSER] ğŸ”Š [AGENT EVENT] AgentAudioDone received

[1A[2K[BROWSER] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue

[1A[2K[BROWSER] [SLEEP_CYCLE][CORE] AgentAudioDone received - audio generation complete, but playback may continue

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: AgentAudioDone

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 93

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 93, startTimeRef.current = 2.0720000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0720000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 94

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 94, startTimeRef.current = 2.0920000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.092s, current time: 0.213s, active sources: 94

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 94, startTimeRef.current = 2.0920000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0920000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 95

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 95, startTimeRef.current = 2.1120000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.112s, current time: 0.213s, active sources: 95

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 408), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 408

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 408 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 408 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (408 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 95, startTimeRef.current = 2.1120000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.009s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.1120000000000014 (duration: 0.0085)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 96

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 96, startTimeRef.current = 2.1205000000000016

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.121s, current time: 0.213s, active sources: 96

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 95

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 94

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 93

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 92

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 91

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 90

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 89

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 88

[1A[2K[BROWSER] 22:04:51 - Sending text message: Hello, can you help me?

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent manager already exists, reusing

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Manager reference stored, state: connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent manager already connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Injecting user message: Hello, can you help me? - WebSocket state: connected

[1A[2K[BROWSER] ğŸ“ [TEXT_MESSAGE] Attempting to send: Hello, can you help me? - Connection state: connected

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: InjectUserMessage

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=InjectUserMessage, isSettings=false

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] NOT a Settings message, skipping

[1A[2K[BROWSER] [WebSocketManager:agent] Sending JSON: {type: InjectUserMessage, content: Hello, can you help me?}

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=InjectUserMessage, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: InjectUserMessage)

[1A[2K[BROWSER] ğŸ“ [TEXT_MESSAGE] Message sent successfully

[1A[2K[BROWSER] [DeepgramVoiceInteraction] User message sent successfully

[1A[2K[BROWSER] 22:04:51 - Text message sent to Deepgram agent

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 87

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UserStartedSpeaking"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UserStartedSpeaking}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UserStartedSpeaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: UserStartedSpeaking): {type: UserStartedSpeaking}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ¤ [VAD] UserStartedSpeaking message received

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Clearing audio queue (barge-in)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ“¢ clearAudio helper called

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”´ Calling audioManager.clearAudioQueue()

[1A[2K[BROWSER] [AudioManager] ğŸš¨ CLEARING AUDIO QUEUE - EMERGENCY STOP ğŸš¨

[1A[2K[BROWSER] [AudioManager] [clearAudioQueue] Before: activeSourceNodes.length = 87, startTimeRef.current = 2.1205000000000016

[1A[2K[BROWSER] [AudioManager] â±ï¸ Reset timing reference from 2.121s to 0.411s

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Attempting to stop 87 active audio sources

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 1/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 1 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 2/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 2 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 3/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 3 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 4/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 4 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 5/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 5 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 6/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 6 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 7/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 7 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 8/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 8 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 9/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 9 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 10/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 10 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 11/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 11 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 12/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 12 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 13/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 13 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 14/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 14 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 15/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 15 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 16/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 16 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 17/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 17 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 18/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 18 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 19/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 19 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 20/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 20 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 21/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 21 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 22/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 22 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 23/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 23 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 24/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 24 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 25/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 25 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 26/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 26 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 27/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 27 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 28/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 28 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 29/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 29 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 30/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 30 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 31/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 31 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 32/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 32 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 33/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 33 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 34/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 34 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 35/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 35 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 36/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 36 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 37/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 37 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 38/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 38 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 39/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 39 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 40/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 40 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 41/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 41 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 42/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 42 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 43/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 43 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 44/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 44 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 45/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 45 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 46/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 46 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 47/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 47 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 48/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 48 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 49/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 49 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 50/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 50 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 51/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 51 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 52/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 52 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 53/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 53 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 54/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 54 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 55/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 55 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 56/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 56 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 57/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 57 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 58/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 58 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 59/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 59 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 60/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 60 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 61/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 61 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 62/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 62 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 63/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 63 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 64/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 64 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 65/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 65 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 66/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 66 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 67/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 67 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 68/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 68 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 69/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 69 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 70/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 70 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 71/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 71 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 72/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 72 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 73/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 73 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 74/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 74 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 75/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 75 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 76/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 76 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 77/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 77 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 78/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 78 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 79/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 79 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 80/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 80 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 81/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 81 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 82/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 82 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 83/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 83 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 84/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 84 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 85/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 85 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 86/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 86 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Stopping source 87/87

[1A[2K[BROWSER] [AudioManager] âœ… Source 87 stopped and disconnected

[1A[2K[BROWSER] [AudioManager] ğŸ§¹ Cleared 87 active sources from tracking array

[1A[2K[BROWSER] [AudioManager] ğŸ§¹ Cleared currentSource reference

[1A[2K[BROWSER] [AudioManager] ğŸ”‡ Set isPlaying state to false (was: true)

[1A[2K[BROWSER] [AudioManager] ğŸ“¢ Emitting playing=false event

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Playing state: false

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: NOT PLAYING, current agent state: speaking

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback finished - transitioning agent from speaking to idle

[1A[2K[BROWSER] [SLEEP_CYCLE][CORE] Audio playback finished - transitioning agent to idle

[1A[2K[BROWSER] [AudioManager] ğŸ”„ Attempting to flush the audio context

[1A[2K[BROWSER] [AudioManager] [clearAudioQueue] After: activeSourceNodes.length = 0, startTimeRef.current = 0.4106666666666667

[1A[2K[BROWSER] [AudioManager] âœ… Audio queue cleared, all playback should have stopped

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”„ Manipulating audio context time reference

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ“¢ clearAudio helper completed

[1A[2K[BROWSER] 22:04:51 - ğŸ¤ [AGENT] User started speaking at 22:04:51

[1A[2K[BROWSER] ğŸ¯ [AGENT] UserStartedSpeaking from agent service - setting isUserSpeaking=true

[1A[2K[BROWSER] ğŸ¤– [AgentStateService] State transition: idle â†’ listening (User started speaking)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UserStartedSpeaking

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"ConversationText","role":"user","content":"Hello, can you help me?"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: ConversationText, role: user, content: Hello, can you help me?}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: ConversationText

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: ConversationText): {type: ConversationText, role: user, content: Hello, can you help me?}

[1A[2K[BROWSER] ğŸ’¬ [AGENT EVENT] ConversationText received role= user

[1A[2K[BROWSER] 22:04:51 - User message from server: Hello, can you help me?

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: ConversationText

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"History","role":"user","content":"Hello, can you help me?"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: History, role: user, content: Hello, can you help me?}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: History

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: History): {type: History, role: user, content: Hello, can you help me?}

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: History

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: true, isPlayingChanged: true, isUserSpeakingChanged: true}

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting USER_STARTED/STOPPED_SPEAKING event

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STARTED_SPEAKING

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STARTED_SPEAKING

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: 20

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 20

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout cleared successfully

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting AGENT_STATE_CHANGED: speaking -> listening

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=listening, isPlaying=false, isUserSpeaking=true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: true, agentState: listening, isPlaying: false, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting PLAYBACK_STATE_CHANGED: true -> false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=listening, isUserSpeaking=true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: true, agentState: listening, isPlaying: false, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=listening, isPlaying=false, isUserSpeaking=true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: true, agentState: listening, isPlaying: false, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: agentState changed to listening

[1A[2K[BROWSER] 22:04:51 - Agent state changed: listening

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to false

[1A[2K[BROWSER] 22:04:51 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045889812-0.5723119029724728}

[1A[2K[BROWSER] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connected, isConnected: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true}

[1A[2Kâœ… onPlaybackStateChange callback working - audio status changed from true to false

[1A[2K[42/178] [chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
ğŸ§ª Testing comprehensive callback integration...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] 22:04:51 - Component is not ready

[1A[2K[BROWSER] 22:04:51 - Agent state changed: idle

[1A[2K[BROWSER] 22:04:51 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045891688-0.9635705239798513}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:51 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:51 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] [vite] connecting...

[1A[2K[BROWSER] [vite] connected.

[1A[2K[BROWSER] %cDownload the React DevTools for a better development experience: https://react.dev/link/react-devtools font-weight:bold

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] [TEST-APP] Transcription options - interim_results: true (env var: not set)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Creating new IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] About to create IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService constructor - debug: true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService created successfully

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: false, isPlayingChanged: false, isUserSpeakingChanged: false}

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: true, isReady: false, needsInitialization: true, isMounted: true, mountId: 0}

[1A[2K[BROWSER] ğŸ”§ [Component] Proceeding with initialization {isFirstMount: true, needsInitialization: true, isReady: false, transcriptionOptionsChanged: true, agentOptionsChanged: true}

[1A[2K[BROWSER] ğŸ”§ [Component] DeepgramVoiceInteraction initialized {services: transcription + agent, mountId: 1767045891707-0.10455395627262898, isStrictModeReInvoke: false}

[1A[2K[BROWSER] ğŸ”§ [INIT] Service configuration details: {transcriptionOptions: Object, agentOptions: Object, isTranscriptionConfigured: true, isAgentConfigured: true, apiKeyPresent: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription and agent services are configured (managers will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent service is configured (manager will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio manager will be created lazily when audio access is requested

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: undefined, isFirstRender: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] First render - skipping change detection

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isReady changed to false

[1A[2K[BROWSER] 22:04:51 - Component is not ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: agentState changed to idle

[1A[2K[BROWSER] 22:04:51 - Agent state changed: idle

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to false

[1A[2K[BROWSER] 22:04:51 - Audio playback: stopped - Agent playback completed

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Destroying IdleTimeoutService (cleanup)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ”§ [Component] useEffect cleanup running {mountId: 1767045891707-0.10455395627262898, transcriptionManagerExists: false, agentManagerExists: false, isMounted: true}

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup stack trace:     at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17482:13)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListUnmount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8500:117)
    at commitHookPassiveUnmountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8519:60)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Creating new IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] About to create IdleTimeoutService

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService constructor - debug: true

[1A[2K[BROWSER] ğŸ¯ [DEBUG] IdleTimeoutService created successfully

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: false, isPlayingChanged: false, isUserSpeakingChanged: false}

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: false, needsInitialization: true, isMounted: true, mountId: 1767045891707-0.10455395627262898}

[1A[2K[BROWSER] ğŸ”§ [Component] Proceeding with initialization {isFirstMount: false, needsInitialization: true, isReady: false, transcriptionOptionsChanged: true, agentOptionsChanged: true}

[1A[2K[BROWSER] ğŸ”§ [Component] DeepgramVoiceInteraction initialized {services: transcription + agent, mountId: 1767045891708-0.6839658056491812, isStrictModeReInvoke: true}

[1A[2K[BROWSER] ğŸ”§ [INIT] Service configuration details: {transcriptionOptions: Object, agentOptions: Object, isTranscriptionConfigured: true, isAgentConfigured: true, apiKeyPresent: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription and agent services are configured (managers will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent service is configured (manager will be created on demand)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio manager will be created lazily when audio access is requested

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false, connectionState: undefined, isConnected: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false}

[1A[2K[BROWSER] Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K[BROWSER] 22:04:51 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] 22:04:51 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...

[1A[2K[BROWSER] ğŸ”§ [Component] useEffect cleanup running {mountId: 1767045891708-0.6839658056491812, transcriptionManagerExists: false, agentManagerExists: false, isMounted: true}

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup stack trace:     at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17482:13)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListUnmount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8500:117)
    at commitHookPassiveUnmountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8519:60)

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045891708-0.6839658056491812}

[1A[2K[BROWSER] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false, connectionState: undefined, isConnected: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isReady changed to true

[1A[2K[BROWSER] 22:04:51 - Component is ready

[1A[2K[BROWSER] ğŸ”§ [Component] Cleanup detected StrictMode re-invocation - preserving connections and state

[1A[2K[BROWSER] âœ… AudioContext already running

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:227:3 â€º Echo Cancellation Detection and Configuration â€º should verify microphone remains active during agent playback
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[BROWSER] ğŸ¤ [APP] toggleMicrophone called

[1A[2K[BROWSER] ğŸ¤ [APP] micEnabled: false

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K[BROWSER] 22:04:52 - Starting audio capture (lazy initialization)

[1A[2K[BROWSER] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K[BROWSER] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K[BROWSER] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K[BROWSER] 22:04:52 - Starting agent and transcription services...

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Start method called with options: {"agent":true,"transcription":true}

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] start() - Fresh connection detected, resetting allowAgentRef from true to true

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”„ Fresh connection starting - resetting audio blocking state

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Service start flags: transcription=true, agent=true

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Creating transcription manager lazily...

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”§ [TRANSCRIPTION] Creating transcription manager lazily

[1A[2K[BROWSER] VAD: utterance_end_ms set to 1000ms

[1A[2K[BROWSER] VAD: interim_results set to true

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Not using keyterm prompting. Building queryParams object excluding array types.

[1A[2K[BROWSER] [WebSocketManager:transcription] WebSocketManager created

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Creating agent manager lazily...

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ”§ [AGENT] Creating agent manager lazily

[1A[2K[BROWSER] ğŸ”§ [AGENT] Creating WebSocketManager with URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K[BROWSER] ğŸ”§ [AGENT] Connection mode: direct

[1A[2K[BROWSER] ğŸ”§ [AGENT] Proxy endpoint: undefined

[1A[2K[BROWSER] ğŸ”§ [AGENT] API key present: true

[1A[2K[BROWSER] ğŸ”§ [AGENT] Auth token present: false

[1A[2K[BROWSER] [WebSocketManager:agent] WebSocketManager created

[1A[2K[BROWSER] [DeepgramVoiceInteraction] AudioManager not configured, skipping initialization

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K[BROWSER] [WebSocketManager:transcription] Connecting to WebSocket...

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Transcription state event: connecting Previous: undefined

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription state: connecting

[1A[2K[BROWSER] 22:04:52 - transcription connection state: connecting

[1A[2K[BROWSER] [WebSocketManager:transcription] Built URL with params: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] [WebSocketManager:transcription] Connecting to wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] URL: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Service: transcription

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K[BROWSER] [WebSocketManager:transcription] Initial readyState: 0

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
â³ Waiting for speech detection...

[1A[2Kâœ… Speech started detected: 22:04:50

[1A[2Kâ³ Waiting for UtteranceEnd detection...

[1A[2Kâœ… UtteranceEnd detected: Channel: [0,1], Last word end: 1.36s

[1A[2Kâœ… User stopped speaking callback: 22:04:51

[1A[2Kâ³ Waiting for agent to finish responding...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:227:3 â€º Echo Cancellation Detection and Configuration â€º should verify microphone remains active during agent playback
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:transcription] WebSocket connected

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Transcription state event: connected Previous: connecting

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription state: connected

[1A[2K[BROWSER] 22:04:52 - transcription connection state: connected

[1A[2K[BROWSER] ğŸ”§ [TRANSCRIPTION] Starting periodic keepalive audio to prevent timeout

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[BROWSER] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K[BROWSER] [WebSocketManager:agent] Connecting to WebSocket...

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connecting Previous: undefined

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent state: connecting

[1A[2K[BROWSER] 22:04:52 - agent connection state: connecting

[1A[2K[BROWSER] [WebSocketManager:agent] Built URL with params: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] [WebSocketManager:agent] Connecting to wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Service: agent

[1A[2K[BROWSER] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K[BROWSER] [WebSocketManager:agent] Initial readyState: 0

[1A[2K[BROWSER] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K[BROWSER] ğŸ”§ [TRANSCRIPTION] Periodic keepalive audio sent

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:227:3 â€º Echo Cancellation Detection and Configuration â€º should verify microphone remains active during agent playback
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone remains active during playback

[1A[2K[43/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
ğŸ” Testing barge-in functionality...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
âœ… Agent finished responding

[1A[2Kâ³ Waiting for idle conditions (agent idle, user idle, audio not playing)...

[1A[2KğŸ“Š Idle state: agentIdle=true, userIdle=true, audioNotPlaying=true, timeoutActive=false

[1A[2KâŒ ISSUE #244 REPRODUCED: Timeout is NOT active when it should be!

[1A[2K   Expected: timeoutActive=true when agentIdle=true, userIdle=true, audioNotPlaying=true

[1A[2K   Actual: timeoutActive=false

[1A[2Kâ³ Waiting for idle timeout (10 seconds)...

[1A[2K[chromium] â€º tests/e2e/diagnostic-vad.spec.js:133:3 â€º Diagnostic VAD Tests â€º should track WebSocket connection timing
Timing results:

[1A[2K  After 1s: Enabled

[1A[2K  After 2s: Enabled

[1A[2K  After 3s: Enabled

[1A[2K
WebSocket Events:

[1A[2K  [3071ms] ğŸ” [AUDIO BLOCKING] start() - Fresh connection detected, resetting allowAgentRef from true to true

[1A[2K  [3071ms] [DeepgramVoiceInteraction] ğŸ”„ Fresh connection starting - resetting audio blocking state

[1A[2K  [3071ms] [WebSocketManager:transcription] WebSocketManager created

[1A[2K  [3071ms] ğŸ”§ [AGENT] Creating WebSocketManager with URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K  [3071ms] [WebSocketManager:agent] WebSocketManager created

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K  [3071ms] [WebSocketManager:transcription] Connecting to WebSocket...

[1A[2K  [3071ms] 22:04:50 - transcription connection state: connecting

[1A[2K  [3071ms] [WebSocketManager:transcription] Built URL with params: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [3071ms] [WebSocketManager:transcription] Connecting to wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] URL: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] Service: transcription

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K  [3071ms] [WebSocketManager:transcription] Initial readyState: 0

[1A[2K  [3071ms] [WebSocketManager:transcription] WebSocket connected

[1A[2K  [3071ms] 22:04:51 - transcription connection state: connected

[1A[2K  [3071ms] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  [3071ms] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K  [3071ms] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K  [3071ms] [WebSocketManager:agent] Connecting to WebSocket...

[1A[2K  [3071ms] 22:04:51 - agent connection state: connecting

[1A[2K  [3071ms] [WebSocketManager:agent] Built URL with params: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [3071ms] [WebSocketManager:agent] Connecting to wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] Service: agent

[1A[2K  [3071ms] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K  [3071ms] [WebSocketManager:agent] Initial readyState: 0

[1A[2K  [3071ms] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K  [3071ms] [WebSocketManager:agent] WebSocket connected

[1A[2K  [3071ms] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Agent WebSocket connected for first time

[1A[2K  [3071ms] 22:04:51 - agent connection state: connected

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K  [3071ms] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  [3071ms] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Agent service already connected, skipping connection

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Welcome","request_id":"bd164197-1574-4441-988b-a6efec3e9a58"}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Welcome, request_id: bd164197-1574-4441-988b-a6efec3e9a58}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Welcome

[1A[2K  [3071ms] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K  [3071ms] [DeepgramVoiceInteraction] Welcome message received - dual mode connection established

[1A[2K  [3071ms] [DeepgramVoiceInteraction] New connection - triggering greeting flow

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Welcome

[1A[2K  [3071ms] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K  [3071ms] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K  [3071ms] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K  [3071ms] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K  [3071ms] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K  [3071ms] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K  [3071ms] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [3071ms] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K  [3071ms] [WebSocketManager:agent] Started keepalive interval

[1A[2K  [3071ms] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"ConversationText","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: ConversationText

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: ConversationText

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"History","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: History

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: History

[1A[2K  [3071ms] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connected, isConnected: true}

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3071ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3071ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3071ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3072ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3072ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3072ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [3073ms] [WebSocketManager:agent] Received Blob binary data (size: 408), converting to ArrayBuffer...

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [3073ms] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"AgentAudioDone"}

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: AgentAudioDone}

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: AgentAudioDone

[1A[2K  [3073ms] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: AgentAudioDone

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [3073ms] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 408), emitting binary event...

[1A[2Kâœ… WebSocket timing test completed

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] WebSocket connected

[1A[2K[BROWSER] ğŸ”§ [DEBUG] Agent state event: connected Previous: connecting

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent state: connected

[1A[2K[BROWSER] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent WebSocket connected for first time

[1A[2K[BROWSER] 22:04:54 - agent connection state: connected

[1A[2K[BROWSER] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K[BROWSER] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[BROWSER] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] AudioManager not available - this is expected for text-only agent interactions

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Start method completed successfully

[1A[2K[BROWSER] ğŸ¤ [APP] Services started (or already connected)

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K[BROWSER] [DeepgramVoiceInteraction] startAudioCapture called - initializing audio manager lazily

[1A[2K[BROWSER] [AudioManager] AudioManager created

[1A[2K[BROWSER] [AudioManager] Initializing AudioManager

[1A[2K[BROWSER] [AudioManager] Created audio analyzer for volume normalization

[1A[2K[BROWSER] [AudioManager] Created Object URL for AudioWorklet: blob:http://localhost:5173/fb08a86f-9e08-4b01-9d40-35f3d507a8cb

[1A[2K[BROWSER] ğŸ¤ [MOCK] AudioWorklet.addModule called - simulating success

[1A[2K[BROWSER] [AudioManager] AudioWorklet loaded using Object URL

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio manager ready

[1A[2K[BROWSER] [AudioManager] Revoking Object URL: blob:http://localhost:5173/fb08a86f-9e08-4b01-9d40-35f3d507a8cb

[1A[2K[BROWSER] [DeepgramVoiceInteraction] AudioManager initialized

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent service already connected, skipping connection

[1A[2K[BROWSER] [AudioManager] Requesting microphone access

[1A[2K[BROWSER] ğŸ¤ [MOCK] getUserMedia called - returning mock MediaStream

[1A[2K[BROWSER] [AudioManager] Echo cancellation support: {supported: true, active: false, browser: Chrome, version: 141, limitations: Array(1)}

[1A[2K[BROWSER] [AudioManager] âš ï¸ Echo cancellation requested but not active

[1A[2K[BROWSER] ğŸ¤ [MOCK] createMediaStreamSource called - simulating success

[1A[2K[BROWSER] ğŸ¤ [MOCK] AudioWorkletNode constructor called - simulating success

[1A[2K[BROWSER] ğŸ¤ [MOCK] AudioWorkletNode port.postMessage called with: {type: start}

[1A[2K[BROWSER] [AudioManager] Recording started

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Started polling for idle timeout conditions

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=startAudioCapture, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout started with timeoutId: 14

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Audio capture started successfully

[1A[2K[BROWSER] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K[BROWSER] 22:04:54 - Audio capture started successfully

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Welcome","request_id":"227b49df-e24d-4c6b-9470-3c0f45af4691"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Welcome, request_id: 227b49df-e24d-4c6b-9470-3c0f45af4691}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Welcome

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: Welcome): {type: Welcome, request_id: 227b49df-e24d-4c6b-9470-3c0f45af4691}

[1A[2K[BROWSER] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Welcome message received - dual mode connection established

[1A[2K[BROWSER] [DeepgramVoiceInteraction] New connection - triggering greeting flow

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Welcome

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[44/178] [chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[1A[2K[BROWSER] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K[BROWSER] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Called

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions: undefined

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 0

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Settings message sent, waiting for SettingsApplied confirmation

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}

[1A[2K[BROWSER] ğŸ” [DEBUG] Full Settings message structure: {
  "type": "Settings",
  "audio": {
    "input": {
      "encoding": "linear16",
      "sample_rate": 16000
    },
    "output": {
      "encoding": "linear16",
      "sample_rate": 24000
    }
  },
  "agent": {
    "language": "en",
    "think": {
      "provider": {
        "type": "open_ai",
        "model": "gpt-4o-mini"
      },
      "prompt": "You are a helpful voice assistant. Keep your responses concise and informative."
    },
    "speak": {
      "provider": {
        "type": "deepgram",
        "model": "aura-asteria-en"
      }
    },
    "greeting": "Hello! How can I assist you today?"
  }
}

[1A[2K[BROWSER] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[BROWSER] ğŸ“¤ [Component] Has functions? false

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K[BROWSER] ğŸ“¤ [Component] Before sendJSON call:

[1A[2K[BROWSER] ğŸ“¤ [Component] - agentManagerRef.current exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K[BROWSER] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: Settings

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=Settings, isSettings=true

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… ENTERED Settings block!

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Setting window variables...

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Window variables set successfully

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Settings message detected!

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (exact JSON string): {"type":"Settings","audio":{"input":{"encoding":"linear16","sample_rate":16000},"output":{"encoding":"linear16","sample_rate":24000}},"agent":{"language":"en","think":{"provider":{"type":"open_ai","model":"gpt-4o-mini"},"prompt":"You are a helpful voice assistant. Keep your responses concise and informative."},"speak":{"provider":{"type":"deepgram","model":"aura-asteria-en"}},"greeting":"Hello! How can I assist you today?"}}

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (parsed): {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K[BROWSER] [WebSocketManager:agent] Started keepalive interval

[1A[2K[BROWSER] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Flags set immediately after successful send (StrictMode protection)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
ğŸ§ª Testing client-side function calling end-to-end...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: SettingsApplied): {type: SettingsApplied}

[1A[2K[BROWSER] âœ… [Protocol] SettingsApplied received - settings are now active

[1A[2K[BROWSER] [DeepgramVoiceInteraction] SettingsApplied received - settings are now active

[1A[2K[BROWSER] ğŸ¯ [SettingsApplied] Settings confirmed by Deepgram, audio data can now be processed

[1A[2K[BROWSER] 22:04:54 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] [APP] memoizedAgentOptions: enableFunctionCalling=true, functionType=standard

[1A[2K[BROWSER] [APP] memoizedAgentOptions: enableFunctionCalling=true, functionType=standard

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"ConversationText","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: ConversationText

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: ConversationText): {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] ğŸ’¬ [AGENT EVENT] ConversationText received role= assistant

[1A[2K[BROWSER] 22:04:54 - Agent said: Hello! How can I assist you today?

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: ConversationText

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"History","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: History

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: History): {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: History

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045891708-0.6839658056491812}

[1A[2K[BROWSER] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Entry point - useEffect triggered {agentOptionsRef: exists, prevAgentOptionsRef: exists, isFirstRender: false}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions useEffect] Comparing values: {prevHasFunctions: false, prevFunctionsCount: 0, currentHasFunctions: false, currentFunctionsCount: 0, prevKeys: Array(7)}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connected, isConnected: true}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Change detection: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] [APP] memoizedAgentOptions: enableFunctionCalling=true, functionType=standard

[1A[2K[BROWSER] [APP] memoizedAgentOptions: enableFunctionCalling=true, functionType=standard

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 0, startTimeRef.current = 0

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.16 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 1

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Playing state: true

[1A[2K[BROWSER] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle

[1A[2K[BROWSER] ğŸ¯ [AGENT] Audio playback started - transitioning from idle to speaking

[1A[2K[BROWSER] [SLEEP_CYCLE][CORE] Dispatching AGENT_STATE_CHANGE to speaking (from playback start, previous state: idle)

[1A[2K[BROWSER] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[BROWSER] 22:04:54 - Agent state changed: speaking

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 1, startTimeRef.current = 0.18

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.180s, current time: 0.160s, active sources: 1

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 1, startTimeRef.current = 0.18

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.18 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 2

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 2, startTimeRef.current = 0.19999999999999998

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.200s, current time: 0.165s, active sources: 2

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [useIdleTimeoutManager] State change detected: {prev: Object, current: Object, agentStateChanged: true, isPlayingChanged: true, isUserSpeakingChanged: false}

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting AGENT_STATE_CHANGED: idle -> speaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: 14

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 14

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout cleared successfully

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] [useIdleTimeoutManager] Emitting PLAYBACK_STATE_CHANGED: false -> true

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: agentState changed to speaking

[1A[2K[BROWSER] 22:04:54 - Agent state changed: speaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Notifying parent: isPlaying changed to true

[1A[2K[BROWSER] 22:04:54 - Audio playback: started

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 2, startTimeRef.current = 0.19999999999999998

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.19999999999999998 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 3

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 3, startTimeRef.current = 0.21999999999999997

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.220s, current time: 0.171s, active sources: 3

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 3, startTimeRef.current = 0.21999999999999997

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.21999999999999997 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 4

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 4, startTimeRef.current = 0.23999999999999996

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.240s, current time: 0.176s, active sources: 4

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
âœ… Test page setup complete

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 4, startTimeRef.current = 0.23999999999999996

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.23999999999999996 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 5

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 5, startTimeRef.current = 0.25999999999999995

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.260s, current time: 0.176s, active sources: 5

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 5, startTimeRef.current = 0.25999999999999995

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.25999999999999995 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 6

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 6, startTimeRef.current = 0.27999999999999997

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.280s, current time: 0.176s, active sources: 6

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 6, startTimeRef.current = 0.27999999999999997

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.27999999999999997 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 7

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 7, startTimeRef.current = 0.3

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.300s, current time: 0.176s, active sources: 7

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 7, startTimeRef.current = 0.3

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.3 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 8

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 8, startTimeRef.current = 0.32

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.320s, current time: 0.176s, active sources: 8

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 8, startTimeRef.current = 0.32

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.32 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 9

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 9, startTimeRef.current = 0.34

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.340s, current time: 0.176s, active sources: 9

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 9, startTimeRef.current = 0.34

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.34 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 10

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 10, startTimeRef.current = 0.36000000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.360s, current time: 0.176s, active sources: 10

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 10, startTimeRef.current = 0.36000000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.36000000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 11

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 11, startTimeRef.current = 0.38000000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.380s, current time: 0.176s, active sources: 11

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 11, startTimeRef.current = 0.38000000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.38000000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 12

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 12, startTimeRef.current = 0.4000000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.400s, current time: 0.176s, active sources: 12

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 12, startTimeRef.current = 0.4000000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4000000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 13

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 13, startTimeRef.current = 0.4200000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.420s, current time: 0.176s, active sources: 13

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 13, startTimeRef.current = 0.4200000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4200000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 14

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 14, startTimeRef.current = 0.4400000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.440s, current time: 0.176s, active sources: 14

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 14, startTimeRef.current = 0.4400000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4400000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 15

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 15, startTimeRef.current = 0.46000000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.460s, current time: 0.176s, active sources: 15

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 15, startTimeRef.current = 0.46000000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.46000000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 16

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 16, startTimeRef.current = 0.48000000000000015

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.480s, current time: 0.176s, active sources: 16

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 15

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 15, startTimeRef.current = 0.48000000000000015

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.4800000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 16

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 16, startTimeRef.current = 0.5000000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.500s, current time: 0.181s, active sources: 16

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 16, startTimeRef.current = 0.5000000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5000000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 17

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 17, startTimeRef.current = 0.5200000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.520s, current time: 0.181s, active sources: 17

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []
[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 16

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 16, startTimeRef.current = 0.5200000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5200000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 17

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 17, startTimeRef.current = 0.5400000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.540s, current time: 0.203s, active sources: 17

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 17, startTimeRef.current = 0.5400000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5400000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 18

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 18, startTimeRef.current = 0.5600000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.560s, current time: 0.203s, active sources: 18

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
ğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 18, startTimeRef.current = 0.5600000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5600000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 19

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 19, startTimeRef.current = 0.5800000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.580s, current time: 0.203s, active sources: 19

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 19, startTimeRef.current = 0.5800000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.5800000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 20

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 20, startTimeRef.current = 0.6000000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.600s, current time: 0.208s, active sources: 20

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 20, startTimeRef.current = 0.6000000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6000000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 21

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 21, startTimeRef.current = 0.6200000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.620s, current time: 0.208s, active sources: 21

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 21, startTimeRef.current = 0.6200000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6200000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 22

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 22, startTimeRef.current = 0.6400000000000002

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.640s, current time: 0.208s, active sources: 22

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 22, startTimeRef.current = 0.6400000000000002

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6400000000000002 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 23

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 23, startTimeRef.current = 0.6600000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.660s, current time: 0.213s, active sources: 23

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 23, startTimeRef.current = 0.6600000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6600000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 24

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 24, startTimeRef.current = 0.6800000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.680s, current time: 0.213s, active sources: 24

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 24, startTimeRef.current = 0.6800000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.6800000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 25

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 25, startTimeRef.current = 0.7000000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.700s, current time: 0.213s, active sources: 25

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 25, startTimeRef.current = 0.7000000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7000000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 26

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 26, startTimeRef.current = 0.7200000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.720s, current time: 0.213s, active sources: 26

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 26, startTimeRef.current = 0.7200000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7200000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 27

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 27, startTimeRef.current = 0.7400000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.740s, current time: 0.213s, active sources: 27

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 27, startTimeRef.current = 0.7400000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7400000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 28

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 28, startTimeRef.current = 0.7600000000000003

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.760s, current time: 0.213s, active sources: 28

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 28, startTimeRef.current = 0.7600000000000003

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7600000000000003 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 29

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 29, startTimeRef.current = 0.7800000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.780s, current time: 0.219s, active sources: 29

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 29, startTimeRef.current = 0.7800000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.7800000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 30

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 30, startTimeRef.current = 0.8000000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.800s, current time: 0.219s, active sources: 30

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 30, startTimeRef.current = 0.8000000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8000000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 31

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 31, startTimeRef.current = 0.8200000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.820s, current time: 0.224s, active sources: 31

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 31, startTimeRef.current = 0.8200000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8200000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 32

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 32, startTimeRef.current = 0.8400000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.840s, current time: 0.224s, active sources: 32

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 32, startTimeRef.current = 0.8400000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8400000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 33

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 33, startTimeRef.current = 0.8600000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.860s, current time: 0.224s, active sources: 33

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 33, startTimeRef.current = 0.8600000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8600000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 34

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 34, startTimeRef.current = 0.8800000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.880s, current time: 0.224s, active sources: 34

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 33

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 33, startTimeRef.current = 0.8800000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.8800000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 34

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 34, startTimeRef.current = 0.9000000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.900s, current time: 0.224s, active sources: 34

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 34, startTimeRef.current = 0.9000000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9000000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 35

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 35, startTimeRef.current = 0.9200000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.920s, current time: 0.224s, active sources: 35

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 35, startTimeRef.current = 0.9200000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9200000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 36

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 36, startTimeRef.current = 0.9400000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.940s, current time: 0.224s, active sources: 36

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 36, startTimeRef.current = 0.9400000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9400000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 37

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 37, startTimeRef.current = 0.9600000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.960s, current time: 0.229s, active sources: 37

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 37, startTimeRef.current = 0.9600000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9600000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 38

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 38, startTimeRef.current = 0.9800000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 0.980s, current time: 0.229s, active sources: 38

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 38, startTimeRef.current = 0.9800000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 0.9800000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 39

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 39, startTimeRef.current = 1.0000000000000004

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.000s, current time: 0.229s, active sources: 39

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 39, startTimeRef.current = 1.0000000000000004

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0000000000000004 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 40

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 40, startTimeRef.current = 1.0200000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.020s, current time: 0.229s, active sources: 40

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing InjectUserMessage message

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 40, startTimeRef.current = 1.0200000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0200000000000005 (duration: 0.02)

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=InjectUserMessage, isSettings=false

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] NOT a Settings message, skipping

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 41

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 41, startTimeRef.current = 1.0400000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.040s, current time: 0.229s, active sources: 41

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 41, startTimeRef.current = 1.0400000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0400000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 42

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 42, startTimeRef.current = 1.0600000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.060s, current time: 0.229s, active sources: 42

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 42, startTimeRef.current = 1.0600000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0600000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 43

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 43, startTimeRef.current = 1.0800000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.080s, current time: 0.229s, active sources: 43

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 43, startTimeRef.current = 1.0800000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.0800000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 44

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 44, startTimeRef.current = 1.1000000000000005

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.100s, current time: 0.235s, active sources: 44

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 44, startTimeRef.current = 1.1000000000000005

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1000000000000005 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 45

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 45, startTimeRef.current = 1.1200000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.120s, current time: 0.235s, active sources: 45

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 45, startTimeRef.current = 1.1200000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1200000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 46

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 46, startTimeRef.current = 1.1400000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.140s, current time: 0.235s, active sources: 46

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 45

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 45, startTimeRef.current = 1.1400000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1400000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 46

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 46, startTimeRef.current = 1.1600000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.160s, current time: 0.240s, active sources: 46

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 46, startTimeRef.current = 1.1600000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1600000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 47

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 47, startTimeRef.current = 1.1800000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.180s, current time: 0.240s, active sources: 47

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 47, startTimeRef.current = 1.1800000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.1800000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 48

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 48, startTimeRef.current = 1.2000000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.200s, current time: 0.240s, active sources: 48

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 48, startTimeRef.current = 1.2000000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2000000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 49

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 49, startTimeRef.current = 1.2200000000000006

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.220s, current time: 0.240s, active sources: 49

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 49, startTimeRef.current = 1.2200000000000006

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2200000000000006 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 50

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 50, startTimeRef.current = 1.2400000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.240s, current time: 0.240s, active sources: 50

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 50, startTimeRef.current = 1.2400000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2400000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 51

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 51, startTimeRef.current = 1.2600000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.260s, current time: 0.240s, active sources: 51

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 51, startTimeRef.current = 1.2600000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2600000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 52

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 52, startTimeRef.current = 1.2800000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.280s, current time: 0.240s, active sources: 52

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 52, startTimeRef.current = 1.2800000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.2800000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 53

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 53, startTimeRef.current = 1.3000000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.300s, current time: 0.240s, active sources: 53

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 53, startTimeRef.current = 1.3000000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3000000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 54

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 54, startTimeRef.current = 1.3200000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.320s, current time: 0.251s, active sources: 54

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 54, startTimeRef.current = 1.3200000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3200000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 55

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 55, startTimeRef.current = 1.3400000000000007

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.340s, current time: 0.251s, active sources: 55

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 55, startTimeRef.current = 1.3400000000000007

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3400000000000007 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 56

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 56, startTimeRef.current = 1.3600000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.360s, current time: 0.251s, active sources: 56

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 56, startTimeRef.current = 1.3600000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3600000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 57

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 57, startTimeRef.current = 1.3800000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.380s, current time: 0.251s, active sources: 57

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 57, startTimeRef.current = 1.3800000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.3800000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 58

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 58, startTimeRef.current = 1.4000000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.400s, current time: 0.251s, active sources: 58

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 58, startTimeRef.current = 1.4000000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4000000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 59

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 59, startTimeRef.current = 1.4200000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.420s, current time: 0.251s, active sources: 59

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 59, startTimeRef.current = 1.4200000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4200000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 60

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 60, startTimeRef.current = 1.4400000000000008

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.440s, current time: 0.251s, active sources: 60

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 60, startTimeRef.current = 1.4400000000000008

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4400000000000008 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 61

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 61, startTimeRef.current = 1.4600000000000009

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.460s, current time: 0.251s, active sources: 61

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 61, startTimeRef.current = 1.4600000000000009

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4600000000000009 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 62

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 62, startTimeRef.current = 1.4800000000000009

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.480s, current time: 0.251s, active sources: 62

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 62, startTimeRef.current = 1.4800000000000009

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.4800000000000009 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 63

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 63, startTimeRef.current = 1.5000000000000009

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.500s, current time: 0.251s, active sources: 63

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 63, startTimeRef.current = 1.5000000000000009

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.5000000000000009 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 64

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 64, startTimeRef.current = 1.520000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.520s, current time: 0.251s, active sources: 64

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 64, startTimeRef.current = 1.520000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.520000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 65

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 65, startTimeRef.current = 1.540000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.540s, current time: 0.251s, active sources: 65

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 65, startTimeRef.current = 1.540000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.540000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 66

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 66, startTimeRef.current = 1.560000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.560s, current time: 0.251s, active sources: 66

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 66, startTimeRef.current = 1.560000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.560000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 67

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 67, startTimeRef.current = 1.580000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.580s, current time: 0.256s, active sources: 67

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 67, startTimeRef.current = 1.580000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.580000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 68

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 68, startTimeRef.current = 1.600000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.600s, current time: 0.256s, active sources: 68

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 68, startTimeRef.current = 1.600000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.600000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 69

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 69, startTimeRef.current = 1.620000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.620s, current time: 0.256s, active sources: 69

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 69, startTimeRef.current = 1.620000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.620000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 70

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 70, startTimeRef.current = 1.640000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.640s, current time: 0.256s, active sources: 70

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 69

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 69, startTimeRef.current = 1.640000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.640000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 70

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 70, startTimeRef.current = 1.660000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.660s, current time: 0.261s, active sources: 70

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 70, startTimeRef.current = 1.660000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.660000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 71

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 71, startTimeRef.current = 1.680000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.680s, current time: 0.261s, active sources: 71

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 71, startTimeRef.current = 1.680000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.680000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 72

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 72, startTimeRef.current = 1.700000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.700s, current time: 0.261s, active sources: 72

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 72, startTimeRef.current = 1.700000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.700000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 73

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 73, startTimeRef.current = 1.720000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.720s, current time: 0.261s, active sources: 73

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 73, startTimeRef.current = 1.720000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.720000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 74

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 74, startTimeRef.current = 1.740000000000001

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.740s, current time: 0.261s, active sources: 74

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!
[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Called

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentManagerRef.current: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions: true

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions: [1 functions]

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message
[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ”§ [sendAgentSettings] agentOptions.functions?.length: 1

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettings: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] hasSentSettingsRef.current: false

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Settings message sent, waiting for SettingsApplied confirmation

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ” [SETTINGS DEBUG] Full Settings message with functions: {
  "type": "Settings",
  "audio": {
    "input": {
      "encoding": "linear16",
      "sample_rate": 16000
    },
    "output": {
      "encoding": "linear16",
      "sample_rate": 24000
    }
  },
  "agent": {
    "language": "en",
    "think": {
      "provider": {
        "type": "open_ai",
        "model": "gpt-4o-mini"
      },
      "prompt": "You are a helpful voice assistant. Keep your responses concise and informative.",
      "functions": [
        {
          "name": "get_current_time",
          "description": "Get the current time in a specific timezone. Use this when users ask about the time, what time it is, or current time.",
          "parameters": {
            "type": "object",
            "properties": {
              "timezone": {
                "type": "string",
                "description": "Timezone (e.g., \"America/New_York\", \"UTC\", \"Europe/London\"). Defaults to UTC if not specified."
              }
            }
          }
        }
      ]
    },
    "speak": {
      "provider": {
        "type": "deepgram",
        "model": "aura-asteria-en"
      }
    },
    "greeting": "Hello! How can I assist you today?"
  }
}

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER] ğŸ“¤ [Component] Settings message type: Settings

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 74, startTimeRef.current = 1.740000000000001

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.740000000000001 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 75

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 75, startTimeRef.current = 1.7600000000000011

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.760s, current time: 0.267s, active sources: 75

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 75, startTimeRef.current = 1.7600000000000011

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.7600000000000011 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 76

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 76, startTimeRef.current = 1.7800000000000011

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.780s, current time: 0.267s, active sources: 76

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 76, startTimeRef.current = 1.7800000000000011

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.7800000000000011 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 77

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 77, startTimeRef.current = 1.8000000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.800s, current time: 0.267s, active sources: 77

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 77, startTimeRef.current = 1.8000000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8000000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 78

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 78, startTimeRef.current = 1.8200000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.820s, current time: 0.267s, active sources: 78

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 78, startTimeRef.current = 1.8200000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8200000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 79

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 79, startTimeRef.current = 1.8400000000000012

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: Settings

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=Settings, isSettings=true

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… ENTERED Settings block!

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [AudioManager] Audio scheduled to play at 1.840s, current time: 0.267s, active sources: 79

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] âœ… Settings message detected!

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (exact JSON string): {"type":"Settings","audio":{"input":{"encoding":"linear16","sample_rate":16000},"output":{"encoding":"linear16","sample_rate":24000}},"agent":{"language":"en","think":{"provider":{"type":"open_ai","model":"gpt-4o-mini"},"prompt":"You are a helpful voice assistant. Keep your responses concise and informative.","functions":[{"name":"get_current_time","description":"Get the current time in a specific timezone. Use this when users ask about the time, what time it is, or current time.","parameters":{"type":"object","properties":{"timezone":{"type":"string","description":"Timezone (e.g., \"America/New_York\", \"UTC\", \"Europe/London\"). Defaults to UTC if not specified."}}}}]},"speak":{"provider":{"type":"deepgram","model":"aura-asteria-en"}},"greeting":"Hello! How can I assist you today?"}}

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 79, startTimeRef.current = 1.8400000000000012

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Settings message payload (parsed): {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8400000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 80

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] WebSocket send: Settings {type: Settings, audio: Object, agent: Object}

[1A[2K[BROWSER] ğŸ”§ [sendAgentSettings] Flags set immediately after successful send (StrictMode protection)

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 80, startTimeRef.current = 1.8600000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.860s, current time: 0.267s, active sources: 80

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[BROWSER] ğŸ“¤ [Protocol] Settings sent state updated to true

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 80, startTimeRef.current = 1.8600000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8600000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 81

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 81, startTimeRef.current = 1.8800000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.880s, current time: 0.267s, active sources: 81

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 81, startTimeRef.current = 1.8800000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.8800000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 82

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 82, startTimeRef.current = 1.9000000000000012

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.900s, current time: 0.267s, active sources: 82

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 82, startTimeRef.current = 1.9000000000000012

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9000000000000012 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 83

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 83, startTimeRef.current = 1.9200000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.920s, current time: 0.267s, active sources: 83

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
âœ… Connection established

[1A[2K[chromium] â€º tests/e2e/callback-test.spec.js:216:3 â€º Callback Test Suite â€º should test all callbacks integration with comprehensive workflow
[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K[BROWSER] [WebSocketManager:agent] Received Blob binary data (size: 408), converting to ArrayBuffer...

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K[BROWSER] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"AgentAudioDone"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: AgentAudioDone}

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout started with timeoutId: 20

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: AgentAudioDone

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: AgentAudioDone): {type: AgentAudioDone}

[1A[2K[BROWSER] ğŸ”Š [AGENT EVENT] AgentAudioDone received

[1A[2K[BROWSER] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue

[1A[2K[BROWSER] [SLEEP_CYCLE][CORE] AgentAudioDone received - audio generation complete, but playback may continue

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: AgentAudioDone

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 83, startTimeRef.current = 1.9200000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9200000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 84

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 84, startTimeRef.current = 1.9400000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.940s, current time: 0.272s, active sources: 84

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 84, startTimeRef.current = 1.9400000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9400000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 85

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 85, startTimeRef.current = 1.9600000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.960s, current time: 0.272s, active sources: 85

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 85, startTimeRef.current = 1.9600000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9600000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 86

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 86, startTimeRef.current = 1.9800000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 1.980s, current time: 0.272s, active sources: 86

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 86, startTimeRef.current = 1.9800000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 1.9800000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 87

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 87, startTimeRef.current = 2.0000000000000013

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.000s, current time: 0.272s, active sources: 87

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 87, startTimeRef.current = 2.0000000000000013

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0000000000000013 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 88

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 88, startTimeRef.current = 2.0200000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.020s, current time: 0.272s, active sources: 88

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 88, startTimeRef.current = 2.0200000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0200000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 89

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 89, startTimeRef.current = 2.0400000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.040s, current time: 0.272s, active sources: 89

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 89, startTimeRef.current = 2.0400000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0400000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 90

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 90, startTimeRef.current = 2.0600000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.060s, current time: 0.272s, active sources: 90

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 90, startTimeRef.current = 2.0600000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0600000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 91

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 91, startTimeRef.current = 2.0800000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.080s, current time: 0.277s, active sources: 91

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 91, startTimeRef.current = 2.0800000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.0800000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 92

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 92, startTimeRef.current = 2.1000000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.100s, current time: 0.277s, active sources: 92

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 92, startTimeRef.current = 2.1000000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.1000000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 93

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 93, startTimeRef.current = 2.1200000000000014

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.120s, current time: 0.277s, active sources: 93

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 93, startTimeRef.current = 2.1200000000000014

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.1200000000000014 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 94

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 94, startTimeRef.current = 2.1400000000000015

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.140s, current time: 0.277s, active sources: 94

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 960

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 960 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 960 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (960 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 94, startTimeRef.current = 2.1400000000000015

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.020s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.1400000000000015 (duration: 0.02)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 95

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 95, startTimeRef.current = 2.1600000000000015

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.160s, current time: 0.277s, active sources: 95

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 408), emitting binary event...

[1A[2K[BROWSER] ğŸµ [AUDIO EVENT] handleAgentAudio received buffer bytes= 408

[1A[2K[BROWSER] [DeepgramVoiceInteraction] handleAgentAudio called! Received buffer of 408 bytes

[1A[2K[BROWSER] ğŸ” [AUDIO BLOCKING] handleAgentAudio - allowAgentRef.current=true (BLOCKED=false)

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Passing buffer to AudioManager.queueAudio()

[1A[2K[BROWSER] ğŸµ [AUDIO] Audio context state: running

[1A[2K[BROWSER] [AudioManager] ğŸµ [queueAudio] Received audio data: 408 bytes

[1A[2K[BROWSER] [AudioManager] Processing audio data (408 bytes)...

[1A[2K[BROWSER] [AudioManager] [queueAudio] Before: activeSourceNodes.length = 95, startTimeRef.current = 2.1600000000000015

[1A[2K[BROWSER] [AudioManager] [queueAudio] AudioContext state: running

[1A[2K[BROWSER] [AudioManager] [queueAudio] Created audio buffer (0.009s)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Scheduled source to start at 2.1600000000000015 (duration: 0.0085)

[1A[2K[BROWSER] [AudioManager] [queueAudio] Added source. activeSourceNodes.length = 96

[1A[2K[BROWSER] [AudioManager] [queueAudio] After: activeSourceNodes.length = 96, startTimeRef.current = 2.1685000000000016

[1A[2K[BROWSER] [AudioManager] Audio scheduled to play at 2.169s, current time: 0.277s, active sources: 96

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Successfully queued audio buffer for playback

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 95

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 94

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 93

[1A[2K[BROWSER] 22:04:54 - Sending text message: Hello, this is a comprehensive test message

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent manager already exists, reusing

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Manager reference stored, state: connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Agent manager already connected

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Injecting user message: Hello, this is a comprehensive test message - WebSocket state: connected

[1A[2K[BROWSER] ğŸ“ [TEXT_MESSAGE] Attempting to send: Hello, this is a comprehensive test message - Connection state: connected

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] Called with type: InjectUserMessage

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] DEBUG: data.type=InjectUserMessage, isSettings=false

[1A[2K[BROWSER] ğŸ“¤ [WEBSOCKET.sendJSON] NOT a Settings message, skipping

[1A[2K[BROWSER] [WebSocketManager:agent] Sending JSON: {type: InjectUserMessage, content: Hello, this is a comprehensive test message}

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=InjectUserMessage, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: InjectUserMessage)

[1A[2K[BROWSER] ğŸ“ [TEXT_MESSAGE] Message sent successfully

[1A[2K[BROWSER] [DeepgramVoiceInteraction] User message sent successfully

[1A[2K[BROWSER] 22:04:54 - Text message sent to Deepgram agent

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 92

[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): InjectUserMessage message
[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2Kâœ… Comprehensive callback integration test completed

[1A[2KğŸ“Š Callback Status:

[1A[2K  - onReady: âœ…

[1A[2K  - onAgentUtterance: âœ…

[1A[2K  - onPlaybackStateChange: âœ…

[1A[2K[BROWSER] [AudioManager] [onended] Audio source playback ended

[1A[2K[BROWSER] [AudioManager] [onended] Source removed. activeSourceNodes.length = 91

[1A[2K[45/178] [chromium] â€º tests/e2e/greeting-audio-timing.spec.js:48:3 â€º Greeting Audio Timing â€º should play greeting audio when user clicks into text input field
[1A[2K[46/178] [chromium] â€º tests/e2e/greeting-audio-timing.spec.js:81:3 â€º Greeting Audio Timing â€º should play greeting audio when user presses microphone button
[1A[2K[47/178] [chromium] â€º tests/e2e/greeting-audio-timing.spec.js:111:3 â€º Greeting Audio Timing â€º should replay greeting audio immediately on reconnection
[1A[2K[48/178] [chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Error message

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] WebSocket receive: Error {type: Error, description: Received InjectUserMessage before Settings., code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Error","description":"Received InjectUserMessage before Settings.","code":"NON_SETTINGS_MESSAGE_BEFORE_SETTINGS"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Error, description: Received InjectUserMessage before Settings., code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: Error): {type: Error, description: Received InjectUserMessage before Settings., code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS}

[1A[2K[BROWSER] âŒ [FUNCTION DEBUG] Error received after sending Settings with functions: {
  "type": "Error",
  "description": "Received InjectUserMessage before Settings.",
  "code": "NON_SETTINGS_MESSAGE_BEFORE_SETTINGS"
}

[1A[2K[BROWSER] ğŸš¨ [ERROR] Deepgram error received: {service: agent, code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS, message: Received InjectUserMessage before Settings., details: Object}

[1A[2K[BROWSER] ğŸš¨ [ERROR] Error message: Received InjectUserMessage before Settings.

[1A[2K[BROWSER] ğŸš¨ [ERROR] Error details: {type: Error, description: Received InjectUserMessage before Settings., code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] Error: {service: agent, code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS, message: Received InjectUserMessage before Settings., details: Object}

[1A[2K[BROWSER] 22:04:54 - Error (agent): Received InjectUserMessage before Settings.

[1A[2K[BROWSER] Deepgram error: {service: agent, code: NON_SETTINGS_MESSAGE_BEFORE_SETTINGS, message: Received InjectUserMessage before Settings., details: Object}

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
ğŸ§ª Testing Issue #139: Idle timeout after greeting completion...

[1A[2KStep 1: Starting fresh browser session...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1005 

[1A[2K[WebServer] [Proxy] Client connection closed: 1000 

[1A[2K[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ”§ [Connection] hasSentSettingsRef and globalSettingsSent reset to false due to connection close

[1A[2K[BROWSER] Reset hasSentSettings flag due to connection close

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence
  +2001ms: agentIdle=true, userIdle=true, audioNotPlaying=true, timeoutActive=false, connection=connected

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
Step 2: Establishing connection via microphone...

[1A[2KInitial connection status: connected

[1A[2KStep 3: Waiting for agent to start speaking greeting...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:257:3 â€º Echo Cancellation Detection and Configuration â€º should preserve barge-in functionality during agent playback
âœ… Barge-in functionality preserved - agent interrupted and processed new message

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
âœ… Greeting sent

[1A[2Kâœ… Agent started speaking greeting

[1A[2KStep 4: Waiting for agent to finish speaking greeting...

[1A[2K[49/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:316:3 â€º Echo Cancellation Detection and Configuration â€º should detect browser echo cancellation support
[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:316:3 â€º Echo Cancellation Detection and Configuration â€º should detect browser echo cancellation support
ğŸ” Testing browser echo cancellation detection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[50/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:149:5 â€º Declarative Props API - Issue #305 â€º connectionState/autoStart props (replaces start/stop) â€º should connect when autoStartAgent is true
[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KBrowser info: {
  "userAgent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.7390.37 Safari/537.36",
  "hasGetSupportedConstraints": true,
  "hasGetSettings": true,
  "supportedConstraints": {
    "aspectRatio": true,
    "autoGainControl": true,
    "brightness": true,
    "channelCount": true,
    "colorTemperature": true,
    "contrast": true,
    "deviceId": true,
    "displaySurface": true,
    "echoCancellation": true,
    "exposureCompensation": true,
    "exposureMode": true,
    "exposureTime": true,
    "facingMode": true,
    "focusDistance": true,
    "focusMode": true,
    "frameRate": true,
    "groupId": true,
    "height": true,
    "iso": true,
    "latency": true,
    "noiseSuppression": true,
    "pan": true,
    "pointsOfInterest": true,
    "resizeMode": true,
    "restrictOwnAudio": true,
    "sampleRate": true,
    "sampleSize": true,
    "saturation": true,
    "sharpness": true,
    "suppressLocalAudioPlayback": true,
    "tilt": true,
    "torch": true,
    "voiceIsolation": true,
    "whiteBalanceMode": true,
    "width": true,
    "zoom": true
  }
}

[1A[2Kâœ… echoCancellation constraint supported: [33mtrue[39m

[1A[2Kâœ… Browser echo cancellation detection APIs available (2 detection logs)

[1A[2K[51/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:365:3 â€º Echo Cancellation Detection and Configuration â€º should validate audio constraints before applying
[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:365:3 â€º Echo Cancellation Detection and Configuration â€º should validate audio constraints before applying
ğŸ” Testing constraint validation...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
Step 5: Waiting for connection to close after idle timeout...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:365:3 â€º Echo Cancellation Detection and Configuration â€º should validate audio constraints before applying
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
â³ +1005ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:365:3 â€º Echo Cancellation Detection and Configuration â€º should validate audio constraints before applying
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Constraint validation executed (no errors for valid constraints)

[1A[2K[52/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:408:3 â€º Echo Cancellation Detection and Configuration â€º should handle different sample rates
[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:408:3 â€º Echo Cancellation Detection and Configuration â€º should handle different sample rates
ğŸ” Testing sample rate constraint...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Sample rate constraint capability documented

[1A[2K   Note: Custom sample rate test requires test-app prop support

[1A[2K[53/178] [chromium] â€º tests/e2e/echo-cancellation.spec.js:425:3 â€º Echo Cancellation Detection and Configuration â€º should prevent agent TTS from triggering itself (echo cancellation effectiveness)
[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:425:3 â€º Echo Cancellation Detection and Configuration â€º should prevent agent TTS from triggering itself (echo cancellation effectiveness)
ğŸ” Testing echo cancellation effectiveness: agent TTS should not trigger itself...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[54/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:189:5 â€º Declarative Props API - Issue #305 â€º connectionState/autoStart props (replaces start/stop) â€º should connect when connectionState prop is "connected"
[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone enabled and ready

[1A[2KğŸ“¤ Sending text message: "Tell me a short story about a robot"

[1A[2Kâ³ Waiting for agent to start speaking...

[1A[2Kâœ… Agent started speaking (TTS playing)

[1A[2Kâœ… Audio playback confirmed

[1A[2Kâ³ Waiting for agent to finish speaking...

[1A[2Kâœ… Agent finished speaking

[1A[2K[chromium] â€º tests/e2e/extended-silence-idle-timeout.spec.js:11:3 â€º Extended Silence Idle Timeout Test â€º should demonstrate connection closure with >10 seconds of silence

ğŸ“Š Idle Timeout State Analysis:

[1A[2KâŒ ISSUE #244: Timeout was never active!

[1A[2K   This indicates the idle timeout never started after UtteranceEnd

[1A[2K   Expected: timeoutActive should become true when agentIdle=true and userIdle=true

[1A[2K
ğŸ“Š Final state: agentIdle=true, userIdle=true, audioNotPlaying=true, timeoutActive=false

[1A[2Kâœ… Connection closed due to idle timeout

[1A[2K
ğŸ‰ SUCCESS: Extended silence test completed

[1A[2KğŸ’¡ This demonstrates that:

[1A[2K  1. Speech detection works via data-testid elements

[1A[2K  2. UtteranceEnd detection works via data-testid elements

[1A[2K  3. onUserStoppedSpeaking callback works via data-testid elements

[1A[2K  4. Idle timeout closes connection after speech completion

[1A[2K[55/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout
ğŸ§ª Testing microphone activation after idle timeout...

[1A[2KStep 1: Setting up test page and waiting for connection...

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
â³ +6024ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
[BROWSER] ğŸ”§ [Connection] hasSentSettingsRef and globalSettingsSent reset to false due to connection close

[1A[2K[BROWSER] Reset hasSentSettings flag due to connection close

[1A[2Kâš ï¸ SettingsApplied not received - continuing anyway (may be expected with functions)

[1A[2KğŸ“¤ Settings message captured from window (test mode)

[1A[2KğŸ“‹ Settings structure: {
  hasAgent: [33mtrue[39m,
  hasListen: [33mfalse[39m,
  hasThink: [33mtrue[39m,
  hasFunctions: [33mtrue[39m,
  functionsCount: [33m1[39m
}

[1A[2Kâœ… Functions found in Settings message (from window): [33m1[39m

[1A[2K   Function structure verified: { name: [32m'get_current_time'[39m, hasDescription: [33mtrue[39m, hasParameters: [33mtrue[39m }

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout
DEBUG: [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2KDEBUG: [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2KInitial connection status: connected

[1A[2KStep 2: Sending brief message to trigger agent response...

[1A[2KDEBUG: [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: InjectUserMessage)

[1A[2KWaiting for agent to respond and finish...

[1A[2KStep 3: Waiting for idle conditions (agent idle, user idle, audio not playing)...

[1A[2Kâœ… Idle conditions met - timeout should now be active

[1A[2KStep 4: Waiting for idle timeout after agent response...

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2Kâ³ +1003ms: Connection still connected

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2KDEBUG: ğŸµ [AUDIO] Audio context state: running

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
âœ… Connection closed after 9037ms (expected: ~10000ms)

[1A[2Kâœ… Timeout timing within expected range: 9037ms

[1A[2KStep 6: Sending "hi" via text input...

[1A[2Kâœ… Reconnected after text input

[1A[2Kâœ… Sent "hi" message

[1A[2KStep 7: Waiting for agent response...

[1A[2Kâœ… Agent started responding

[1A[2Kâœ… Agent finished responding

[1A[2KStep 8: Waiting for agent to finish responding...

[1A[2KStep 9: Waiting for connection to close after response...

[1A[2K[chromium] â€º tests/e2e/echo-cancellation.spec.js:425:3 â€º Echo Cancellation Detection and Configuration â€º should prevent agent TTS from triggering itself (echo cancellation effectiveness)
ğŸ“Š Echo Cancellation Test Results:

[1A[2K   - Total UserStartedSpeaking events: 8

[1A[2K   - Events during TTS playback: 4

[1A[2K   - Transcript updates during TTS: 0

[1A[2K   - Initial transcript: "(Waiting for transcript...)"

[1A[2K   - Final transcript: "(Waiting for transcript...)"

[1A[2K   - TTS duration: 47ms

[1A[2Kâš ï¸ WARNING: UserStartedSpeaking events detected DURING agent TTS playback

[1A[2K   This indicates echo cancellation may not be working properly

[1A[2K   Events during TTS: [
  { timestamp: [33m1767045903443[39m, value: [32m'22:05:03'[39m },
  { timestamp: [33m1767045903942[39m, value: [32m'22:05:03'[39m },
  { timestamp: [33m1767045904467[39m, value: [32m'22:05:03'[39m },
  { timestamp: [33m1767045904943[39m, value: [32m'22:05:03'[39m }
]

[1A[2Kâœ… No transcript updates during agent TTS - echo cancellation filtering working

[1A[2Kâœ… Echo cancellation test completed

[1A[2K   Note: Real-world testing with speakers needed for definitive echo cancellation verification

[1A[2K[56/178] [chromium] â€º tests/e2e/idle-timeout-during-agent-speech.spec.js:35:3 â€º Idle Timeout During Agent Speech â€º should NOT timeout while agent is actively speaking
[1A[2K[chromium] â€º tests/e2e/idle-timeout-during-agent-speech.spec.js:35:3 â€º Idle Timeout During Agent Speech â€º should NOT timeout while agent is actively speaking
ğŸ§ª Testing idle timeout during agent speech...

[1A[2KStep 1: Setting up test page and establishing connection...

[1A[2K[57/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:223:5 â€º Declarative Props API - Issue #305 â€º connectionState/autoStart props (replaces start/stop) â€º should disconnect when connectionState prop is "disconnected"
[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:37:3 â€º Greeting Idle Timeout â€º should timeout after greeting completes (Issue #139)
âœ… Connection closed after 1003ms (expected: ~10000ms)

[1A[2Kâš ï¸  Timeout timing outside expected range: 1003ms (expected: 5000-15000ms)

[1A[2K
âœ… SUCCESS: Issue #139 is fixed - idle timeout works correctly after agent speech

[1A[2K[58/178] [chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:133:3 â€º Greeting Idle Timeout â€º should timeout after initial greeting on page load
[1A[2K[chromium] â€º tests/e2e/idle-timeout-during-agent-speech.spec.js:35:3 â€º Idle Timeout During Agent Speech â€º should NOT timeout while agent is actively speaking
Initial connection status: connected

[1A[2KStep 2: Sending text message for long response...

[1A[2Kâœ… Sent text message requesting long response

[1A[2KStep 3: Waiting for agent to start responding...

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:133:3 â€º Greeting Idle Timeout â€º should timeout after initial greeting on page load
AudioContext state after greeting: undefined

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout
â³ +6022ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:133:3 â€º Greeting Idle Timeout â€º should timeout after initial greeting on page load
â³ +1005ms: Connection still connected

[1A[2K[59/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:278:5 â€º Declarative Props API - Issue #305 â€º function call response via callback return value â€º should handle function call response via callback return value
[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it
âš ï¸ SettingsApplied not received - this may be expected when functions are included

[1A[2K   Deepgram may have validation issues with function definitions

[1A[2K   However, functions ARE being sent in Settings message (verified via component)

[1A[2Kâ³ Waiting for FunctionCallRequest via component callback...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout
â³ +11046ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:133:3 â€º Greeting Idle Timeout â€º should timeout after initial greeting on page load
â³ +6025ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout
DEBUG: ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2Kâœ… Connection closed after 13059ms (expected: ~10000ms)

[1A[2KConnection status after timeout: closed

[1A[2KStep 5: Attempting to activate microphone...

[1A[2KMic status before click: Disabled

[1A[2Kâœ… Clicked microphone button

[1A[2KStep 6: Waiting for reconnection and mic activation (up to 5 seconds)...

[1A[2KDEBUG: [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2KDEBUG: [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2KDEBUG: [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2KDEBUG: [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[60/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:381:5 â€º Declarative Props API - Issue #305 â€º function call response via callback return value â€º should handle async function call response via Promise return
[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:133:3 â€º Greeting Idle Timeout â€º should timeout after initial greeting on page load
âœ… Connection closed after 11047ms (expected: ~10000ms)

[1A[2Kâœ… Timeout timing within expected range: 11047ms

[1A[2Kâœ… Connection closed after 11047ms (expected: ~10000ms)

[1A[2K[61/178] [chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:166:3 â€º Greeting Idle Timeout â€º should NOT play greeting if AudioContext is suspended
[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:166:3 â€º Greeting Idle Timeout â€º should NOT play greeting if AudioContext is suspended
âœ… Greeting sent

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:50:3 â€º Idle Timeout Behavior â€º should handle microphone activation after idle timeout

ğŸ“Š FINAL STATE:

[1A[2K  Microphone: Enabled

[1A[2K  Connection: connected

[1A[2K  Errors captured: 1

[1A[2K  Debug logs captured: 134

[1A[2K
ğŸš¨ ERRORS:

[1A[2K  1. [AudioManager] ğŸš¨ CLEARING AUDIO QUEUE - EMERGENCY STOP ğŸš¨

[1A[2K
ğŸ” DEBUG LOGS:

[1A[2K  1. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  2. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  3. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: InjectUserMessage)

[1A[2K  4. ğŸµ [AUDIO] Audio context state: running

[1A[2K  5. ğŸµ [AUDIO] Audio context state: running

[1A[2K  6. ğŸµ [AUDIO] Audio context state: running

[1A[2K  7. ğŸµ [AUDIO] Audio context state: running

[1A[2K  8. ğŸµ [AUDIO] Audio context state: running

[1A[2K  9. ğŸµ [AUDIO] Audio context state: running

[1A[2K  10. ğŸµ [AUDIO] Audio context state: running

[1A[2K  11. ğŸµ [AUDIO] Audio context state: running

[1A[2K  12. ğŸµ [AUDIO] Audio context state: running

[1A[2K  13. ğŸµ [AUDIO] Audio context state: running

[1A[2K  14. ğŸµ [AUDIO] Audio context state: running

[1A[2K  15. ğŸµ [AUDIO] Audio context state: running

[1A[2K  16. ğŸµ [AUDIO] Audio context state: running

[1A[2K  17. ğŸµ [AUDIO] Audio context state: running

[1A[2K  18. ğŸµ [AUDIO] Audio context state: running

[1A[2K  19. ğŸµ [AUDIO] Audio context state: running

[1A[2K  20. ğŸµ [AUDIO] Audio context state: running

[1A[2K  21. ğŸµ [AUDIO] Audio context state: running

[1A[2K  22. ğŸµ [AUDIO] Audio context state: running

[1A[2K  23. ğŸµ [AUDIO] Audio context state: running

[1A[2K  24. ğŸµ [AUDIO] Audio context state: running

[1A[2K  25. ğŸµ [AUDIO] Audio context state: running

[1A[2K  26. ğŸµ [AUDIO] Audio context state: running

[1A[2K  27. ğŸµ [AUDIO] Audio context state: running

[1A[2K  28. ğŸµ [AUDIO] Audio context state: running

[1A[2K  29. ğŸµ [AUDIO] Audio context state: running

[1A[2K  30. ğŸµ [AUDIO] Audio context state: running

[1A[2K  31. ğŸµ [AUDIO] Audio context state: running

[1A[2K  32. ğŸµ [AUDIO] Audio context state: running

[1A[2K  33. ğŸµ [AUDIO] Audio context state: running

[1A[2K  34. ğŸµ [AUDIO] Audio context state: running

[1A[2K  35. ğŸµ [AUDIO] Audio context state: running

[1A[2K  36. ğŸµ [AUDIO] Audio context state: running

[1A[2K  37. ğŸµ [AUDIO] Audio context state: running

[1A[2K  38. ğŸµ [AUDIO] Audio context state: running

[1A[2K  39. ğŸµ [AUDIO] Audio context state: running

[1A[2K  40. ğŸµ [AUDIO] Audio context state: running

[1A[2K  41. ğŸµ [AUDIO] Audio context state: running

[1A[2K  42. ğŸµ [AUDIO] Audio context state: running

[1A[2K  43. ğŸµ [AUDIO] Audio context state: running

[1A[2K  44. ğŸµ [AUDIO] Audio context state: running

[1A[2K  45. ğŸµ [AUDIO] Audio context state: running

[1A[2K  46. ğŸµ [AUDIO] Audio context state: running

[1A[2K  47. ğŸµ [AUDIO] Audio context state: running

[1A[2K  48. ğŸµ [AUDIO] Audio context state: running

[1A[2K  49. ğŸµ [AUDIO] Audio context state: running

[1A[2K  50. ğŸµ [AUDIO] Audio context state: running

[1A[2K  51. ğŸµ [AUDIO] Audio context state: running

[1A[2K  52. ğŸµ [AUDIO] Audio context state: running

[1A[2K  53. ğŸµ [AUDIO] Audio context state: running

[1A[2K  54. ğŸµ [AUDIO] Audio context state: running

[1A[2K  55. ğŸµ [AUDIO] Audio context state: running

[1A[2K  56. ğŸµ [AUDIO] Audio context state: running

[1A[2K  57. ğŸµ [AUDIO] Audio context state: running

[1A[2K  58. ğŸµ [AUDIO] Audio context state: running

[1A[2K  59. ğŸµ [AUDIO] Audio context state: running

[1A[2K  60. ğŸµ [AUDIO] Audio context state: running

[1A[2K  61. ğŸµ [AUDIO] Audio context state: running

[1A[2K  62. ğŸµ [AUDIO] Audio context state: running

[1A[2K  63. ğŸµ [AUDIO] Audio context state: running

[1A[2K  64. ğŸµ [AUDIO] Audio context state: running

[1A[2K  65. ğŸµ [AUDIO] Audio context state: running

[1A[2K  66. ğŸµ [AUDIO] Audio context state: running

[1A[2K  67. ğŸµ [AUDIO] Audio context state: running

[1A[2K  68. ğŸµ [AUDIO] Audio context state: running

[1A[2K  69. ğŸµ [AUDIO] Audio context state: running

[1A[2K  70. ğŸµ [AUDIO] Audio context state: running

[1A[2K  71. ğŸµ [AUDIO] Audio context state: running

[1A[2K  72. ğŸµ [AUDIO] Audio context state: running

[1A[2K  73. ğŸµ [AUDIO] Audio context state: running

[1A[2K  74. ğŸµ [AUDIO] Audio context state: running

[1A[2K  75. ğŸµ [AUDIO] Audio context state: running

[1A[2K  76. ğŸµ [AUDIO] Audio context state: running

[1A[2K  77. ğŸµ [AUDIO] Audio context state: running

[1A[2K  78. ğŸµ [AUDIO] Audio context state: running

[1A[2K  79. ğŸµ [AUDIO] Audio context state: running

[1A[2K  80. ğŸµ [AUDIO] Audio context state: running

[1A[2K  81. ğŸµ [AUDIO] Audio context state: running

[1A[2K  82. ğŸµ [AUDIO] Audio context state: running

[1A[2K  83. ğŸµ [AUDIO] Audio context state: running

[1A[2K  84. ğŸµ [AUDIO] Audio context state: running

[1A[2K  85. ğŸµ [AUDIO] Audio context state: running

[1A[2K  86. ğŸµ [AUDIO] Audio context state: running

[1A[2K  87. ğŸµ [AUDIO] Audio context state: running

[1A[2K  88. ğŸµ [AUDIO] Audio context state: running

[1A[2K  89. ğŸµ [AUDIO] Audio context state: running

[1A[2K  90. ğŸµ [AUDIO] Audio context state: running

[1A[2K  91. ğŸµ [AUDIO] Audio context state: running

[1A[2K  92. ğŸµ [AUDIO] Audio context state: running

[1A[2K  93. ğŸµ [AUDIO] Audio context state: running

[1A[2K  94. ğŸµ [AUDIO] Audio context state: running

[1A[2K  95. ğŸµ [AUDIO] Audio context state: running

[1A[2K  96. ğŸµ [AUDIO] Audio context state: running

[1A[2K  97. ğŸµ [AUDIO] Audio context state: running

[1A[2K  98. ğŸµ [AUDIO] Audio context state: running

[1A[2K  99. ğŸµ [AUDIO] Audio context state: running

[1A[2K  100. ğŸµ [AUDIO] Audio context state: running

[1A[2K  101. ğŸµ [AUDIO] Audio context state: running

[1A[2K  102. ğŸµ [AUDIO] Audio context state: running

[1A[2K  103. ğŸµ [AUDIO] Audio context state: running

[1A[2K  104. ğŸµ [AUDIO] Audio context state: running

[1A[2K  105. ğŸµ [AUDIO] Audio context state: running

[1A[2K  106. ğŸµ [AUDIO] Audio context state: running

[1A[2K  107. ğŸµ [AUDIO] Audio context state: running

[1A[2K  108. ğŸµ [AUDIO] Audio context state: running

[1A[2K  109. ğŸµ [AUDIO] Audio context state: running

[1A[2K  110. ğŸµ [AUDIO] Audio context state: running

[1A[2K  111. ğŸµ [AUDIO] Audio context state: running

[1A[2K  112. ğŸµ [AUDIO] Audio context state: running

[1A[2K  113. ğŸµ [AUDIO] Audio context state: running

[1A[2K  114. ğŸµ [AUDIO] Audio context state: running

[1A[2K  115. ğŸµ [AUDIO] Audio context state: running

[1A[2K  116. ğŸµ [AUDIO] Audio context state: running

[1A[2K  117. ğŸµ [AUDIO] Audio context state: running

[1A[2K  118. ğŸµ [AUDIO] Audio context state: running

[1A[2K  119. ğŸµ [AUDIO] Audio context state: running

[1A[2K  120. ğŸµ [AUDIO] Audio context state: running

[1A[2K  121. ğŸµ [AUDIO] Audio context state: running

[1A[2K  122. ğŸµ [AUDIO] Audio context state: running

[1A[2K  123. ğŸµ [AUDIO] Audio context state: running

[1A[2K  124. ğŸµ [AUDIO] Audio context state: running

[1A[2K  125. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K  126. ğŸµ [AUDIO] Audio context state: running

[1A[2K  127. ğŸµ [AUDIO] Audio context state: running

[1A[2K  128. ğŸµ [AUDIO] Audio context state: running

[1A[2K  129. ğŸµ [AUDIO] Audio context state: running

[1A[2K  130. ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2K  131. [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  132. [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  133. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  134. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K
ğŸ” VALIDATING EXPECTED BEHAVIOR:

[1A[2KAsserting microphone is enabled after reconnection attempt...

[1A[2Kâœ… Microphone successfully enabled

[1A[2Kâœ… Connection established

[1A[2Kâœ… Test passed: Microphone activation after idle timeout works correctly!

[1A[2K[62/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:168:3 â€º Idle Timeout Behavior â€º should show loading state during reconnection attempt
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:168:3 â€º Idle Timeout Behavior â€º should show loading state during reconnection attempt
ğŸ§ª Testing loading state during reconnection...

[1A[2K[chromium] â€º tests/e2e/greeting-idle-timeout.spec.js:166:3 â€º Greeting Idle Timeout â€º should NOT play greeting if AudioContext is suspended
AudioContext state: running

[1A[2KGreeting audio played: true

[1A[2Kâœ… Test passed: AudioContext running, greeting audio played

[1A[2K[63/178] [chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ§ª Testing interim and final transcript receipt with fake audio...

[1A[2KğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2K[WebServer] [Proxy] New client connection from ::1
[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2K[WebServer] [DEBUG] Service type detected: transcription (from query: transcription, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing transcription service to wss://api.deepgram.com/v1/listen

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): [
[WebServer]   [ 'model', 'nova-3' ],
[WebServer]   [ 'language', 'en-US' ],
[WebServer]   [ 'smart_format', 'true' ],
[WebServer]   [ 'interim_results', 'true' ],
[WebServer]   [ 'diarize', 'true' ],
[WebServer]   [ 'channels', '1' ],
[WebServer]   [ 'vad_events', 'true' ],
[WebServer]   [ 'utterance_end_ms', '1000' ],
[WebServer]   [ 'sample_rate', '16000' ],
[WebServer]   [ 'encoding', 'linear16' ]
[WebServer] ]

[1A[2K[WebServer] [Proxy] Connecting to Deepgram transcription service at wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16...

[1A[2K[WebServer] [Proxy] New client connection from ::1

[1A[2K[WebServer] [DEBUG] Connection received from ::1, URL: /deepgram-proxy?service=agent

[1A[2K[WebServer] [DEBUG] Service type detected: agent (from query: agent, pathname: /deepgram-proxy)

[1A[2K[WebServer] [DEBUG] Routing agent service to wss://agent.deepgram.com/v1/agent/converse

[1A[2K[WebServer] [DEBUG] Forwarding query params to Deepgram (excluding service/token): []

[1A[2K[WebServer] [Proxy] Connecting to Deepgram agent service at wss://agent.deepgram.com/v1/agent/converse...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2K[WebServer] [Proxy] ğŸ“¤ Settings message received from client!
[WebServer] [Proxy] ğŸ“¤ Client state: 1, Deepgram state: 0

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing Settings message

[1A[2K[WebServer] [Proxy] âš ï¸ Settings message queued (Deepgram not ready yet)

[1A[2K[WebServer] [Proxy] Deepgram not ready (state: 0), queuing binary message

[1A[2K[WebServer] [Proxy] Connected to Deepgram transcription service
[WebServer] [Proxy] Client â†’ Deepgram (queued): binary message (320 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K  1) [chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it 

    [31mTest timeout of 30000ms exceeded.[39m

    Error: page.waitForFunction: Test timeout of 30000ms exceeded.

      303 |     
      304 |     // Wait for function call request with timeout
    > 305 |     await page.waitForFunction(
          |                ^
      306 |       () => window.functionCallRequests && window.functionCallRequests.length > 0,
      307 |       { timeout: 20000 }
      308 |     );
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/function-calling-e2e.spec.js:305:16

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/function-calling-e2e-Funct-c74e6-unction-call-and-execute-it-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/function-calling-e2e-Funct-c74e6-unction-call-and-execute-it-chromium/error-context.md


[1A[2K[WebServer] [Proxy] Connected to Deepgram agent service

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram (queued): Settings message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Welcome message

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:168:3 â€º Idle Timeout Behavior â€º should show loading state during reconnection attempt
Waiting for idle timeout...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SettingsApplied message
[WebServer] [Proxy] âœ… SettingsApplied received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (408 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: âš™ï¸  suppress all logs with { quiet: true }

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:59936) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[64/178] [chromium] â€º tests/e2e/function-calling-e2e.spec.js:365:3 â€º Function Calling E2E Tests â€º should verify functions are included in Settings message
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:365:3 â€º Function Calling E2E Tests â€º should verify functions are included in Settings message
ğŸ§ª Testing that functions are included in Settings message...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:365:3 â€º Function Calling E2E Tests â€º should verify functions are included in Settings message
âœ… Connection established

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2Kâœ… Connection established and settings applied

[1A[2KğŸ¤ Loading and streaming pre-recorded audio sample (human speech): shopping-concierge-question...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/declarative-props-api.spec.js:381:5 â€º Declarative Props API - Issue #305 â€º function call response via callback return value â€º should handle async function call response via Promise return
âš ï¸ Function call not received within timeout - this is acceptable

[1A[2K   The async handler is set up correctly and will work when a function call occurs

[1A[2K[65/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:477:5 â€º Declarative Props API - Issue #305 â€º interruptAgent prop (replaces interruptAgent method) â€º should interrupt TTS when interruptAgent prop is true
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message
[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Hello?, transcriptLength: 6}

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message
[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Okay., transcriptLength: 5}

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: You, transcriptLength: 3}

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: help?, transcriptLength: 5}

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message
[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (320 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Me?, transcriptLength: 3}

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Find a, transcriptLength: 6}

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message
[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:365:3 â€º Function Calling E2E Tests â€º should verify functions are included in Settings message
ğŸ“‹ Captured Settings message from window (test mode)

[1A[2KğŸ” [COMPARISON] Full Settings message sent to Deepgram:

[1A[2K{
  "type": "Settings",
  "audio": {
    "input": {
      "encoding": "linear16",
      "sample_rate": 16000
    },
    "output": {
      "encoding": "linear16",
      "sample_rate": 24000
    }
  },
  "agent": {
    "language": "en",
    "think": {
      "provider": {
        "type": "open_ai",
        "model": "gpt-4o-mini"
      },
      "prompt": "You are a helpful voice assistant. Keep your responses concise and informative."
    },
    "speak": {
      "provider": {
        "type": "deepgram",
        "model": "aura-asteria-en"
      }
    },
    "greeting": "Hello! How can I assist you today?"
  }
}

[1A[2KğŸ“Š WebSocket capture summary: {
  url: [32m'wss://agent.deepgram.com/v1/agent/converse?service=agent'[39m,
  sentCount: [33m2[39m,
  receivedCount: [33m218[39m,
  sentTypes: [ [32m'Settings'[39m, [32m'InjectUserMessage'[39m ],
  receivedTypes: [
    [32m'connected'[39m,       [32m'Welcome'[39m,          [32m'Welcome'[39m,
    [32m'SettingsApplied'[39m, [32m'ConversationText'[39m, [32m'History'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,          [32m'binary'[39m,           [32m'binary'[39m,
    [32m'binary'[39m,
    ... 118 more items
  ]
}

[1A[2KğŸ“‹ Using Settings message from window (test mode) - most reliable

[1A[2KâŒ Functions NOT found in Settings message (from window)

[1A[2K   Settings structure: { hasAgent: [33mtrue[39m, hasThink: [33mtrue[39m, thinkKeys: [ [32m'provider'[39m, [32m'prompt'[39m ] }

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: gift, transcriptLength: 4}

[1A[2K  2) [chromium] â€º tests/e2e/function-calling-e2e.spec.js:365:3 â€º Function Calling E2E Tests â€º should verify functions are included in Settings message 

    Error: Functions not found in Settings message - this indicates functions are not being included

      544 |           thinkKeys: settings.agent?.think ? Object.keys(settings.agent.think) : []
      545 |         });
    > 546 |         throw new Error('Functions not found in Settings message - this indicates functions are not being included');
          |               ^
      547 |       }
      548 |     } else {
      549 |       // FALLBACK: Try WebSocket capture (may not work in proxy mode)
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/function-calling-e2e.spec.js:546:15

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/function-calling-e2e-Funct-1f766-ncluded-in-Settings-message-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/function-calling-e2e-Funct-1f766-ncluded-in-Settings-message-chromium/error-context.md


[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: ğŸ” encrypt with Dotenvx: https://dotenvx.com

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:60172) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[66/178] [chromium] â€º tests/e2e/function-calling-e2e.spec.js:603:3 â€º Function Calling E2E Tests â€º should test minimal function definition for SettingsApplied issue
[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: for my, transcriptLength: 6}

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)
[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:603:3 â€º Function Calling E2E Tests â€º should test minimal function definition for SettingsApplied issue
ğŸ§ª Testing minimal function definition to isolate SettingsApplied issue...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2KğŸ” Step 0: Waiting for component to be ready...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (4096 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (1706 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (1706 bytes)

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
âœ… Audio sample streamed: shopping-concierge-question

[1A[2Kâ³ Waiting for UserStartedSpeaking...

[1A[2Kâœ… UserStartedSpeaking detected: 22:05:29

[1A[2Kâ³ Waiting for UtteranceEnd...

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UserStartedSpeaking message

[1A[2K[WebServer] [Proxy] ğŸ¤ UserStartedSpeaking received from Deepgram, forwarding to client

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: friend's, transcriptLength: 8}

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[67/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:525:5 â€º Declarative Props API - Issue #305 â€º interruptAgent prop (replaces interruptAgent method) â€º should trigger onAgentInterrupted callback when TTS is interrupted
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: birthday?, transcriptLength: 9}

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:603:3 â€º Function Calling E2E Tests â€º should test minimal function definition for SettingsApplied issue
ğŸ” Step 1: Focusing text input to trigger onFocus handler (matches manual test)...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: UtteranceEnd message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2Kâœ… UtteranceEnd detected: Channel: [0,1], Last word end: 9.51s

[1A[2K
ğŸ“Š === VAD EVENTS ===

[1A[2KğŸ¤ UserStartedSpeaking: 22:05:29

[1A[2KğŸ”š UtteranceEnd: Channel: [0,1], Last word end: 9.51s

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:603:3 â€º Function Calling E2E Tests â€º should test minimal function definition for SettingsApplied issue
[BROWSER SETTINGS] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message

[1A[2K[BROWSER SETTINGS] ğŸ“¤ [Protocol] Settings message sent successfully (sendJSON returned true)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (768 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: ConversationText message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: History message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)
[WebServer] [Proxy] Deepgram â†’ Client: binary message (960 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: binary message (498 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: AgentAudioDone message

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:603:3 â€º Function Calling E2E Tests â€º should test minimal function definition for SettingsApplied issue
ğŸ” Step 2: Waiting for connection to be established...

[1A[2Kâœ… Connection established

[1A[2KğŸ” Step 3: Checking if functions are in agentOptions before waiting for SettingsApplied...

[1A[2KğŸ” AgentOptions check: { hasLastSettings: [33mtrue[39m, hasLastFunctions: [33mfalse[39m, testMode: [33mtrue[39m }

[1A[2KğŸ” Step 4: Waiting for SettingsApplied (matches manual test flow)...

[1A[2Kâœ… SettingsApplied received

[1A[2KğŸ” Step 4: Now filling and sending message (after SettingsApplied)...

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (320 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2KğŸ“Š Transcript count changed: 0 -> 10

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2KğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: SpeechStarted message

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:168:3 â€º Idle Timeout Behavior â€º should show loading state during reconnection attempt
Clicking microphone and checking for loading state...

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:603:3 â€º Function Calling E2E Tests â€º should test minimal function definition for SettingsApplied issue
ğŸ” Debug (attempt 1): Test mode=true, hasPayload=true, hasParsed=true

[1A[2KğŸ” Debug: All DEEPGRAM/SETTINGS keys: [
  [32m'__DEEPGRAM_TEST_MODE__'[39m,
  [32m'__DEEPGRAM_LAST_SETTINGS__'[39m,
  [32m'__DEEPGRAM_LAST_FUNCTIONS__'[39m,
  [32m'__DEEPGRAM_WS_SETTINGS_PAYLOAD__'[39m,
  [32m'__DEEPGRAM_WS_SETTINGS_PARSED__'[39m
]

[1A[2Kâœ… Captured Settings message from WebSocketManager (exact JSON string)

[1A[2KğŸ“‹ Payload length: [33m428[39m

[1A[2KğŸ“‹ Captured Settings JSON string (exact WebSocket payload):

[1A[2K{"type":"Settings","audio":{"input":{"encoding":"linear16","sample_rate":16000},"output":{"encoding":"linear16","sample_rate":24000}},"agent":{"language":"en","think":{"provider":{"type":"open_ai","model":"gpt-4o-mini"},"prompt":"You are a helpful voice assistant. Keep your responses concise and informative."},"speak":{"provider":{"type":"deepgram","model":"aura-asteria-en"}},"greeting":"Hello! How can I assist you today?"}}

[1A[2Kâš ï¸ Could not capture Settings message from WebSocketManager

[1A[2K   This may indicate the enhanced logging needs to be checked

[1A[2K   However, unit tests confirm functions are being sent correctly

[1A[2K   Proceeding to test SettingsApplied reception...

[1A[2Kâœ… SettingsApplied received with minimal function!

[1A[2KğŸ‰ Minimal function test completed

[1A[2K[68/178] [chromium] â€º tests/e2e/function-calling-e2e.spec.js:852:3 â€º Function Calling E2E Tests â€º should test minimal function with explicit required array
[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Client â†’ Deepgram: binary message (8192 bytes)

[1A[2K[WebServer] [Proxy] Deepgram â†’ Client: Results message

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
ğŸ“¢ Browser console: [TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)

[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:852:3 â€º Function Calling E2E Tests â€º should test minimal function with explicit required array
ğŸ§ª Testing minimal function with explicit required array...

[1A[2K[chromium] â€º tests/e2e/interim-transcript-validation.spec.js:32:3 â€º Interim Transcript Validation â€º should receive both interim and final transcripts with fake audio
âœ… Transcript count stabilized at 10 after 1500ms

[1A[2K
ğŸ“Š === TRANSCRIPT VALIDATION ===

[1A[2KğŸ“ Total transcripts captured: [33m10[39m

[1A[2KğŸ“‹ Raw transcripts array: [
  {
    "text": "Hello?",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045927489
  },
  {
    "text": "Okay.",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045928028
  },
  {
    "text": "You",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045928329
  },
  {
    "text": "help?",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045928720
  },
  {
    "text": "Me?",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045929157
  },
  {
    "text": "Find a",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045929550
  },
  {
    "text": "gift",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045930017
  },
  {
    "text": "for my",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045930367
  },
  {
    "text": "friend's",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045931203
  },
  {
    "text": "birthday?",
    "is_final": true,
    "speech_final": true,
    "timestamp": 1767045932027
  }
]

[1A[2KğŸ“¢ Captured console messages: [33m24[39m messages

[1A[2KğŸ“¢ First few console messages: [
  [32m'[TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Skipping empty transcript (interim result with no text yet)'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Hello?, transcriptLength: 6}'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: Okay., transcriptLength: 5}'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: You, transcriptLength: 3}'[39m,
  [32m'[TRANSCRIPT-CALLBACK] Received final transcript: {type: transcript, is_final: true, speech_final: true, transcript: help?, transcriptLength: 5}'[39m
]

[1A[2KğŸ“ Final transcripts: [33m10[39m

[1A[2KğŸ“ Interim transcripts: [33m0[39m

[1A[2Kâœ… Complete final transcript identified by speech_final=true

[1A[2K
ğŸ“‹ === COMPLETE FINAL TRANSCRIPT ===

[1A[2KğŸ“ Text: "birthday?"

[1A[2KğŸ“Š Properties: {
  is_final: [33mtrue[39m,
  speech_final: [33mtrue[39m,
  timestamp: [33m1767045932027[39m,
  length: [33m9[39m
}

[1A[2K
ğŸ“‹ === ALL FINAL TRANSCRIPTS (for comparison) ===

[1A[2K1.   "Hello?" (is_final: true, speech_final: true)

[1A[2K2.   "Okay." (is_final: true, speech_final: true)

[1A[2K3.   "You" (is_final: true, speech_final: true)

[1A[2K4.   "help?" (is_final: true, speech_final: true)

[1A[2K5.   "Me?" (is_final: true, speech_final: true)

[1A[2K6.   "Find a" (is_final: true, speech_final: true)

[1A[2K7.   "gift" (is_final: true, speech_final: true)

[1A[2K8.   "for my" (is_final: true, speech_final: true)

[1A[2K9.   "friend's" (is_final: true, speech_final: true)

[1A[2K10. â˜… "birthday?" (is_final: true, speech_final: true)

[1A[2K
ğŸ” === ALL TRANSCRIPTS SUMMARY ===

[1A[2Kis_final values received: [
  {
    text: [32m'Hello?'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045927489[39m
  },
  {
    text: [32m'Okay.'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045928028[39m
  },
  {
    text: [32m'You'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045928329[39m
  },
  {
    text: [32m'help?'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045928720[39m
  },
  {
    text: [32m'Me?'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045929157[39m
  },
  {
    text: [32m'Find a'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045929550[39m
  },
  {
    text: [32m'gift'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045930017[39m
  },
  {
    text: [32m'for my'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045930367[39m
  },
  {
    text: [32m"friend's"[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045931203[39m
  },
  {
    text: [32m'birthday?'[39m,
    is_final: [33mtrue[39m,
    speech_final: [33mtrue[39m,
    is_final_type: [32m'boolean'[39m,
    timestamp: [33m1767045932027[39m
  }
]

[1A[2Kâš ï¸ [NOTE] No interim transcripts received - this may indicate streaming issues

[1A[2K   Expected: Real-time streaming should produce interim transcripts

[1A[2K   Check: Audio streaming implementation and chunk intervals

[1A[2K   Reference: See working test in vad-transcript-analysis.spec.js for streaming pattern

[1A[2K   Test will continue to validate final transcript handling...

[1A[2Kâœ… Final transcripts validated: [33m10[39m

[1A[2Kâœ… All transcripts contain valid text

[1A[2K
âœ… All transcript validations passed!

[1A[2K[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued
[WebServer] [Proxy] Client connection closed: 1001 
[WebServer] [Proxy] Client connection closed - messages sent to Deepgram: 0 queued, messages received from Deepgram: 0 queued

[1A[2K[69/178] [chromium] â€º tests/e2e/js-error-test.spec.js:11:3 â€º JavaScript Error Tests â€º should check for JavaScript errors
[1A[2K[chromium] â€º tests/e2e/function-calling-e2e.spec.js:852:3 â€º Function Calling E2E Tests â€º should test minimal function with explicit required array
âœ… Connection established

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:168:3 â€º Idle Timeout Behavior â€º should show loading state during reconnection attempt
Button text during operation: Disable Mic

[1A[2KShows loading/disabled state: false

[1A[2K[WebServer] [Proxy] Deepgram agent connection closed: 1001 

[1A[2K[70/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:575:5 â€º Declarative Props API - Issue #305 â€º interruptAgent prop (replaces interruptAgent method) â€º should clear interruptAgent after onAgentInterrupted is called
[1A[2K  3) [chromium] â€º tests/e2e/idle-timeout-during-agent-speech.spec.js:35:3 â€º Idle Timeout During Agent Speech â€º should NOT timeout while agent is actively speaking 

    [31mTest timeout of 30000ms exceeded.[39m

    Error: page.waitForFunction: Test timeout of 30000ms exceeded.

      74 |     
      75 |     // Wait for agent response to appear and start growing
    > 76 |     await page.waitForFunction(() => {
         |                ^
      77 |       const agentResponse = document.querySelector('[data-testid="agent-response"]');
      78 |       return agentResponse?.textContent && agentResponse.textContent.length > 100;
      79 |     }, { timeout: 15000 });
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/idle-timeout-during-agent-speech.spec.js:76:16

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/idle-timeout-during-agent--7f6ff--agent-is-actively-speaking-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/idle-timeout-during-agent--7f6ff--agent-is-actively-speaking-chromium/error-context.md


[1A[2K  4) [chromium] â€º tests/e2e/function-calling-e2e.spec.js:852:3 â€º Function Calling E2E Tests â€º should test minimal function with explicit required array 

    ReferenceError: functions is not defined

      917 |     
      918 |     // Verify function has explicit required array (if captured)
    > 919 |     if (settingsFromWindow && functions) {
          |                               ^
      920 |       expect(functions.length).toBe(1);
      921 |       
      922 |       const func = functions[0];
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/function-calling-e2e.spec.js:919:31

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/function-calling-e2e-Funct-c02df-ith-explicit-required-array-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/function-calling-e2e-Funct-c02df-ith-explicit-required-array-chromium/error-context.md


[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: ğŸ”„ add secrets lifecycle management: https://dotenvx.com/ops

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:60470) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: âš™ï¸  suppress all logs with { quiet: true }

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:60471) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[71/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:33:3 â€º Lazy Initialization E2E Tests â€º should not create WebSocket managers during component initialization
[1A[2K[72/178] [chromium] â€º tests/e2e/logging-behavior.spec.js:6:3 â€º Logging Behavior Tests â€º should log event log entries to console
[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:6:3 â€º Logging Behavior Tests â€º should log event log entries to console
ğŸ§ª Testing console logging synchronization...

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:33:3 â€º Lazy Initialization E2E Tests â€º should not create WebSocket managers during component initialization
ğŸ” Testing that no managers are created during component mount (before onReady)...

[1A[2KğŸ” Manager creation times: []

[1A[2KğŸ” Ready callback times: []

[1A[2KğŸ” Managers created before onReady: [33m0[39m

[1A[2KğŸ” Connection status before onReady: closed

[1A[2Kâœ… Verified: No managers created during component mount (before onReady callback)

[1A[2K[73/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:117:3 â€º Lazy Initialization E2E Tests â€º should create agent manager when start() is called with agent flag
[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:117:3 â€º Lazy Initialization E2E Tests â€º should create agent manager when start() is called with agent flag
ğŸ” Testing start() with agent flag...

[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:6:3 â€º Logging Behavior Tests â€º should log event log entries to console
Debug info: {
  eventLogExists: [33mtrue[39m,
  eventLogHTML: [32m'<h3 style="color: rgb(226, 232, 240);">Event Log</h3><button style="margin-bottom: 10px; pointer-events: auto; background-color: rgb(74, 85, 104); color: rgb(226, 232, 240); border: 1px solid rgb(45, 55, 72); padding: 5px 10px; border-radius: 4px;">Clear Logs</button><pre style="max-height: 300px; overflow-y: scroll; background: rgb(45, 55, 72); padding: 5px; color: rgb(226, 232, 240); border: 1px solid rgb(74, 85, 104); border-radius: 4px;">22:05:38 - Component is ready\n'[39m +
    [32m'22:05:38 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...\n'[39m +
    [32m'22:05:38 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...\n'[39m +
    [32m'22:05:38 - Audio playback: stopped - Agent playback completed\n'[39m +
    [32m'22:05:38 - Agent state changed: idle\n'[39m +
    [32m'22:05:38 - Component is not ready</pre>'[39m,
  allTestIds: [
    [32m'voice-agent'[39m,
    [32m'deepgram-component'[39m,
    [32m'agent-state'[39m,
    [32m'api-mode-indicator'[39m,
    [32m'audio-playing-status'[39m,
    [32m'component-ready-status'[39m,
    [32m'auto-connect-states'[39m,
    [32m'mic-status'[39m,
    [32m'agent-speaking'[39m,
    [32m'agent-silent'[39m,
    [32m'vad-states'[39m,
    [32m'user-started-speaking'[39m,
    [32m'user-stopped-speaking'[39m,
    [32m'utterance-end'[39m,
    [32m'idle-timeout-state'[39m,
    [32m'idle-timeout-active'[39m,
    [32m'start-button'[39m,
    [32m'connection-status'[39m,
    [32m'transcription-connection-status'[39m,
    [32m'has-sent-settings'[39m,
    [32m'tts-mute-button'[39m,
    [32m'microphone-button'[39m,
    [32m'transcription'[39m,
    [32m'agent-response'[39m,
    [32m'transcript-history'[39m,
    [32m'user-message'[39m,
    [32m'text-input'[39m,
    [32m'send-button'[39m,
    [32m'event-log'[39m
  ],
  bodyText: [32m'\n'[39m +
    [32m'    Deepgram Voice Interaction TestComponent States:App UI State (isSleeping): falseCore Component State (agentState via callback): idleğŸŸ¢ Valid Deepgram API KeyText messages will be sent to Deepgram agent serviceConnection Mode (Issue #242)Direct (apiKey)Proxy (proxyEndpoint)Audio Recording: falseAudio Playing: falseComponent Ready: trueAuto-Connect Dual Mode States:Microphone Enabled: DisabledAgent Speaking: falseAgent Silent: trueVAD (Voice Activity Detection) States:Debug - utteranceEndDete'[39m
}

[1A[2KFound 6 event log entries

[1A[2KFound 10 console log entries

[1A[2KSynchronized entries: 6/6

[1A[2K[74/178] [chromium] â€º tests/e2e/logging-behavior.spec.js:81:3 â€º Logging Behavior Tests â€º should log transcript entries to both console and event log
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:168:3 â€º Idle Timeout Behavior â€º should show loading state during reconnection attempt
Final button text: Disable Mic

[1A[2K[75/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:81:3 â€º Logging Behavior Tests â€º should log transcript entries to both console and event log
ğŸ§ª Testing transcript logging...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
ğŸ§ª Testing idle timeout behavior during active conversation with REAL AUDIO...

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:117:3 â€º Lazy Initialization E2E Tests â€º should create agent manager when start() is called with agent flag
ğŸ” Component check before start: {
  "hasComponent": true,
  "hasStartMethod": true,
  "hasStopMethod": true
}

[1A[2K[chromium] â€º tests/e2e/js-error-test.spec.js:11:3 â€º JavaScript Error Tests â€º should check for JavaScript errors
JavaScript Errors:

[1A[2K
JavaScript Warnings:

[1A[2K  âš ï¸ Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K  âš ï¸ Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K
React loaded: [33mfalse[39m

[1A[2K
Script loading status:

[1A[2K  inline - Error: false

[1A[2K  http://localhost:5173/@vite/client - Error: false

[1A[2K  http://localhost:5173/src/main.tsx?t=1767045568497 - Error: false

[1A[2K[76/178] [chromium] â€º tests/e2e/manual-diagnostic.spec.js:13:3 â€º Manual Testing Diagnostics â€º should capture and analyze all console traffic during manual testing
[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:117:3 â€º Lazy Initialization E2E Tests â€º should create agent manager when start() is called with agent flag
ğŸ” start() result: {
  "success": true
}

[1A[2Kâœ… Connection established via start({ agent: true })

[1A[2KğŸ” Connection states after start(): {
  "agent": "connected",
  "transcription": "closed",
  "agentConnected": true,
  "transcriptionConnected": false
}

[1A[2Kâœ… Verified: Agent manager created and connected via start({ agent: true })

[1A[2K[77/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:213:3 â€º Lazy Initialization E2E Tests â€º should create both managers when start() is called with both flags
[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:213:3 â€º Lazy Initialization E2E Tests â€º should create both managers when start() is called with both flags
ğŸ” Testing start() with both service flags...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
ğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2K[78/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:621:5 â€º Declarative Props API - Issue #305 â€º startAudioCapture prop (replaces startAudioCapture method) â€º should start audio capture when startAudioCapture prop is true
[1A[2K[chromium] â€º tests/e2e/manual-diagnostic.spec.js:13:3 â€º Manual Testing Diagnostics â€º should capture and analyze all console traffic during manual testing
ğŸ” Starting comprehensive manual testing diagnostic...

[1A[2KğŸ“‹ Instructions: Click the microphone button and speak, then stay silent

[1A[2Kâ±ï¸  This test will run for 30 seconds to capture all traffic

[1A[2KStep 1: Waiting for microphone button click...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
ğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:213:3 â€º Lazy Initialization E2E Tests â€º should create both managers when start() is called with both flags
ğŸ” start() result: {
  "success": true
}

[1A[2Kâœ… Connection established via start({ agent: true, transcription: true })

[1A[2KğŸ” Connection states after start(): {
  "agent": "connected",
  "transcription": "connected",
  "agentConnected": true,
  "transcriptionConnected": true
}

[1A[2Kâœ… Verified: Both managers created and connected via start({ agent: true, transcription: true })

[1A[2K[79/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:254:3 â€º Lazy Initialization E2E Tests â€º should create agent manager when injectUserMessage() is called
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
ğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2KMicrophone status: Enabled

[1A[2KStep 2: Simulating ongoing conversation with REAL AUDIO SAMPLES...

[1A[2KSpeaking: "hello"

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:254:3 â€º Lazy Initialization E2E Tests â€º should create agent manager when injectUserMessage() is called
ğŸ” Testing injectUserMessage() lazy creation...

[1A[2KğŸ” Initial connection states: {
  "agent": "closed",
  "transcription": "closed",
  "agentConnected": false,
  "transcriptionConnected": false
}

[1A[2KğŸ” injectUserMessage() result: {
  "success": true,
  "before": {
    "agent": "closed",
    "transcription": "closed",
    "agentConnected": false,
    "transcriptionConnected": false
  },
  "after": {
    "agent": "connected",
    "transcription": "closed",
    "agentConnected": true,
    "transcriptionConnected": false
  }
}

[1A[2KğŸ” Relevant console logs: [
  [32m'[log] ğŸ“¤ [Protocol] Sending agent settings with context (correct Deepgram API format): {conversationHistoryLength: 0, contextMessages: Array(0), hasSpeakProvider: true, speakModel: aura-asteria-en, greetingIncluded: true}'[39m,
  [32m'[log] ğŸ“¤ [Component] About to call agentManagerRef.current.sendJSON with Settings message'[39m,
  [32m'[log] ğŸ“¤ [Component] WebSocketManager exists? true'[39m,
  [32m'[log] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse'[39m,
  [32m'[log] ğŸ“¤ [Component] - agentManagerRef.current exists? true'[39m,
  [32m'[log] ğŸ“¤ [Component] - WebSocket exists? true'[39m,
  [32m'[log] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)'[39m,
  [32m'[log] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent'[39m,
  [32m'[log] 22:05:45 - Agent said: Hello! How can I assist you today?'[39m,
  [32m'[log] ğŸ”Š [AGENT EVENT] AgentAudioDone received'[39m,
  [32m'[log] ğŸ¯ [AGENT] AgentAudioDone received - audio generation complete, playback may continue'[39m,
  [32m'[log] ğŸ¯ [AUDIO] Playback state changed: PLAYING, current agent state: idle'[39m,
  [32m"[log] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start"[39m,
  [32m'[log] 22:05:45 - Agent state changed: speaking'[39m,
  [32m'[log] 22:05:45 - Agent state changed: speaking'[39m,
  [32m'[log] ğŸ“ [TEXT_MESSAGE] Attempting to send: Hello, this is a test message - Connection state: connected'[39m,
  [32m'[log] ğŸ¯ [AUDIO] Playback state changed: NOT PLAYING, current agent state: speaking'[39m,
  [32m'[log] ğŸ¯ [AGENT] Audio playback finished - transitioning agent from speaking to idle'[39m,
  [32m'[log] 22:05:45 - Agent state changed: listening'[39m,
  [32m'[log] 22:05:45 - Audio playback: stopped - Agent playback completed'[39m
]

[1A[2KğŸ” Connection states from injectUserMessage() result: {
  "agent": "connected",
  "transcription": "closed",
  "agentConnected": true,
  "transcriptionConnected": false
}

[1A[2Kâœ… injectUserMessage() attempted lazy manager creation

[1A[2K   Manager state: connected

[1A[2K   Note: If manager is "not-found", it may have been cleared by React StrictMode cleanup

[1A[2Kâœ… Verified: Agent manager created lazily via injectUserMessage()

[1A[2K[80/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:363:3 â€º Lazy Initialization E2E Tests â€º should verify lazy initialization via microphone activation
[1A[2K[chromium] â€º tests/e2e/manual-diagnostic.spec.js:13:3 â€º Manual Testing Diagnostics â€º should capture and analyze all console traffic during manual testing
Mic status: Enabled

[1A[2KStep 2: Simulating speech...

[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:81:3 â€º Logging Behavior Tests â€º should log transcript entries to both console and event log
Found 0 transcript entries in event log

[1A[2KFound 0 transcript entries in console

[1A[2Kâ„¹ï¸ No transcript entries found (may need actual speech input)

[1A[2K[81/178] [chromium] â€º tests/e2e/logging-behavior.spec.js:139:3 â€º Logging Behavior Tests â€º should log user messages to both console and event log
[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:139:3 â€º Logging Behavior Tests â€º should log user messages to both console and event log
ğŸ§ª Testing user message logging...

[1A[2K[WebServer] [Proxy] Deepgram transcription connection closed: 1001 

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
âœ… VAD events detected: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2KWaiting 1000ms before next phrase...

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:363:3 â€º Lazy Initialization E2E Tests â€º should verify lazy initialization via microphone activation
ğŸ” Testing lazy initialization via microphone activation...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
Speaking: "hello__how_are_you_today_"

[1A[2K[chromium] â€º tests/e2e/manual-diagnostic.spec.js:13:3 â€º Manual Testing Diagnostics â€º should capture and analyze all console traffic during manual testing
Step 3: Simulating more speech...

[1A[2KStep 4: Waiting for silence period...

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:363:3 â€º Lazy Initialization E2E Tests â€º should verify lazy initialization via microphone activation
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[82/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:680:5 â€º Declarative Props API - Issue #305 â€º startAudioCapture prop (replaces startAudioCapture method) â€º should stop audio capture when startAudioCapture prop is false
[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established (may close due to idle timeout)

[1A[2KğŸ“Š UI Connection status: connected

[1A[2Kâœ… Lazy initialization verified - mic click triggered manager creation!

[1A[2K[83/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:396:3 â€º Lazy Initialization E2E Tests â€º should create managers when startAudioCapture() is called
[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:396:3 â€º Lazy Initialization E2E Tests â€º should create managers when startAudioCapture() is called
ğŸ” Testing startAudioCapture() lazy creation...

[1A[2KğŸ” Initial connection states: {
  "agent": "closed",
  "transcription": "closed",
  "agentConnected": false,
  "transcriptionConnected": false
}

[1A[2K[chromium] â€º tests/e2e/manual-diagnostic.spec.js:13:3 â€º Manual Testing Diagnostics â€º should capture and analyze all console traffic during manual testing

ğŸ“Š COMPREHENSIVE DIAGNOSTIC REPORT:

[1A[2K============================================================

[1A[2K
ğŸ¯ FINAL STATUS:

[1A[2K  Microphone: Enabled

[1A[2K  Connection: connected

[1A[2K  Total Logs Captured: 2501

[1A[2K
ğŸ”Š AUDIO TRAFFIC ANALYSIS:

[1A[2K  Audio-related logs: 1797

[1A[2K  Recent audio logs:

[1A[2K    [2025-12-29T22:05:48.204Z] ğŸµ [sendAudioData] transcriptionManagerRef.current?.getState(): connected

[1A[2K    [2025-12-29T22:05:48.204Z] ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K    [2025-12-29T22:05:48.205Z] ğŸµ [sendAudioData] âœ… Settings confirmed, sending to agent service

[1A[2K    [2025-12-29T22:05:48.206Z] ğŸµ [AUDIO] Audio data sent to Deepgram agent service

[1A[2K    [2025-12-29T22:05:48.556Z] ğŸ”§ [TRANSCRIPTION] Periodic keepalive audio sent

[1A[2K
ğŸŒ WEBSOCKET TRAFFIC ANALYSIS:

[1A[2K  WebSocket-related logs: 497

[1A[2K  Recent WebSocket logs:

[1A[2K    [2025-12-29T22:05:46.197Z] [WebSocketManager:transcription] Sending binary data: 8192 bytes

[1A[2K    [2025-12-29T22:05:46.198Z] [WebSocketManager:agent] Sending binary data: 8192 bytes

[1A[2K    [2025-12-29T22:05:48.205Z] [WebSocketManager:transcription] Sending binary data: 8192 bytes

[1A[2K    [2025-12-29T22:05:48.205Z] [WebSocketManager:agent] Sending binary data: 8192 bytes

[1A[2K    [2025-12-29T22:05:48.555Z] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K
ğŸ™ï¸ VAD EVENTS ANALYSIS:

[1A[2K  VAD-related logs: 3

[1A[2K  VAD events found:

[1A[2K    [2025-12-29T22:05:43.185Z] VAD: utterance_end_ms set to 1000ms

[1A[2K    [2025-12-29T22:05:43.185Z] VAD: interim_results set to true

[1A[2K    [2025-12-29T22:05:43.829Z] ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2K
âš™ï¸ SETTINGS ANALYSIS:

[1A[2K  Settings-related logs: 32

[1A[2K  Recent settings logs:

[1A[2K    [2025-12-29T22:05:43.779Z] 22:05:43 - Greeting marked sent (SettingsApplied received via callback)

[1A[2K    [2025-12-29T22:05:43.829Z] ğŸ”§ [Component] Initialization check {isFirstMount: false, isReady: true, needsInitialization: false, isMounted: true, mountId: 1767045942155-0.6117053739012511}

[1A[2K    [2025-12-29T22:05:43.829Z] ğŸ”§ [Component] Skipping re-initialization - dependencies unchanged and component is ready

[1A[2K
âŒ ERROR ANALYSIS:

[1A[2K  Error logs: 0

[1A[2K  âœ… No errors detected

[1A[2K
ğŸ” DIAGNOSTIC RECOMMENDATIONS:

[1A[2K
ğŸ“‹ NEXT STEPS:

[1A[2K  1. Share this diagnostic report

[1A[2K  2. Check if VAD configuration includes utteranceEndMs and interimResults

[1A[2K  3. Verify that real audio APIs are working (not mocked)

[1A[2K  4. Check Deepgram API key and project ID

[1A[2K
============================================================

[1A[2Kâœ… Diagnostic completed

[1A[2K[84/178] [chromium] â€º tests/e2e/manual-diagnostic.spec.js:193:3 â€º Manual Testing Diagnostics â€º should test VAD configuration specifically
[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:396:3 â€º Lazy Initialization E2E Tests â€º should create managers when startAudioCapture() is called
ğŸ” startAudioCapture() result: {
  "success": true,
  "after": {
    "agent": "connected",
    "transcription": "connected",
    "agentConnected": true,
    "transcriptionConnected": true
  }
}

[1A[2Kâœ… Connection established via startAudioCapture()

[1A[2KğŸ” Connection states after wait: {
  "agent": "connected",
  "transcription": "connected",
  "agentConnected": true,
  "transcriptionConnected": true
}

[1A[2Kâœ… Managers created lazily via startAudioCapture() - state: connected

[1A[2K[85/178] [chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:464:3 â€º Lazy Initialization E2E Tests â€º should handle agent already connected when microphone is activated
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
âœ… VAD events detected: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2KWaiting 1000ms before next phrase...

[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:139:3 â€º Logging Behavior Tests â€º should log user messages to both console and event log
Found 1 user message entries in event log

[1A[2KFound 1 user message entries in console

[1A[2Kâœ… User message entries found in both console and event log

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:464:3 â€º Lazy Initialization E2E Tests â€º should handle agent already connected when microphone is activated
ğŸ” Testing microphone activation with agent already connected...

[1A[2K[86/178] [chromium] â€º tests/e2e/logging-behavior.spec.js:192:3 â€º Logging Behavior Tests â€º should verify addLog function logs to both places
[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:192:3 â€º Logging Behavior Tests â€º should verify addLog function logs to both places
ğŸ§ª Testing addLog function behavior...

[1A[2K[chromium] â€º tests/e2e/manual-diagnostic.spec.js:193:3 â€º Manual Testing Diagnostics â€º should test VAD configuration specifically
ğŸ” VAD Configuration Check:

[1A[2K  Component available: [33mtrue[39m

[1A[2K  Available methods: [
  [32m'start'[39m,
  [32m'stop'[39m,
  [32m'updateAgentInstructions'[39m,
  [32m'interruptAgent'[39m,
  [32m'allowAgent'[39m,
  [32m'sleep'[39m,
  [32m'wake'[39m,
  [32m'toggleSleep'[39m,
  [32m'injectAgentMessage'[39m,
  [32m'injectUserMessage'[39m,
  [32m'startAudioCapture'[39m,
  [32m'sendFunctionCallResponse'[39m,
  [32m'sendAudioData'[39m,
  [32m'getAudioContext'[39m
]

[1A[2K  VAD config in page: VAD configuration not found in page

[1A[2K[87/178] [chromium] â€º tests/e2e/manual-vad-workflow.spec.js:29:3 â€º Manual VAD Workflow Tests â€º should handle complete manual workflow: speak â†’ silence â†’ timeout
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
Speaking: "hello"

[1A[2K[chromium] â€º tests/e2e/lazy-initialization-e2e.spec.js:464:3 â€º Lazy Initialization E2E Tests â€º should handle agent already connected when microphone is activated
ğŸ” start() result: {
  "success": true
}

[1A[2Kâœ… Agent connection established before microphone activation

[1A[2KğŸ” Connection states before startAudioCapture(): {
  "agent": "connected",
  "transcription": "closed",
  "agentConnected": true,
  "transcriptionConnected": false
}

[1A[2KğŸ” startAudioCapture() result: {
  "success": true,
  "states": {
    "agent": "connected",
    "transcription": "connected",
    "agentConnected": true,
    "transcriptionConnected": true
  }
}

[1A[2Kâœ… Connection verified after microphone activation

[1A[2KğŸ” Connection states after startAudioCapture(): {
  "agent": "connected",
  "transcription": "connected",
  "agentConnected": true,
  "transcriptionConnected": true
}

[1A[2Kâœ… Verified: Agent reused when microphone activated (transcription created by startAudioCapture)

[1A[2K[88/178] [chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
ğŸ§ª Testing microphone activation after idle timeout...

[1A[2KStep 1: Setting up test page and establishing connection...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:29:3 â€º Manual VAD Workflow Tests â€º should handle complete manual workflow: speak â†’ silence â†’ timeout
Step 1: Turning on microphone...

[1A[2K[89/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:758:5 â€º Declarative Props API - Issue #305 â€º Backward Compatibility â€º should maintain backward compatibility with imperative ref methods
[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
Initial connection status: connected

[1A[2KStep 2: Waiting for idle timeout...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
âœ… VAD events detected: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2KWaiting 1000ms before next phrase...

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
â³ +1005ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/logging-behavior.spec.js:192:3 â€º Logging Behavior Tests â€º should verify addLog function logs to both places
Synchronization rate: 100.0% (6/6)

[1A[2K[90/178] [chromium] â€º tests/e2e/microphone-control.spec.js:34:3 â€º Microphone Control â€º should enable microphone when button clicked
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
Speaking: "hello__how_are_you_today_"

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:34:3 â€º Microphone Control â€º should enable microphone when button clicked
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:29:3 â€º Manual VAD Workflow Tests â€º should handle complete manual workflow: speak â†’ silence â†’ timeout
Mic status after click: Enabled

[1A[2Kâœ… Microphone enabled

[1A[2KStep 2: Simulating speech "wait one moment"...

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:34:3 â€º Microphone Control â€º should enable microphone when button clicked
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[91/178] [chromium] â€º tests/e2e/microphone-control.spec.js:49:3 â€º Microphone Control â€º should disable microphone when button clicked again
[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:49:3 â€º Microphone Control â€º should disable microphone when button clicked again
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[92/178] [chromium] â€º tests/e2e/declarative-props-api.spec.js:783:5 â€º Declarative Props API - Issue #305 â€º Backward Compatibility â€º should allow mixing declarative props with imperative methods
[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
âœ… VAD events detected: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2KWaiting 1000ms before next phrase...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:29:3 â€º Manual VAD Workflow Tests â€º should handle complete manual workflow: speak â†’ silence â†’ timeout
Event log after speech: Event LogClear Logs22:05:56 - Audio playback: stopped - Agent playback completed
22:05:56 - Agent state changed: idle
22:05:54 - Audio playback: started
22:05:54 - Agent state changed: speaking
22:05:54 - Agent state changed: speaking
22:05:54 - Agent said: Hello! How can I assist you today?
22:05:54 - Greeting marked sent (SettingsApplied received via callback)
22:05:54 - Audio capture started successfully
22:05:54 - agent connection state: connected
22:05:54 - agent connection state: connecting
22:05:54 - transcription connection state: connected
22:05:54 - transcription connection state: connecting
22:05:54 - Starting agent and transcription services...
22:05:54 - Starting audio capture (lazy initialization)
22:05:53 - Component is ready
22:05:53 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...
22:05:53 - Loaded instructions via loader: You are a helpful voice assistant. Keep your respo...
22:05:53 - Audio playback: stopped - Agent playback completed
22:05:53 - Agent state changed: idle
22:05:53 - Component is not ready

[1A[2KStep 3: Staying silent to trigger UtteranceEnd...

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:49:3 â€º Microphone Control â€º should disable microphone when button clicked again
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
â³ +6021ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
Speaking: "hello"

[1A[2K[93/178] [chromium] â€º tests/e2e/microphone-control.spec.js:68:3 â€º Microphone Control â€º should start transcription service when microphone button clicked with agent already connected (Issue #255)
[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:29:3 â€º Manual VAD Workflow Tests â€º should handle complete manual workflow: speak â†’ silence â†’ timeout
UtteranceEnd status: Not detected

[1A[2KStep 4: Waiting for connection to close due to timeout...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:206:3 â€º Idle Timeout Behavior â€º should not timeout during active conversation after UtteranceEnd
âœ… VAD events detected: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2KStep 3: Checking connection stayed alive during REAL conversation...

[1A[2KFinal connection status: connected

[1A[2K
Connection close events: 0

[1A[2Kâœ… Connection stayed alive during REAL conversation with VAD events

[1A[2Kâœ… No premature idle timeouts during REAL conversation

[1A[2K[94/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
ğŸ§ª Testing idle timeout with realistic conversation timing (2.3s padding)...

[1A[2K[95/178] [chromium] â€º tests/e2e/microphone-control.spec.js:109:8 â€º Microphone Control â€º should handle microphone permission denied
[1A[2K[96/178] [chromium] â€º tests/e2e/microphone-control.spec.js:126:3 â€º Microphone Control â€º should handle microphone permission granted
[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:126:3 â€º Microphone Control â€º should handle microphone permission granted
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[97/178] [chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:23:3 â€º Fixed Microphone Functionality Tests â€º should enable microphone when button is clicked (FIXED)
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
ğŸ¤ [AUDIO_SETUP] Starting audio sending prerequisites setup...

[1A[2KğŸ¤ [AUDIO_SETUP] Step 1: Granting microphone permissions...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone permissions granted

[1A[2KğŸ¤ [AUDIO_SETUP] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Component is ready

[1A[2KğŸ¤ [AUDIO_SETUP] Step 3: Clicking microphone button...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Microphone button clicked

[1A[2KğŸ¤ [AUDIO_SETUP] Step 4: Waiting for connection...

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… Connection established

[1A[2KğŸ¤ [AUDIO_SETUP] Step 5: Waiting for settings to be applied...

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:23:3 â€º Fixed Microphone Functionality Tests â€º should enable microphone when button is clicked (FIXED)
ğŸ¤ Testing microphone activation with proper sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
ğŸ¤ [AUDIO_SETUP] âœ… Settings applied (SettingsApplied received)

[1A[2KğŸ¤ [AUDIO_SETUP] Step 6: Waiting 600ms for settings processing delay...

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:126:3 â€º Microphone Control â€º should handle microphone permission granted
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
ğŸ¤ [AUDIO_SETUP] âœ… Settings processing delay passed

[1A[2KğŸ¤ [AUDIO_SETUP] âœ… All audio sending prerequisites complete!

[1A[2KğŸ¤ [AUDIO_SETUP] ğŸ’¡ Component is now ready to accept audio data via sendAudioData()

[1A[2KMicrophone status: Enabled

[1A[2KStep 2: Simulating realistic conversation with proper timing...

[1A[2KSpeaking: "hello" (expected duration: 2638ms)

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:126:3 â€º Microphone Control â€º should handle microphone permission granted
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
âœ… Connection closed after 11035ms (expected: ~10000ms)

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:126:3 â€º Microphone Control â€º should handle microphone permission granted
ğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
Connection status after timeout: closed

[1A[2KStep 3: Using MicrophoneHelpers for proper activation after timeout...

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:126:3 â€º Microphone Control â€º should handle microphone permission granted
ğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[98/178] [chromium] â€º tests/e2e/microphone-control.spec.js:145:3 â€º Microphone Control â€º should maintain microphone disabled by default
[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:23:3 â€º Fixed Microphone Functionality Tests â€º should enable microphone when button is clicked (FIXED)
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[99/178] [chromium] â€º tests/e2e/microphone-control.spec.js:156:3 â€º Microphone Control â€º should handle microphone control via props
[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone successfully enabled with proper sequence!

[1A[2K[100/178] [chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:41:3 â€º Fixed Microphone Functionality Tests â€º should show VAD elements when microphone is enabled (FIXED)
[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:41:3 â€º Fixed Microphone Functionality Tests â€º should show VAD elements when microphone is enabled (FIXED)
ğŸ¤ Testing VAD elements with proper microphone activation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[101/178] [chromium] â€º tests/e2e/microphone-control.spec.js:169:3 â€º Microphone Control â€º should handle microphone toggle callback
[1A[2K[102/178] [chromium] â€º tests/e2e/microphone-control.spec.js:184:3 â€º Microphone Control â€º should maintain microphone state during reconnection
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
âœ… VAD events detected: 2

[1A[2KWaiting 1000ms before next phrase (realistic conversation pause)...

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:41:3 â€º Fixed Microphone Functionality Tests â€º should show VAD elements when microphone is enabled (FIXED)
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[103/178] [chromium] â€º tests/e2e/microphone-control.spec.js:193:3 â€º Microphone Control â€º should handle microphone errors gracefully
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
Speaking: "hello__how_are_you_today_" (expected duration: 3810ms)

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:41:3 â€º Fixed Microphone Functionality Tests â€º should show VAD elements when microphone is enabled (FIXED)
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2Kâœ… VAD elements verified with proper microphone activation!

[1A[2K[104/178] [chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:60:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation with retry logic (FIXED)
[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:60:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation with retry logic (FIXED)
ğŸ¤ Testing microphone activation with retry logic...

[1A[2KğŸ¤ [MICROPHONE_RETRY] Attempt 1/3

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_RETRY] âœ… Success on attempt 1

[1A[2Kâœ… Microphone activation with retry logic successful!

[1A[2K[105/178] [chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:78:3 â€º Fixed Microphone Functionality Tests â€º should verify microphone prerequisites before activation (FIXED)
[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:78:3 â€º Fixed Microphone Functionality Tests â€º should verify microphone prerequisites before activation (FIXED)
ğŸ¤ Testing microphone prerequisites verification...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
âœ… VAD events detected: 2

[1A[2KWaiting 1000ms before next phrase (realistic conversation pause)...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:29:3 â€º Manual VAD Workflow Tests â€º should handle complete manual workflow: speak â†’ silence â†’ timeout
âœ… Manual VAD workflow completed successfully

[1A[2K[106/178] [chromium] â€º tests/e2e/manual-vad-workflow.spec.js:92:3 â€º Manual VAD Workflow Tests â€º should detect VAD events during manual workflow
[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:92:3 â€º Manual VAD Workflow Tests â€º should detect VAD events during manual workflow
ğŸ§ª Testing VAD event detection during manual workflow...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:78:3 â€º Fixed Microphone Functionality Tests â€º should verify microphone prerequisites before activation (FIXED)
ğŸ¤ [MICROPHONE_VERIFY] Verifying microphone prerequisites...

[1A[2KğŸ¤ [MICROPHONE_VERIFY] âœ… Page loaded

[1A[2KğŸ¤ [MICROPHONE_VERIFY] Component initialized: true

[1A[2KğŸ¤ [MICROPHONE_VERIFY] Agent connected: false

[1A[2KğŸ¤ [MICROPHONE_VERIFY] âš ï¸ Greeting status not available, proceeding anyway

[1A[2KğŸ¤ [MICROPHONE_VERIFY] Mic button visible: true

[1A[2KğŸ¤ [MICROPHONE_VERIFY] Mic button enabled: true

[1A[2KğŸ¤ [MICROPHONE_VERIFY] All prerequisites met: false

[1A[2Kâ„¹ï¸ Agent not connected yet (lazy init - expected before activation)

[1A[2Kâœ… Core microphone prerequisites verified (page loaded, component initialized, button ready)!

[1A[2K[107/178] [chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
Speaking: "hello" (expected duration: 2638ms)

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
ğŸ¤ Testing microphone activation after idle timeout...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:92:3 â€º Manual VAD Workflow Tests â€º should detect VAD events during manual workflow
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/microphone-control.spec.js:193:3 â€º Microphone Control â€º should handle microphone errors gracefully
âœ… Microphone error handled gracefully - final status: Disabled

[1A[2K[108/178] [chromium] â€º tests/e2e/microphone-functionality.spec.js:13:3 â€º Microphone Functionality Tests â€º should actually enable microphone when button is clicked
[1A[2K[chromium] â€º tests/e2e/microphone-functionality.spec.js:13:3 â€º Microphone Functionality Tests â€º should actually enable microphone when button is clicked
ğŸ¤ Testing microphone activation with proper sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:92:3 â€º Manual VAD Workflow Tests â€º should detect VAD events during manual workflow
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone enabled and connected

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
âœ… Initial connection established

[1A[2Kâ³ Waiting for idle timeout...

[1A[2K[chromium] â€º tests/e2e/microphone-functionality.spec.js:13:3 â€º Microphone Functionality Tests â€º should actually enable microphone when button is clicked
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
âœ… VAD events detected: 2

[1A[2KWaiting 1000ms before next phrase (realistic conversation pause)...

[1A[2K[chromium] â€º tests/e2e/microphone-functionality.spec.js:13:3 â€º Microphone Functionality Tests â€º should actually enable microphone when button is clicked
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone successfully enabled with proper sequence!

[1A[2K[109/178] [chromium] â€º tests/e2e/microphone-functionality.spec.js:31:3 â€º Microphone Functionality Tests â€º should show VAD elements when microphone is enabled
[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
â³ +1003ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/microphone-functionality.spec.js:31:3 â€º Microphone Functionality Tests â€º should show VAD elements when microphone is enabled
ğŸ¤ Testing VAD elements with proper microphone activation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
Speaking: "hello__how_are_you_today_" (expected duration: 3810ms)

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
âœ… Connection confirmed as closed after timeout

[1A[2KğŸ¤ Microphone button clicked for reconnection

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:92:3 â€º Manual VAD Workflow Tests â€º should detect VAD events during manual workflow
âœ… VAD events detected: 1

[1A[2Kâœ… VAD events successfully detected during manual workflow!

[1A[2K[chromium] â€º tests/e2e/microphone-functionality.spec.js:31:3 â€º Microphone Functionality Tests â€º should show VAD elements when microphone is enabled
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[110/178] [chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:35:3 â€º Microphone Activation After Idle Timeout â€º should handle microphone activation after idle timeout
âœ… Connection re-established

[1A[2Kâœ… Microphone enabled after reconnection

[1A[2K
ğŸ“Š FINAL STATE:

[1A[2K  Microphone: Enabled

[1A[2K  Connection: connected

[1A[2K  Errors captured: 0

[1A[2Kâœ… Microphone successfully enabled after idle timeout!

[1A[2Kâœ… Connection re-established!

[1A[2Kâœ… Test passed: Microphone activation after idle timeout works correctly!

[1A[2K[111/178] [chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
ğŸ§ª Testing loading state during reconnection...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
ğŸ§ª Testing VAD events in console logs during manual workflow...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/microphone-functionality.spec.js:31:3 â€º Microphone Functionality Tests â€º should show VAD elements when microphone is enabled
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2Kâœ… VAD elements verified with proper microphone activation!

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
Waiting for idle timeout...

[1A[2K[112/178] [chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone enabled and connected

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
â³ +1004ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
VAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
ğŸ” Starting microphone reliability test...

[1A[2KStep 1: Enabling microphone...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
VAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:289:3 â€º Idle Timeout Behavior â€º should handle conversation with realistic timing and padding
âœ… VAD events detected: 2

[1A[2KStep 3: Verifying connection stayed alive during realistic conversation...

[1A[2KFinal connection status: connected

[1A[2K
Connection close events: 0

[1A[2Kâœ… Connection stayed alive during realistic conversation with proper timing

[1A[2Kâœ… No premature idle timeouts during realistic conversation with 2.3s padding

[1A[2K[113/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
ğŸ§ª Testing idle timeout behavior: connection should close after 10 seconds of inactivity...

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
VAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] No timeout to stop (timeoutId is null)

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
VAD Console Log: [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":0.64}

[1A[2KVAD Console Log: [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2KVAD Console Log: [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd

[1A[2KVAD Console Log: ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2KVAD Console Log: ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2KVAD Console Log: ğŸ” [DEBUG] Processing message type: UtteranceEnd

[1A[2KVAD Console Log: ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2KVAD Console Log: ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process

[1A[2KVAD Console Log: 22:06:21 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected

[1A[2KVAD Console Log: ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)

[1A[2KVAD Console Log: [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
â³ +6021ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/manual-vad-workflow.spec.js:128:3 â€º Manual VAD Workflow Tests â€º should show VAD events in console logs during manual workflow
VAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2KVAD Console Log: ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2Kâœ… VAD events detected: 1

[1A[2KAll VAD Console Logs: [
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸ” [DEBUG] Checking for VAD event type: History'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'[WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":0.64}'[39m,
  [32m'[WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}'[39m,
  [32m'[WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd'[39m,
  [32m'ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}'[39m,
  [32m'ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}'[39m,
  [32m'ğŸ” [DEBUG] Processing message type: UtteranceEnd'[39m,
  [32m'ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}'[39m,
  [32m'ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process'[39m,
  [32m'22:06:21 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected'[39m,
  [32m'ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)'[39m,
  [32m'[WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m,
  [32m'ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events'[39m
]

[1A[2Kâœ… VAD events detected (console log validation is secondary)

[1A[2K[114/178] [chromium] â€º tests/e2e/page-content.spec.js:12:3 â€º Page Content Tests â€º should check what elements are on the page
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2KStep 1: Enabling microphone...

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Started polling for idle timeout conditions

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ¯ [DEBUG] No timeout to stop (timeoutId is null)

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] disableResets() called

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Starting timeout with timeoutId: null

[1A[2K[BROWSER] ğŸ¯ [DEBUG] Timeout started with timeoutId: 17

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ”§ [TRANSCRIPTION] Starting periodic keepalive audio to prevent timeout

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[BROWSER] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=startAudioCapture, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
After first enable - Mic: Enabled, Connection: connected

[1A[2KStep 2: Putting agent to sleep...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2Kâœ… Connection is open

[1A[2KStep 2: Checking idle timeout state...

[1A[2KğŸ” Initial timeout state: { agentManager: [1mnull[22m, transcriptionManager: [1mnull[22m }

[1A[2KStep 3: Waiting for idle timeout to close connection...

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[BROWSER] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
â³ +6021ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/page-content.spec.js:12:3 â€º Page Content Tests â€º should check what elements are on the page
Page title: Vite + React + TS

[1A[2KBody text (first 500 chars): 
    Deepgram Voice Interaction TestComponent States:App UI State (isSleeping): falseCore Component State (agentState via callback): idleğŸŸ¢ Valid Deepgram API KeyText messages will be sent to Deepgram agent serviceConnection Mode (Issue #242)Direct (apiKey)Proxy (proxyEndpoint)Audio Recording: falseAudio Playing: falseComponent Ready: trueAuto-Connect Dual Mode States:Microphone Enabled: DisabledAgent Speaking: falseAgent Silent: trueVAD (Voice Activity Detection) States:Debug - utteranceEndDete

[1A[2KNumber of buttons found: [33m8[39m

[1A[2KNumber of elements with data-testid: [33m29[39m

[1A[2KData-testid elements:

[1A[2K  DIV[data-testid="voice-agent"]

[1A[2K  DIV[data-testid="deepgram-component"]

[1A[2K  STRONG[data-testid="agent-state"]

[1A[2K  DIV[data-testid="api-mode-indicator"]

[1A[2K  STRONG[data-testid="audio-playing-status"]

[1A[2K  STRONG[data-testid="component-ready-status"]

[1A[2K  DIV[data-testid="auto-connect-states"]

[1A[2K  STRONG[data-testid="mic-status"]

[1A[2K  STRONG[data-testid="agent-speaking"]

[1A[2K  STRONG[data-testid="agent-silent"]

[1A[2K  DIV[data-testid="vad-states"]

[1A[2K  STRONG[data-testid="user-started-speaking"]

[1A[2K  STRONG[data-testid="user-stopped-speaking"]

[1A[2K  STRONG[data-testid="utterance-end"]

[1A[2K  DIV[data-testid="idle-timeout-state"]

[1A[2K  STRONG[data-testid="idle-timeout-active"]

[1A[2K  BUTTON[data-testid="start-button"]

[1A[2K  STRONG[data-testid="connection-status"]

[1A[2K  STRONG[data-testid="transcription-connection-status"]

[1A[2K  STRONG[data-testid="has-sent-settings"]

[1A[2K  BUTTON[data-testid="tts-mute-button"]

[1A[2K  BUTTON[data-testid="microphone-button"]

[1A[2K  PRE[data-testid="transcription"]

[1A[2K  PRE[data-testid="agent-response"]

[1A[2K  DIV[data-testid="transcript-history"]

[1A[2K  PRE[data-testid="user-message"]

[1A[2K  INPUT[data-testid="text-input"]

[1A[2K  BUTTON[data-testid="send-button"]

[1A[2K  DIV[data-testid="event-log"]

[1A[2K[115/178] [chromium] â€º tests/e2e/page-content.spec.js:50:3 â€º Page Content Tests â€º should render voice agent component correctly
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
After sleep - Mic: Enabled, Connection: connected

[1A[2KStep 2.5: Waking agent up...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2Kâ³ +2003ms: Connection still connected

[1A[2K[116/178] [chromium] â€º tests/e2e/react-error-test.spec.js:11:3 â€º React Error Detection â€º should detect React rendering errors
[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
âœ… Connection closed after 11040ms (expected: ~10000ms)

[1A[2Kâœ… Connection closed after idle timeout

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
Step 3: Disabling microphone...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
After disable - Mic: Disabled, Connection: closed

[1A[2KStep 4: Re-enabling microphone...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
âœ… Connection closed after 11040ms (expected: ~10000ms)

[1A[2KClicking microphone and checking for loading state...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-activation-after-idle-timeout.spec.js:98:3 â€º Microphone Activation After Idle Timeout â€º should show loading state during reconnection attempt
Button text during operation: Disable Mic

[1A[2KShows loading/disabled state: false

[1A[2KFinal button text: Disable Mic

[1A[2KFinal connection status: connected

[1A[2Kâœ… Connection re-established after mic button click

[1A[2K[117/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability
After re-enable - Mic: Enabled, Connection: closed

[1A[2KStep 5: Simulating speech...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/react-error-test.spec.js:11:3 â€º React Error Detection â€º should detect React rendering errors
React DevTools available: [33mtrue[39m

[1A[2KReact root element exists: [33mtrue[39m

[1A[2KError boundary detected: [33mfalse[39m

[1A[2K
Console Errors:

[1A[2K
Console Warnings:

[1A[2K  âš ï¸ Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at commitPassiveMountOnFiber (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9885:29)
    at recursivelyTraversePassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9866:13)

[1A[2K  âš ï¸ Failed to load instructions from file, using default: Error: File reading not supported in browser environment
    at getDefaultInstructionsFilePath (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:38:11)
    at loadInstructionsFromFile (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/instructions-loader.ts:16:46)
    at loadInstructions (http://localhost:5173/src/App.tsx?t=1767045568497:176:36)
    at http://localhost:5173/src/App.tsx?t=1767045568497:196:5
    at react-stack-bottom-frame (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:17476:20)
    at runWithFiberInDEV (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:1483:72)
    at commitHookEffectListMount (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8458:122)
    at commitHookPassiveMountEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:8516:60)
    at reconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:10014:13)
    at recursivelyTraverseReconnectPassiveEffects (http://localhost:5173/node_modules/.vite/deps/react-dom_client.js?v=31bd7610:9993:11)

[1A[2K
Body content length: [33m1710[39m

[1A[2KBody content preview: 
    Deepgram Voice Interaction TestComponent States:App UI State (isSleeping): falseCore Component State (agentState via callback): idleğŸŸ¢ Valid Deepgram API KeyText messages will be sent to Deepgram

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[118/178] [chromium] â€º tests/e2e/simple-mic-test.spec.js:16:3 â€º Simple Microphone State Tests â€º should test basic microphone functionality
[1A[2K[chromium] â€º tests/e2e/simple-mic-test.spec.js:16:3 â€º Simple Microphone State Tests â€º should test basic microphone functionality
ğŸ¤ Testing basic microphone functionality with proper sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Idle timeout reached (10000ms) - firing callback

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/simple-mic-test.spec.js:16:3 â€º Simple Microphone State Tests â€º should test basic microphone functionality
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:13:3 â€º Microphone Reliability Diagnostics â€º should track microphone enable/disable reliability

ğŸ“Š MICROPHONE RELIABILITY REPORT:

[1A[2K============================================================

[1A[2K
ğŸ¯ STATUS PROGRESSION:

[1A[2K  1. First enable:    Mic=Enabled, Connection=connected

[1A[2K  2. After timeout:  Mic=Enabled, Connection=connected

[1A[2K  3. After disable:  Mic=Disabled, Connection=closed

[1A[2K  4. After re-enable: Mic=Enabled, Connection=closed

[1A[2K
ğŸ¤ MICROPHONE LOGS:

[1A[2K  [2025-12-29T22:06:20.379Z] ğŸ¤ [APP] toggleMicrophone called

[1A[2K  [2025-12-29T22:06:20.380Z] ğŸ¤ [APP] micEnabled: false

[1A[2K  [2025-12-29T22:06:20.382Z] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K  [2025-12-29T22:06:20.382Z] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K  [2025-12-29T22:06:20.382Z] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K  [2025-12-29T22:06:20.382Z] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K  [2025-12-29T22:06:20.382Z] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [APP] Services started (or already connected)

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [MOCK] AudioWorklet.addModule called - simulating success

[1A[2K  [2025-12-29T22:06:20.678Z] [AudioManager] Requesting microphone access

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [MOCK] getUserMedia called - returning mock MediaStream

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [MOCK] createMediaStreamSource called - simulating success

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [MOCK] AudioWorkletNode constructor called - simulating success

[1A[2K  [2025-12-29T22:06:20.678Z] ğŸ¤ [MOCK] AudioWorkletNode port.postMessage called with: {type: start}

[1A[2K  [2025-12-29T22:06:20.679Z] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K  [2025-12-29T22:06:27.512Z] ğŸ¤ [APP] toggleMicrophone called

[1A[2K  [2025-12-29T22:06:27.513Z] ğŸ¤ [APP] micEnabled: true

[1A[2K  [2025-12-29T22:06:27.513Z] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K  [2025-12-29T22:06:27.513Z] ğŸ¤ [APP] Disabling microphone

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] toggleMicrophone called

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] micEnabled: false

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] deepgramRef.current: true

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] About to call startAudioCapture()

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] deepgramRef.current exists, calling startAudioCapture()

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] deepgramRef.current methods: [start, stop, updateAgentInstructions, interruptAgent, allowAgent, sleep, wake, toggleSleep, injectAgentMessage, injectUserMessage, startAudioCapture, sendFunctionCallResponse, sendAudioData, getAudioContext]

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ¤ [APP] Starting both agent and transcription services...

[1A[2K  [2025-12-29T22:06:28.817Z] ğŸ¤ [APP] Services started (or already connected)

[1A[2K  [2025-12-29T22:06:28.817Z] ğŸ¤ [APP] startAudioCapture method exists, calling it

[1A[2K  [2025-12-29T22:06:28.818Z] [AudioManager] Requesting microphone access

[1A[2K  [2025-12-29T22:06:28.818Z] ğŸ¤ [MOCK] getUserMedia called - returning mock MediaStream

[1A[2K  [2025-12-29T22:06:28.818Z] ğŸ¤ [MOCK] createMediaStreamSource called - simulating success

[1A[2K  [2025-12-29T22:06:28.818Z] ğŸ¤ [MOCK] AudioWorkletNode constructor called - simulating success

[1A[2K  [2025-12-29T22:06:28.818Z] ğŸ¤ [MOCK] AudioWorkletNode port.postMessage called with: {type: start}

[1A[2K  [2025-12-29T22:06:28.819Z] ğŸ¤ [APP] startAudioCapture() completed successfully

[1A[2K  [2025-12-29T22:06:31.583Z] ğŸ¤ [RELIABILITY] Sending audio data after re-enable

[1A[2K
ğŸ”— CONNECTION LOGS:

[1A[2K  [2025-12-29T22:06:20.383Z] ğŸ” [AUDIO BLOCKING] start() - Fresh connection detected, resetting allowAgentRef from true to true

[1A[2K  [2025-12-29T22:06:20.383Z] [DeepgramVoiceInteraction] ğŸ”„ Fresh connection starting - resetting audio blocking state

[1A[2K  [2025-12-29T22:06:20.384Z] [WebSocketManager:transcription] WebSocketManager created

[1A[2K  [2025-12-29T22:06:20.384Z] ğŸ”§ [AGENT] Creating WebSocketManager with URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K  [2025-12-29T22:06:20.385Z] [WebSocketManager:agent] WebSocketManager created

[1A[2K  [2025-12-29T22:06:20.385Z] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K  [2025-12-29T22:06:20.385Z] [WebSocketManager:transcription] Connecting to WebSocket...

[1A[2K  [2025-12-29T22:06:20.385Z] 22:06:20 - transcription connection state: connecting

[1A[2K  [2025-12-29T22:06:20.385Z] [WebSocketManager:transcription] Built URL with params: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [2025-12-29T22:06:20.385Z] [WebSocketManager:transcription] Connecting to wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [2025-12-29T22:06:20.386Z] ğŸ”Œ [WebSocketManager.connect] URL: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [2025-12-29T22:06:20.386Z] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K  [2025-12-29T22:06:20.386Z] ğŸ”Œ [WebSocketManager.connect] Service: transcription

[1A[2K  [2025-12-29T22:06:20.386Z] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K  [2025-12-29T22:06:20.386Z] [WebSocketManager:transcription] Initial readyState: 0

[1A[2K  [2025-12-29T22:06:20.554Z] [WebSocketManager:transcription] WebSocket connected

[1A[2K  [2025-12-29T22:06:20.555Z] 22:06:20 - transcription connection state: connected

[1A[2K  [2025-12-29T22:06:20.555Z] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  [2025-12-29T22:06:20.555Z] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K  [2025-12-29T22:06:20.556Z] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  [2025-12-29T22:06:20.556Z] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K  [2025-12-29T22:06:20.556Z] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K  [2025-12-29T22:06:20.556Z] [WebSocketManager:agent] Connecting to WebSocket...

[1A[2K  [2025-12-29T22:06:20.556Z] 22:06:20 - agent connection state: connecting

[1A[2K  [2025-12-29T22:06:20.556Z] [WebSocketManager:agent] Built URL with params: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:20.556Z] [WebSocketManager:agent] Connecting to wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:20.556Z] ğŸ”Œ [WebSocketManager.connect] URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:20.556Z] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K  [2025-12-29T22:06:20.556Z] ğŸ”Œ [WebSocketManager.connect] Service: agent

[1A[2K  [2025-12-29T22:06:20.556Z] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K  [2025-12-29T22:06:20.556Z] [WebSocketManager:agent] Initial readyState: 0

[1A[2K  [2025-12-29T22:06:20.657Z] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K  [2025-12-29T22:06:20.675Z] [WebSocketManager:agent] WebSocket connected

[1A[2K  [2025-12-29T22:06:20.675Z] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K  [2025-12-29T22:06:20.676Z] [DeepgramVoiceInteraction] Agent WebSocket connected for first time

[1A[2K  [2025-12-29T22:06:20.676Z] 22:06:20 - agent connection state: connected

[1A[2K  [2025-12-29T22:06:20.677Z] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K  [2025-12-29T22:06:20.677Z] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K  [2025-12-29T22:06:20.677Z] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  [2025-12-29T22:06:20.677Z] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K  [2025-12-29T22:06:20.677Z] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  [2025-12-29T22:06:20.677Z] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K  [2025-12-29T22:06:20.678Z] [DeepgramVoiceInteraction] Agent service already connected, skipping connection

[1A[2K  [2025-12-29T22:06:20.679Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.679Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:20.679Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Welcome","request_id":"0a92d222-74b5-4100-9c4d-0fb6ca6fdfc5"}

[1A[2K  [2025-12-29T22:06:20.679Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Welcome, request_id: 0a92d222-74b5-4100-9c4d-0fb6ca6fdfc5}

[1A[2K  [2025-12-29T22:06:20.679Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Welcome

[1A[2K  [2025-12-29T22:06:20.679Z] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K  [2025-12-29T22:06:20.679Z] [DeepgramVoiceInteraction] Welcome message received - dual mode connection established

[1A[2K  [2025-12-29T22:06:20.679Z] [DeepgramVoiceInteraction] New connection - triggering greeting flow

[1A[2K  [2025-12-29T22:06:20.679Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Welcome

[1A[2K  [2025-12-29T22:06:20.727Z] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K  [2025-12-29T22:06:20.727Z] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K  [2025-12-29T22:06:20.727Z] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K  [2025-12-29T22:06:20.727Z] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K  [2025-12-29T22:06:20.728Z] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K  [2025-12-29T22:06:20.728Z] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K  [2025-12-29T22:06:20.728Z] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:20.728Z] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K  [2025-12-29T22:06:20.728Z] [WebSocketManager:agent] Started keepalive interval

[1A[2K  [2025-12-29T22:06:20.728Z] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K  [2025-12-29T22:06:20.760Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.760Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:20.760Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K  [2025-12-29T22:06:20.760Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K  [2025-12-29T22:06:20.760Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K  [2025-12-29T22:06:20.761Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K  [2025-12-29T22:06:20.776Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.776Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:20.776Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"ConversationText","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K  [2025-12-29T22:06:20.776Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: ConversationText, role: assistant, content: Hello! How can I assist you today?}

[1A[2K  [2025-12-29T22:06:20.776Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: ConversationText

[1A[2K  [2025-12-29T22:06:20.777Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: ConversationText

[1A[2K  [2025-12-29T22:06:20.782Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.782Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:20.782Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"History","role":"assistant","content":"Hello! How can I assist you today?"}

[1A[2K  [2025-12-29T22:06:20.782Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: History, role: assistant, content: Hello! How can I assist you today?}

[1A[2K  [2025-12-29T22:06:20.782Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: History

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: History

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.783Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.784Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.784Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.784Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.784Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.784Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.784Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.785Z] [DeepgramVoiceInteraction] ğŸ” [agentOptions Change] Diagnostic: {agentOptionsChanged: false, agentOptionsExists: true, agentManagerExists: true, connectionState: connected, isConnected: true}

[1A[2K  [2025-12-29T22:06:20.785Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.786Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.786Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.787Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.787Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.787Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.788Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.788Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.802Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.813Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.814Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.814Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.814Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.814Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.814Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.815Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.815Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.815Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.815Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.815Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.815Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.816Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.817Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.817Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.817Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.817Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.817Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.817Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.818Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.818Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.818Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.818Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.818Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.818Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.819Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.820Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.821Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.821Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.821Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.821Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.821Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.822Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.822Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.822Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.823Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.823Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.823Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.823Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.824Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.824Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.824Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.825Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.825Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.825Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.826Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.826Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.826Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.827Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.827Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.827Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.828Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.828Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.828Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.828Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.830Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.844Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.845Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.845Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.857Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.858Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.859Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.860Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.861Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.862Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.862Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.862Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.862Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.862Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.862Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.863Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.863Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.863Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.863Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.863Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.863Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.864Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.864Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.864Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.864Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.864Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.865Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.869Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.870Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.871Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.872Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.875Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.876Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.877Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.877Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.877Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.878Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.878Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.879Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.879Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.879Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.880Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.880Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.880Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.880Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.881Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.881Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.881Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.881Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.882Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.882Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.882Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.882Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.883Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.883Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.883Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.884Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.885Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.886Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.886Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.886Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.886Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.887Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.887Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.887Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.888Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.889Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.889Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.889Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.889Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.889Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.896Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.897Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.898Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.899Z] [WebSocketManager:agent] Received Blob binary data (size: 960), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.900Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.900Z] [WebSocketManager:agent] Received message data type: object, is ArrayBuffer: false, is Blob: true

[1A[2K  [2025-12-29T22:06:20.900Z] [WebSocketManager:agent] Received Blob binary data (size: 408), converting to ArrayBuffer...

[1A[2K  [2025-12-29T22:06:20.901Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:20.901Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:20.901Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"AgentAudioDone"}

[1A[2K  [2025-12-29T22:06:20.901Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: AgentAudioDone}

[1A[2K  [2025-12-29T22:06:20.903Z] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K  [2025-12-29T22:06:20.903Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: AgentAudioDone

[1A[2K  [2025-12-29T22:06:20.903Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: AgentAudioDone

[1A[2K  [2025-12-29T22:06:20.903Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.904Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.905Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.905Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.905Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.905Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.906Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.906Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.906Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.906Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.907Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.907Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.907Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.908Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.908Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.908Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 960), emitting binary event...

[1A[2K  [2025-12-29T22:06:20.911Z] [WebSocketManager:agent] Converted Blob to ArrayBuffer (byteLength: 408), emitting binary event...

[1A[2K  [2025-12-29T22:06:22.395Z] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K  [2025-12-29T22:06:22.395Z] [WebSocketManager:transcription] WebSocket already connected or connecting

[1A[2K  [2025-12-29T22:06:22.395Z] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K  [2025-12-29T22:06:22.395Z] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K  [2025-12-29T22:06:22.395Z] [WebSocketManager:agent] WebSocket already connected or connecting

[1A[2K  [2025-12-29T22:06:22.395Z] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K  [2025-12-29T22:06:25.660Z] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K  [2025-12-29T22:06:27.513Z] [WebSocketManager:transcription] Sending JSON: {type: CloseStream}

[1A[2K  [2025-12-29T22:06:27.572Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:27.572Z] [WebSocketManager:transcription] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:27.572Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Results","channel_index":[0,1],"duration":0.02,"start":0.0,"is_final":true,"speech_final":true,"channel":{"alternatives":[{"transcript":"","confidence":0.0,"words":[]}]},"metadata":{"request_id":"8e784775-19cc-4635-95cb-5994147bce34","model_info":{"name":"general-nova-3","version":"2025-04-17.21547","arch":"nova-3"},"model_uuid":"40bd3654-e622-47c4-a111-63a61b23bfe8"},"from_finalize":false}

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Results, channel_index: Array(2), duration: 0.02, start: 0, is_final: true}

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] NOT resetting idle timeout - empty transcript

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Results

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Results

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Results","channel_index":[0,1],"duration":0.0,"start":0.02,"is_final":true,"speech_final":true,"channel":{"alternatives":[{"transcript":"","confidence":0.0,"words":[]}]},"metadata":{"request_id":"8e784775-19cc-4635-95cb-5994147bce34","model_info":{"name":"general-nova-3","version":"2025-04-17.21547","arch":"nova-3"},"model_uuid":"40bd3654-e622-47c4-a111-63a61b23bfe8"},"from_finalize":false}

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Results, channel_index: Array(2), duration: 0, start: 0.02, is_final: true}

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] NOT resetting idle timeout - empty transcript

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Results

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Results

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:27.573Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Metadata","transaction_key":"deprecated","request_id":"8e784775-19cc-4635-95cb-5994147bce34","sha256":"9e132485d5107211de325a45e7917cbe3e4b5b9cde3e4ee91d7d2102317759ee","created":"2025-12-29T22:06:20.597Z","duration":0.02,"channels":1,"models":["40bd3654-e622-47c4-a111-63a61b23bfe8"],"model_info":{"40bd3654-e622-47c4-a111-63a61b23bfe8":{"name":"general-nova-3","version":"2025-04-17.21547","arch":"nova-3"}}}

[1A[2K  [2025-12-29T22:06:27.574Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Metadata, transaction_key: deprecated, request_id: 8e784775-19cc-4635-95cb-5994147bce34, sha256: 9e132485d5107211de325a45e7917cbe3e4b5b9cde3e4ee91d7d2102317759ee, created: 2025-12-29T22:06:20.597Z}

[1A[2K  [2025-12-29T22:06:27.574Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Metadata

[1A[2K  [2025-12-29T22:06:27.574Z] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Metadata

[1A[2K  [2025-12-29T22:06:27.575Z] [WebSocketManager:transcription] WebSocket closed: code=1000, reason='', wasClean=true

[1A[2K  [2025-12-29T22:06:27.575Z] [WebSocketManager:transcription] No keepalive interval to stop

[1A[2K  [2025-12-29T22:06:27.575Z] [WebSocketManager:transcription] ğŸ”§ [WebSocketManager] No keepalive interval was running to stop

[1A[2K  [2025-12-29T22:06:27.575Z] 22:06:27 - transcription connection state: closed

[1A[2K  [2025-12-29T22:06:27.575Z] [WebSocketManager:transcription] ğŸ”„ [LAZY_RECONNECT] Connection closed - lazy reconnection enabled, waiting for manual trigger

[1A[2K  [2025-12-29T22:06:27.575Z] [WebSocketManager:transcription] ğŸ”„ [LAZY_RECONNECT] Close details: code=1000, reason='', wasClean=true

[1A[2K  [2025-12-29T22:06:27.575Z] [WebSocketManager:transcription] ğŸ”„ [LAZY_RECONNECT] Previous connection state: closed

[1A[2K  [2025-12-29T22:06:27.576Z] [WebSocketManager:transcription] ğŸ”„ [LAZY_RECONNECT] Reconnect attempts would have been: 0/5

[1A[2K  [2025-12-29T22:06:28.518Z] [WebSocketManager:transcription] Closing WebSocket

[1A[2K  [2025-12-29T22:06:28.518Z] [WebSocketManager:transcription] ğŸ”§ [WebSocketManager] close() called from:     at Object.stop (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/components/DeepgramVoiceInteraction/index.tsx?t=1767045259176:1828:41)
    at async toggleMicrophone (http://localhost:5173/src/App.tsx?t=1767045568497:625:9)

[1A[2K  [2025-12-29T22:06:28.518Z] [WebSocketManager:transcription] No keepalive interval to stop

[1A[2K  [2025-12-29T22:06:28.518Z] [WebSocketManager:transcription] ğŸ”§ [WebSocketManager] No keepalive interval was running to stop

[1A[2K  [2025-12-29T22:06:28.519Z] [WebSocketManager:agent] Closing WebSocket

[1A[2K  [2025-12-29T22:06:28.519Z] [WebSocketManager:agent] ğŸ”§ [WebSocketManager] close() called from:     at Object.stop (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/components/DeepgramVoiceInteraction/index.tsx?t=1767045259176:1832:33)
    at async toggleMicrophone (http://localhost:5173/src/App.tsx?t=1767045568497:625:9)

[1A[2K  [2025-12-29T22:06:28.519Z] [WebSocketManager:agent] Stopped keepalive interval

[1A[2K  [2025-12-29T22:06:28.519Z] [WebSocketManager:agent] ğŸ”§ [WebSocketManager] Keepalive interval cleared and stopped

[1A[2K  [2025-12-29T22:06:28.519Z] 22:06:28 - agent connection state: closed

[1A[2K  [2025-12-29T22:06:28.519Z] ğŸ”§ [Connection] Agent connection closed - checking for errors or reasons

[1A[2K  [2025-12-29T22:06:28.519Z] ğŸ”§ [Connection] Connection close event details: {type: state, state: closed, isReconnection: undefined}

[1A[2K  [2025-12-29T22:06:28.519Z] ğŸ”§ [Connection] hasSentSettingsRef and globalSettingsSent reset to false due to connection close

[1A[2K  [2025-12-29T22:06:28.519Z] Reset hasSentSettings flag due to connection close

[1A[2K  [2025-12-29T22:06:28.562Z] ğŸ” [AUDIO BLOCKING] start() - Fresh connection detected, resetting allowAgentRef from true to true

[1A[2K  [2025-12-29T22:06:28.562Z] [DeepgramVoiceInteraction] ğŸ”„ Fresh connection starting - resetting audio blocking state

[1A[2K  [2025-12-29T22:06:28.563Z] [WebSocketManager:transcription] WebSocketManager created

[1A[2K  [2025-12-29T22:06:28.563Z] ğŸ”§ [AGENT] Creating WebSocketManager with URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K  [2025-12-29T22:06:28.563Z] [WebSocketManager:agent] WebSocketManager created

[1A[2K  [2025-12-29T22:06:28.569Z] [DeepgramVoiceInteraction] Connecting Transcription WebSocket...

[1A[2K  [2025-12-29T22:06:28.569Z] [WebSocketManager:transcription] Connecting to WebSocket...

[1A[2K  [2025-12-29T22:06:28.570Z] 22:06:28 - transcription connection state: connecting

[1A[2K  [2025-12-29T22:06:28.570Z] [WebSocketManager:transcription] Built URL with params: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [2025-12-29T22:06:28.570Z] [WebSocketManager:transcription] Connecting to wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [2025-12-29T22:06:28.570Z] ğŸ”Œ [WebSocketManager.connect] URL: wss://api.deepgram.com/v1/listen?model=nova-3&language=en-US&smart_format=true&interim_results=true&diarize=true&channels=1&vad_events=true&utterance_end_ms=1000&sample_rate=16000&encoding=linear16&service=transcription

[1A[2K  [2025-12-29T22:06:28.570Z] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K  [2025-12-29T22:06:28.570Z] ğŸ”Œ [WebSocketManager.connect] Service: transcription

[1A[2K  [2025-12-29T22:06:28.570Z] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K  [2025-12-29T22:06:28.570Z] [WebSocketManager:transcription] Initial readyState: 0

[1A[2K  [2025-12-29T22:06:28.593Z] [WebSocketManager:agent] WebSocket closed: code=1000, reason='Closed by client', wasClean=true

[1A[2K  [2025-12-29T22:06:28.593Z] [WebSocketManager:agent] No keepalive interval to stop

[1A[2K  [2025-12-29T22:06:28.593Z] [WebSocketManager:agent] ğŸ”§ [WebSocketManager] No keepalive interval was running to stop

[1A[2K  [2025-12-29T22:06:28.593Z] ğŸ”§ [Connection] Agent connection closed - checking for errors or reasons

[1A[2K  [2025-12-29T22:06:28.593Z] ğŸ”§ [Connection] Connection close event details: {type: state, state: closed, isReconnection: undefined}

[1A[2K  [2025-12-29T22:06:28.593Z] ğŸ”§ [Connection] hasSentSettingsRef and globalSettingsSent reset to false due to connection close

[1A[2K  [2025-12-29T22:06:28.593Z] Reset hasSentSettings flag due to connection close

[1A[2K  [2025-12-29T22:06:28.714Z] [WebSocketManager:transcription] WebSocket connected

[1A[2K  [2025-12-29T22:06:28.714Z] 22:06:28 - transcription connection state: connected

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription

[1A[2K  [2025-12-29T22:06:28.715Z] [DeepgramVoiceInteraction] Transcription WebSocket connected

[1A[2K  [2025-12-29T22:06:28.715Z] [DeepgramVoiceInteraction] Connecting Agent WebSocket...

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:agent] Connecting to WebSocket...

[1A[2K  [2025-12-29T22:06:28.715Z] 22:06:28 - agent connection state: connecting

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:agent] Built URL with params: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:agent] Connecting to wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:28.715Z] ğŸ”Œ [WebSocketManager.connect] URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:28.715Z] ğŸ”Œ [WebSocketManager.connect] Is proxy mode: false

[1A[2K  [2025-12-29T22:06:28.715Z] ğŸ”Œ [WebSocketManager.connect] Service: agent

[1A[2K  [2025-12-29T22:06:28.715Z] ğŸ”Œ [WebSocketManager.connect] Created WebSocket with token protocol (direct mode)

[1A[2K  [2025-12-29T22:06:28.715Z] [WebSocketManager:agent] Initial readyState: 0

[1A[2K  [2025-12-29T22:06:28.815Z] [WebSocketManager:agent] WebSocket connected

[1A[2K  [2025-12-29T22:06:28.815Z] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K  [2025-12-29T22:06:28.816Z] [DeepgramVoiceInteraction] Agent WebSocket connected for first time

[1A[2K  [2025-12-29T22:06:28.816Z] 22:06:28 - agent connection state: connected

[1A[2K  [2025-12-29T22:06:28.816Z] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K  [2025-12-29T22:06:28.816Z] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K  [2025-12-29T22:06:28.817Z] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  [2025-12-29T22:06:28.817Z] [WebSocketManager:agent] Agent service: Keepalive will start after Settings is sent

[1A[2K  [2025-12-29T22:06:28.817Z] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K  [2025-12-29T22:06:28.817Z] [DeepgramVoiceInteraction] Agent WebSocket connected

[1A[2K  [2025-12-29T22:06:28.817Z] [DeepgramVoiceInteraction] Agent service already connected, skipping connection

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:transcription] Sending binary data: 320 bytes

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"Welcome","request_id":"22af7076-22f9-405b-8efc-e1694b81b06f"}

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: Welcome, request_id: 22af7076-22f9-405b-8efc-e1694b81b06f}

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: Welcome

[1A[2K  [2025-12-29T22:06:28.819Z] âœ… [Protocol] Welcome message received - dual mode connection established

[1A[2K  [2025-12-29T22:06:28.819Z] [DeepgramVoiceInteraction] Welcome message received - dual mode connection established

[1A[2K  [2025-12-29T22:06:28.819Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: Welcome

[1A[2K  [2025-12-29T22:06:28.868Z] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K  [2025-12-29T22:06:28.868Z] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K  [2025-12-29T22:06:28.869Z] ğŸ“¤ [Component] WebSocketManager exists? true

[1A[2K  [2025-12-29T22:06:28.869Z] ğŸ“¤ [Component] WebSocket URL: wss://agent.deepgram.com/v1/agent/converse

[1A[2K  [2025-12-29T22:06:28.869Z] ğŸ“¤ [Component] - WebSocket exists? true

[1A[2K  [2025-12-29T22:06:28.869Z] ğŸ“¤ [Component] - WebSocket readyState: 1 (OPEN)

[1A[2K  [2025-12-29T22:06:28.869Z] ğŸ“¤ [Component] - WebSocket URL: wss://agent.deepgram.com/v1/agent/converse?service=agent

[1A[2K  [2025-12-29T22:06:28.869Z] [WebSocketManager:agent] Settings sent - keepalive can now send KeepAlive messages

[1A[2K  [2025-12-29T22:06:28.869Z] [WebSocketManager:agent] Started keepalive interval

[1A[2K  [2025-12-29T22:06:28.869Z] [WebSocketManager:agent] Sending JSON: {type: Settings, audio: Object, agent: Object}

[1A[2K  [2025-12-29T22:06:28.908Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Received message from server

[1A[2K  [2025-12-29T22:06:28.908Z] [WebSocketManager:agent] Received message data type: string, is ArrayBuffer: false, is Blob: false

[1A[2K  [2025-12-29T22:06:28.908Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"SettingsApplied"}

[1A[2K  [2025-12-29T22:06:28.908Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: SettingsApplied}

[1A[2K  [2025-12-29T22:06:28.908Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: SettingsApplied

[1A[2K  [2025-12-29T22:06:28.909Z] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: SettingsApplied

[1A[2K  [2025-12-29T22:06:30.900Z] ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2K  [2025-12-29T22:06:30.900Z] [WebSocketManager:agent] Closing WebSocket

[1A[2K  [2025-12-29T22:06:30.900Z] [WebSocketManager:agent] ğŸ”§ [WebSocketManager] close() called from:     at IdleTimeoutService.onTimeoutCallback (http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/hooks/useIdleTimeoutManager.ts:36:32)
    at http://localhost:5173/@fs/Users/davidmcgee/Development/dg_react_agent/src/utils/IdleTimeoutService.ts:257:31

[1A[2K  [2025-12-29T22:06:30.900Z] [WebSocketManager:agent] Stopped keepalive interval

[1A[2K  [2025-12-29T22:06:30.900Z] [WebSocketManager:agent] ğŸ”§ [WebSocketManager] Keepalive interval cleared and stopped

[1A[2K  [2025-12-29T22:06:30.901Z] 22:06:30 - agent connection state: closed

[1A[2K  [2025-12-29T22:06:30.901Z] ğŸ”§ [Connection] Agent connection closed - checking for errors or reasons

[1A[2K  [2025-12-29T22:06:30.901Z] ğŸ”§ [Connection] Connection close event details: {type: state, state: closed, isReconnection: undefined}

[1A[2K  [2025-12-29T22:06:30.901Z] ğŸ”§ [Connection] hasSentSettingsRef and globalSettingsSent reset to false due to connection close

[1A[2K  [2025-12-29T22:06:30.901Z] Reset hasSentSettings flag due to connection close

[1A[2K  [2025-12-29T22:06:30.973Z] [WebSocketManager:agent] WebSocket closed: code=1000, reason='Closed by client', wasClean=true

[1A[2K  [2025-12-29T22:06:30.973Z] [WebSocketManager:agent] No keepalive interval to stop

[1A[2K  [2025-12-29T22:06:30.973Z] [WebSocketManager:agent] ğŸ”§ [WebSocketManager] No keepalive interval was running to stop

[1A[2K  [2025-12-29T22:06:30.974Z] ğŸ”§ [Connection] Agent connection closed - checking for errors or reasons

[1A[2K  [2025-12-29T22:06:30.974Z] ğŸ”§ [Connection] Connection close event details: {type: state, state: closed, isReconnection: undefined}

[1A[2K  [2025-12-29T22:06:30.974Z] ğŸ”§ [Connection] hasSentSettingsRef and globalSettingsSent reset to false due to connection close

[1A[2K  [2025-12-29T22:06:30.974Z] Reset hasSentSettings flag due to connection close

[1A[2K  [2025-12-29T22:06:31.585Z] [WebSocketManager:transcription] Sending binary data: 8192 bytes

[1A[2K
ğŸ™ï¸ VAD LOGS:

[1A[2K  [2025-12-29T22:06:20.383Z] VAD: utterance_end_ms set to 1000ms

[1A[2K  [2025-12-29T22:06:20.383Z] VAD: interim_results set to true

[1A[2K  [2025-12-29T22:06:20.783Z] ğŸ” [DEBUG] Checking for VAD event type: History

[1A[2K  [2025-12-29T22:06:28.563Z] VAD: utterance_end_ms set to 1000ms

[1A[2K  [2025-12-29T22:06:28.563Z] VAD: interim_results set to true

[1A[2K  [2025-12-29T22:06:31.585Z] ğŸµ [TRANSCRIPTION] Sending audio data to transcription service for VAD events

[1A[2K
ğŸ” RELIABILITY ANALYSIS:

[1A[2K  âŒ ISSUE: Microphone not disabled after timeout

[1A[2K  âœ… Microphone successfully re-enabled

[1A[2K  âŒ ISSUE: Connection not established after re-enable

[1A[2K
ğŸ“‹ RECOMMENDATIONS:

[1A[2K  ğŸ’¡ Fix: Ensure microphone disables when connection closes

[1A[2K  ğŸ’¡ Fix: Debug connection re-establishment

[1A[2K
============================================================

[1A[2K[119/178] [chromium] â€º tests/e2e/microphone-reliability.spec.js:164:3 â€º Microphone Reliability Diagnostics â€º should test connection state consistency
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2K[chromium] â€º tests/e2e/simple-mic-test.spec.js:16:3 â€º Simple Microphone State Tests â€º should test basic microphone functionality
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:48:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should display VAD status elements
ğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2K[120/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:62:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should initialize with default VAD states
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:62:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should initialize with default VAD states
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/simple-mic-test.spec.js:16:3 â€º Simple Microphone State Tests â€º should test basic microphone functionality
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Basic microphone functionality verified!

[1A[2K[121/178] [chromium] â€º tests/e2e/strict-mode-behavior.spec.js:25:3 â€º StrictMode Behavior Validation â€º should preserve connections during StrictMode cleanup/re-mount cycle
[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:25:3 â€º StrictMode Behavior Validation â€º should preserve connections during StrictMode cleanup/re-mount cycle
ğŸ”§ Testing StrictMode connection preservation...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:25:3 â€º StrictMode Behavior Validation â€º should preserve connections during StrictMode cleanup/re-mount cycle
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:387:3 â€º Idle Timeout Behavior â€º should handle idle timeout correctly - connection closes after 10 seconds of inactivity
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[BROWSER] ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart

[1A[2Kâœ… Connection closed after 10017ms (expected: ~10000ms)

[1A[2Kâœ… Connection closed due to idle timeout after 10017ms

[1A[2KğŸ” Final timeout state: { agentManager: [1mnull[22m, transcriptionManager: [1mnull[22m }

[1A[2KğŸ” Idle timeout related logs: [
  [32m'ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: null'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)'[39m,
  [32m'ğŸ¯ [DEBUG] No timeout to stop (timeoutId is null)'[39m,
  [32m'[WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent'[39m,
  [32m'[WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED'[39m,
  [32m'ğŸ¯ [DEBUG] Started polling for idle timeout conditions'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] disableResets() called'[39m,
  [32m'ğŸ¯ [DEBUG] stopTimeout() called - timeoutId: null'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)'[39m,
  [32m'ğŸ¯ [DEBUG] No timeout to stop (timeoutId is null)'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] disableResets() called'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] disableResets() called'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle'[39m,
  [32m'ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout'[39m,
  [32m'ğŸ¯ [DEBUG] Starting timeout with timeoutId: null'[39m,
  [32m'ğŸ¯ [DEBUG] Timeout started with timeoutId: 17'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)'[39m,
  [32m'[WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ”§ [TRANSCRIPTION] Starting periodic keepalive audio to prevent timeout'[39m,
  [32m'[WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription'[39m,
  [32m'[WebSocketManager:transcription] Keepalive disabled - connections will timeout naturally'[39m,
  [32m'[WebSocketManager:transcription] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for transcription'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=startAudioCapture, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false'[39m,
  [32m'ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout'[39m,
  [32m'ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout'[39m,
  [32m'ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout'[39m,
  [32m'ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout'[39m,
  [32m'ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  [32m'ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false'[39m,
  [32m'ğŸ¯ [DEBUG] checkAndStartTimeoutIfNeeded() - conditions met but timeout already running, skipping restart'[39m,
  ... 80 more items
]

[1A[2Kâš ï¸ Idle timeout may not be working as expected

[1A[2KğŸ‰ Idle timeout behavior test completed successfully!

[1A[2K[122/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:485:3 â€º Idle Timeout Behavior â€º should reset idle timeout when startAudioCapture() is called (Issue #222)
[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:164:3 â€º Microphone Reliability Diagnostics â€º should test connection state consistency
ğŸ” Testing connection state consistency...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:485:3 â€º Idle Timeout Behavior â€º should reset idle timeout when startAudioCapture() is called (Issue #222)
ğŸ§ª Testing Issue #222: startAudioCapture() should reset idle timeout...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:62:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should initialize with default VAD states
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:25:3 â€º StrictMode Behavior Validation â€º should preserve connections during StrictMode cleanup/re-mount cycle
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ“Š Initial connection status: connected

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:62:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should initialize with default VAD states
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:25:3 â€º StrictMode Behavior Validation â€º should preserve connections during StrictMode cleanup/re-mount cycle
ğŸ“Š Connection status after StrictMode cycle: connected

[1A[2Kâœ… StrictMode detection working - connections preserved

[1A[2Kâœ… StrictMode connection preservation verified!

[1A[2K[123/178] [chromium] â€º tests/e2e/strict-mode-behavior.spec.js:93:3 â€º StrictMode Behavior Validation â€º should detect StrictMode cleanup in console logs
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:485:3 â€º Idle Timeout Behavior â€º should reset idle timeout when startAudioCapture() is called (Issue #222)
âœ… Connection established

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:93:3 â€º StrictMode Behavior Validation â€º should detect StrictMode cleanup in console logs
ğŸ” Testing StrictMode cleanup detection logging...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:62:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should initialize with default VAD states
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:93:3 â€º StrictMode Behavior Validation â€º should detect StrictMode cleanup in console logs
ğŸ“‹ Found 2 mount log(s)

[1A[2Kâš ï¸ No cleanup logs found (this may be normal if logging is conditional)

[1A[2Kâœ… Component behavior is still validated by other StrictMode tests

[1A[2Kâœ… StrictMode behavior verified (connections preserved as tested in other tests)

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:62:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should initialize with default VAD states
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2K[124/178] [chromium] â€º tests/e2e/strict-mode-behavior.spec.js:140:3 â€º StrictMode Behavior Validation â€º should close connections on actual component unmount (not StrictMode)
[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:140:3 â€º StrictMode Behavior Validation â€º should close connections on actual component unmount (not StrictMode)
ğŸ” Testing actual unmount behavior (negative test for StrictMode)...

[1A[2K[125/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:72:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should handle microphone toggle with VAD elements
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:72:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should handle microphone toggle with VAD elements
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:140:3 â€º StrictMode Behavior Validation â€º should close connections on actual component unmount (not StrictMode)
âœ… Actual unmount test completed

[1A[2KğŸ“‹ Captured 2 connection state change logs

[1A[2KğŸ§¹ Captured 2 cleanup-related logs

[1A[2K[126/178] [chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ”„ Testing connection stability across multiple StrictMode cycles...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:72:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should handle microphone toggle with VAD elements
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:164:3 â€º Microphone Reliability Diagnostics â€º should test connection state consistency
Connection status: connected

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:485:3 â€º Idle Timeout Behavior â€º should reset idle timeout when startAudioCapture() is called (Issue #222)
â³ Waiting ~9 seconds to get close to idle timeout...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:72:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should handle microphone toggle with VAD elements
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:72:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should handle microphone toggle with VAD elements
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:72:5 â€º Real User Workflow Tests â€º Mock-Based Tests (Always Run) â€º should handle microphone toggle with VAD elements
ğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[127/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:92:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle complete user workflow: speak â†’ detect â†’ respond
[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
âœ… Connection confirmed as closed after timeout

[1A[2KğŸ¤ Microphone button clicked for reconnection

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ“Š Connection check 1/5: connected

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:92:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle complete user workflow: speak â†’ detect â†’ respond
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ“Š Connection check 2/5: connected

[1A[2KğŸ“Š Connection check 3/5: connected

[1A[2K[chromium] â€º tests/e2e/microphone-functionality-fixed.spec.js:107:3 â€º Fixed Microphone Functionality Tests â€º should handle microphone activation after idle timeout (FIXED)
âœ… Connection re-established

[1A[2Kâœ… Microphone enabled after reconnection

[1A[2Kâœ… Microphone activation after idle timeout successful!

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ“Š Connection check 4/5: connected

[1A[2K[128/178] [chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
[1A[2K[chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
ğŸ§ª Testing idle timeout with suspended AudioContext...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:192:3 â€º StrictMode Behavior Validation â€º should maintain connection stability during multiple StrictMode cycles
ğŸ“Š Connection check 5/5: connected

[1A[2Kâœ… Connection stability across StrictMode cycles verified!

[1A[2K[129/178] [chromium] â€º tests/e2e/strict-mode-behavior.spec.js:227:3 â€º StrictMode Behavior Validation â€º should not close connections when props change during StrictMode
[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:227:3 â€º StrictMode Behavior Validation â€º should not close connections when props change during StrictMode
ğŸ”§ Testing prop changes during StrictMode...

[1A[2K[chromium] â€º tests/e2e/microphone-reliability.spec.js:164:3 â€º Microphone Reliability Diagnostics â€º should test connection state consistency
Connection status after sleep: connected

[1A[2K
ğŸ“Š CONNECTION STATE CHANGES:

[1A[2K  [2025-12-29T22:06:34.747Z] ğŸ”§ [AGENT] Connection mode: direct

[1A[2K  [2025-12-29T22:06:34.749Z] 22:06:34 - transcription connection state: connecting

[1A[2K  [2025-12-29T22:06:34.902Z] 22:06:34 - transcription connection state: connected

[1A[2K  [2025-12-29T22:06:34.903Z] 22:06:34 - agent connection state: connecting

[1A[2K  [2025-12-29T22:06:35.063Z] ğŸ”— [Protocol] Agent WebSocket connected

[1A[2K  [2025-12-29T22:06:35.063Z] 22:06:35 - agent connection state: connected

[1A[2K  [2025-12-29T22:06:35.064Z] ğŸ”§ [Connection State] Agent connected, checking if Settings should be sent: {hasSentSettingsRef: false, globalSettingsSent: false, stateHasSentSettings: false, shouldSend: true}

[1A[2K  [2025-12-29T22:06:35.065Z] [DeepgramVoiceInteraction] Connection established, sending settings via connection state handler

[1A[2K  [2025-12-29T22:06:35.065Z] ğŸ”§ [Connection State] âœ… Will send Settings after WebSocket is fully open

[1A[2K  [2025-12-29T22:06:35.115Z] ğŸ”§ [Connection State] Checking WebSocket state: 1 (OPEN)

[1A[2K  [2025-12-29T22:06:35.115Z] ğŸ”§ [Connection State] WebSocket is OPEN, sending Settings

[1A[2K  [2025-12-29T22:06:36.778Z] ğŸ” [AUDIO BLOCKING] start() - Connection already exists (agent=true, transcription=true), preserving allowAgentRef.current=true

[1A[2K  [2025-12-29T22:06:36.778Z] [DeepgramVoiceInteraction] ğŸ”„ Connection already exists - preserving audio blocking state

[1A[2K[130/178] [chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:16:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should timeout after text interaction even with suspended AudioContext
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:92:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle complete user workflow: speak â†’ detect â†’ respond
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:16:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should timeout after text interaction even with suspended AudioContext
ğŸ§ª Testing idle timeout after text interaction with suspended AudioContext...

[1A[2K[chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
Step 1: Establishing connection...

[1A[2KInitial connection status: connected

[1A[2KStep 2: Waiting for agent greeting...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:92:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle complete user workflow: speak â†’ detect â†’ respond
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:16:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should timeout after text interaction even with suspended AudioContext
Step 1: Establishing connection via text input...

[1A[2KInitial connection status: connected

[1A[2KInitial AudioContext state: running

[1A[2KStep 3: Sending text message...

[1A[2KStep 4: Waiting for agent response...

[1A[2KAudioContext state after response: running

[1A[2KStep 6: Waiting for idle timeout...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:92:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle complete user workflow: speak â†’ detect â†’ respond
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/strict-mode-behavior.spec.js:227:3 â€º StrictMode Behavior Validation â€º should not close connections when props change during StrictMode
âœ… Prop changes during StrictMode handled correctly

[1A[2K[131/178] [chromium] â€º tests/e2e/text-session-flow.spec.js:28:3 â€º Text Session Flow â€º should auto-connect and re-establish connection when WebSocket is closed
[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:28:3 â€º Text Session Flow â€º should auto-connect and re-establish connection when WebSocket is closed
ğŸ§ª Testing auto-connect when WebSocket is closed

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:92:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle complete user workflow: speak â†’ detect â†’ respond
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KSimulating user speech: "Hello, how are you?"

[1A[2KReal API workflow test completed - VAD elements verified

[1A[2K[132/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:28:3 â€º Text Session Flow â€º should auto-connect and re-establish connection when WebSocket is closed
âœ… Initial connection established

[1A[2KğŸ“ Step 1: Sending first message

[1A[2Kâœ… First message sent and agent responded

[1A[2Kâ¸ï¸ Step 2: Disconnecting to simulate idle timeout

[1A[2K[chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:16:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should timeout after text interaction even with suspended AudioContext
âœ… Connection closed after 1007ms (expected: ~10000ms)

[1A[2Kâœ… Connection closed after 1007ms (expected: ~10000ms)

[1A[2K[133/178] [chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:63:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should resume AudioContext on text input focus
[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:28:3 â€º Text Session Flow â€º should auto-connect and re-establish connection when WebSocket is closed
âœ… Component disconnected

[1A[2KğŸ“ Step 3: Sending second message (should auto-connect)

[1A[2Kâœ… Connection re-established via auto-connect and agent responded

[1A[2KğŸ‰ Auto-connect test PASSED

[1A[2K[chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:63:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should resume AudioContext on text input focus
ğŸ§ª Testing AudioContext resumption on text input focus...

[1A[2K[134/178] [chromium] â€º tests/e2e/text-session-flow.spec.js:57:3 â€º Text Session Flow â€º should handle rapid message exchange within idle timeout
[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:57:3 â€º Text Session Flow â€º should handle rapid message exchange within idle timeout
ğŸ§ª Testing rapid message exchange within 10-second idle timeout

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:57:3 â€º Text Session Flow â€º should handle rapid message exchange within idle timeout
âœ… Initial connection established

[1A[2KğŸ“ Sending message 1/3

[1A[2K[chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
AudioContext state after greeting: running

[1A[2KStep 4: Waiting for idle timeout...

[1A[2K[chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:63:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should resume AudioContext on text input focus
Initial AudioContext state: running

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
â³ +1003ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:57:3 â€º Text Session Flow â€º should handle rapid message exchange within idle timeout
ğŸ“ Sending message 2/3

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/text-idle-timeout-suspended-audio.spec.js:63:3 â€º Text Input Idle Timeout with Suspended AudioContext â€º should resume AudioContext on text input focus
AudioContext state after focus: running

[1A[2Kâœ… AudioContext resumed to running state

[1A[2K[135/178] [chromium] â€º tests/e2e/transcription-config-test.spec.js:5:3 â€º Transcription Configuration Test â€º should verify transcription service is properly configured
[1A[2K[chromium] â€º tests/e2e/transcription-config-test.spec.js:5:3 â€º Transcription Configuration Test â€º should verify transcription service is properly configured
ğŸ” Testing transcription service configuration...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:118:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle real speech-to-text processing
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KSimulating user speech: "What is the weather today?"

[1A[2KReal speech-to-text test completed - VAD elements verified

[1A[2K[chromium] â€º tests/e2e/transcription-config-test.spec.js:5:3 â€º Transcription Configuration Test â€º should verify transcription service is properly configured
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[136/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:139:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle VAD event processing with real API
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:139:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle VAD event processing with real API
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:57:3 â€º Text Session Flow â€º should handle rapid message exchange within idle timeout
ğŸ“ Sending message 3/3

[1A[2Kâœ… All messages sent and connection maintained

[1A[2KğŸ‰ Rapid message exchange test PASSED

[1A[2K[137/178] [chromium] â€º tests/e2e/text-session-flow.spec.js:89:3 â€º Text Session Flow â€º should establish connection, send settings, and respond to initial text
[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:89:3 â€º Text Session Flow â€º should establish connection, send settings, and respond to initial text
ğŸ§ª Testing initial connection flow with settings and first message

[1A[2Kâœ… Connection established

[1A[2Kâœ… Settings applied

[1A[2KğŸ” Checking for Settings message...

[1A[2Kâœ… Settings were sent on initial connection

[1A[2KğŸ“ Sending first message

[1A[2Kâœ… Agent responded

[1A[2KğŸ‰ Initial connection flow test PASSED

[1A[2K[chromium] â€º tests/e2e/transcription-config-test.spec.js:5:3 â€º Transcription Configuration Test â€º should verify transcription service is properly configured
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[138/178] [chromium] â€º tests/e2e/text-session-flow.spec.js:136:3 â€º Text Session Flow â€º should maintain connection through sequential messages
[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:136:3 â€º Text Session Flow â€º should maintain connection through sequential messages
ğŸ§ª Testing sequential message exchange with state tracking

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:139:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle VAD event processing with real API
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/transcription-config-test.spec.js:5:3 â€º Transcription Configuration Test â€º should verify transcription service is properly configured
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2KğŸ“Š Configuration: {
  "isTranscriptionConfigured": true,
  "transcriptionState": "connected",
  "agentState": "connected"
}

[1A[2KğŸ“Š Transcription connection state: connected

[1A[2KğŸ“Š Agent connection state: connected

[1A[2Kâœ… Transcription service configuration verified!

[1A[2KğŸ‰ Issue #103 RESOLVED: Transcription service configuration fixed!

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:136:3 â€º Text Session Flow â€º should maintain connection through sequential messages
âœ… Initial connection established

[1A[2KğŸ“ Sending message 1

[1A[2K[139/178] [chromium] â€º tests/e2e/user-stopped-speaking-callback.spec.js:14:3 â€º onUserStoppedSpeaking Callback Verification â€º should verify onUserStoppedSpeaking callback is implemented and working
[1A[2Kâœ… Response 1 received

[1A[2KğŸ“Š Agent state after message 1: idle

[1A[2KğŸ“ Sending message 2

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-callback.spec.js:14:3 â€º onUserStoppedSpeaking Callback Verification â€º should verify onUserStoppedSpeaking callback is implemented and working
ğŸ§ª Testing onUserStoppedSpeaking callback implementation...

[1A[2K[chromium] â€º tests/e2e/text-session-flow.spec.js:136:3 â€º Text Session Flow â€º should maintain connection through sequential messages
âœ… Response 2 received

[1A[2KğŸ‰ Sequential message exchange test PASSED

[1A[2K[140/178] [chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
ğŸ§ª Demonstrating onUserStoppedSpeaking with fake audio...

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-callback.spec.js:14:3 â€º onUserStoppedSpeaking Callback Verification â€º should verify onUserStoppedSpeaking callback is implemented and working
âœ… Test app loaded

[1A[2Kâœ… DeepgramVoiceInteraction component is available

[1A[2KğŸ¤ Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
âœ… Test app loaded

[1A[2KğŸ¤ Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:139:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle VAD event processing with real API
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:485:3 â€º Idle Timeout Behavior â€º should reset idle timeout when startAudioCapture() is called (Issue #222)
ğŸ¤ Calling startAudioCapture() - should reset idle timeout...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:139:5 â€º Real User Workflow Tests â€º Real API Integration Tests â€º should handle VAD event processing with real API
ğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KSimulating user speech: "Testing VAD events"

[1A[2KReal VAD event processing test completed

[1A[2K[141/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:163:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle utteranceEndMs configuration
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:163:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle utteranceEndMs configuration
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-callback.spec.js:14:3 â€º onUserStoppedSpeaking Callback Verification â€º should verify onUserStoppedSpeaking callback is implemented and working
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-callback.spec.js:14:3 â€º onUserStoppedSpeaking Callback Verification â€º should verify onUserStoppedSpeaking callback is implemented and working
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2KğŸ“¡ Connection status: connected

[1A[2Kâœ… Connection established

[1A[2KğŸ“Š VAD Elements Exist: {
  userSpeaking: [33mfalse[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m,
  speechStarted: [33mfalse[39m
}

[1A[2KğŸ“Š Callback Setup: {
  hasSendAudioData: [33mtrue[39m,
  hasStart: [33mtrue[39m,
  hasStop: [33mtrue[39m,
  componentType: [32m'object'[39m,
  componentKeys: [
    [32m'start'[39m,
    [32m'stop'[39m,
    [32m'updateAgentInstructions'[39m,
    [32m'interruptAgent'[39m,
    [32m'allowAgent'[39m,
    [32m'sleep'[39m,
    [32m'wake'[39m,
    [32m'toggleSleep'[39m,
    [32m'injectAgentMessage'[39m,
    [32m'injectUserMessage'[39m,
    [32m'startAudioCapture'[39m,
    [32m'sendFunctionCallResponse'[39m,
    [32m'sendAudioData'[39m,
    [32m'getAudioContext'[39m
  ]
}

[1A[2KğŸ“Š Callback Implementation: { hasEventLog: [33mtrue[39m, hasVADElements: [33mtrue[39m }

[1A[2KğŸ¯ Testing callback by simulating UtteranceEnd event...

[1A[2KğŸ“Š Callback Test Result: { success: [33mfalse[39m, error: [32m'handleTranscriptionMessage not found'[39m }

[1A[2KğŸ“Š User Stopped Speaking Logs: []

[1A[2Kâœ… onUserStoppedSpeaking callback verification completed

[1A[2Kâœ… The callback is properly implemented and configured

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2KğŸ“¡ Connection status: connected

[1A[2Kâœ… Connection established

[1A[2KğŸµ Loading pre-recorded audio sample...

[1A[2K[142/178] [chromium] â€º tests/e2e/vad-audio-patterns.spec.js:26:3 â€º VAD Audio Patterns â€º should detect VAD events with pre-generated audio samples
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:163:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle utteranceEndMs configuration
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:26:3 â€º VAD Audio Patterns â€º should detect VAD events with pre-generated audio samples
ğŸ§ª Testing VAD with pre-generated audio samples...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
â³ +6031ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:163:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle utteranceEndMs configuration
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:26:3 â€º VAD Audio Patterns â€º should detect VAD events with pre-generated audio samples
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":0.64}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] ğŸ” [DEBUG] Processing message type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process

[1A[2K[BROWSER] 22:06:49 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected

[1A[2K[BROWSER] 22:06:49 - ğŸ¤ [AGENT] User stopped speaking at 22:06:49

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:163:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle utteranceEndMs configuration
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:26:3 â€º VAD Audio Patterns â€º should detect VAD events with pre-generated audio samples
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:163:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle utteranceEndMs configuration
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KUtteranceEnd configuration test completed

[1A[2K[143/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:174:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle interimResults configuration
[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:20:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with real microphone and pre-recorded audio
â³ Waiting for Deepgram VAD to naturally detect end of speech...

[1A[2KğŸ“Š Audio sample has sufficient silence duration for UtteranceEnd detection

[1A[2Kâ³ Waiting for VAD events...

[1A[2KğŸ“Š VAD events detected: 1

[1A[2Kâœ… VAD events detected via fixture

[1A[2KğŸ“Š VAD Events in console: [33m12[39m

[1A[2KğŸ“Š Event Analysis:

[1A[2K  - UserStartedSpeaking events: [33m0[39m

[1A[2K  - UtteranceEnd events: [33m11[39m

[1A[2K  - User stopped speaking events: [33m1[39m

[1A[2Kâœ… UtteranceEnd detected: Channel: [0,1], Last word end: 0.64s

[1A[2Kâœ… User stopped speaking callback: 22:06:49

[1A[2K
ğŸ‰ SUCCESS: onUserStoppedSpeaking demonstration completed

[1A[2KğŸ’¡ This demonstrates that:

[1A[2K  1. Speech detection works via data-testid elements

[1A[2K  2. UtteranceEnd detection works via data-testid elements

[1A[2K  3. onUserStoppedSpeaking callback works via data-testid elements

[1A[2K  4. User speaking state updates correctly

[1A[2Kâœ… onUserStoppedSpeaking demonstration completed

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:174:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle interimResults configuration
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[144/178] [chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ§ª Demonstrating onUserStoppedSpeaking with multiple audio samples...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:485:3 â€º Idle Timeout Behavior â€º should reset idle timeout when startAudioCapture() is called (Issue #222)

ğŸ“Š RESULTS:

[1A[2K  Connection status after startAudioCapture(): connected

[1A[2K  Time elapsed: 3834ms

[1A[2K  Connection closes captured: 0

[1A[2Kâœ… Test passed: startAudioCapture() reset idle timeout correctly!

[1A[2Kâœ… Connection did NOT close immediately after startAudioCapture()

[1A[2K[145/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ¤ Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
ğŸ§ª Testing idle timeout after agent finishes speaking...

[1A[2K[AGENT_STATE] 22:06:50 - Agent state changed: idle

[1A[2K[PLAYBACK] 22:06:50 - Audio playback: stopped - Agent playback completed

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:174:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle interimResults configuration
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/suspended-audiocontext-idle-timeout.spec.js:14:3 â€º Suspended AudioContext Idle Timeout (Issue #139) â€º should timeout even with suspended AudioContext
âœ… Connection closed after 9043ms (expected: ~10000ms)

[1A[2Kâœ… Connection closed after 9043ms (expected: ~10000ms)

[1A[2K[146/178] [chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ§ª Testing different utterance_end_ms values for VAD offset detection...

[1A[2K
ğŸ”§ Testing utterance_end_ms: 500ms

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K[IDLE_TIMEOUT] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2Kâœ… Connection established

[1A[2KStep 1: Sending text message to trigger agent response...

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [DEBUG] Started polling for idle timeout conditions

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=InjectUserMessage, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: InjectUserMessage)

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2KStep 2: Waiting for agent to respond and finish speaking...

[1A[2Kâœ… Agent finished responding

[1A[2KStep 3: Waiting for playback to finish...

[1A[2Kâœ… Playback finished (onPlaybackStateChange(false) fired)

[1A[2KStep 4: Waiting for agent state to transition to idle after playback finishes...

[1A[2Kâœ… Agent state transitioned to idle

[1A[2KğŸ“Š Agent state after playback: "idle"

[1A[2K
ğŸ” AGENT STATE ANALYSIS:

[1A[2K  Expected: 'idle'

[1A[2K  Actual: 'idle'

[1A[2K  Status: âœ… CORRECT

[1A[2K
Step 6: Waiting for idle timeout...

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STARTED_SPEAKING

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 13

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=listening, isPlaying=false, isUserSpeaking=true

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=listening, isPlaying=false, isUserSpeaking=true

[1A[2K[AGENT_STATE] 22:06:52 - Agent state changed: listening

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2K
ğŸµ Testing sample 1/3: hello

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:174:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle interimResults configuration
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:26:3 â€º VAD Audio Patterns â€º should detect VAD events with pre-generated audio samples
âœ… VAD events detected with pre-generated audio: 1

[1A[2K[147/178] [chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":0.64}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] ğŸ” [DEBUG] Processing message type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 0.64}

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process

[1A[2K[BROWSER] 22:06:52 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected

[1A[2K[BROWSER] 22:06:52 - ğŸ¤ [AGENT] User stopped speaking at 22:06:52

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[AGENT_STATE] ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K[AGENT_STATE] 22:06:52 - Agent state changed: speaking

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ“Š VAD events detected for hello: 1

[1A[2KğŸ“Š hello results:

[1A[2K  - UtteranceEnd events: 1

[1A[2K  - User stopped speaking events: 1

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=true

[1A[2K[AGENT_STATE] 22:06:52 - Agent state changed: speaking

[1A[2K[PLAYBACK] 22:06:52 - Audio playback: started

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:174:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle interimResults configuration
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:174:5 â€º Real User Workflow Tests â€º VAD Configuration Tests â€º should handle interimResults configuration
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KInterimResults configuration test completed

[1A[2K[148/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:187:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should integrate VAD events with existing functionality
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:187:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should integrate VAD events with existing functionality
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
ğŸ§ª Testing VAD with realistic audio patterns...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT] [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STOPPED_SPEAKING

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 20

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:187:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should integrate VAD events with existing functionality
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
â³ +2003ms: Connection still connected

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ Testing with audio sample: hello

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[AGENT_STATE] 22:06:54 - Agent state changed: idle

[1A[2K[PLAYBACK] 22:06:54 - Audio playback: stopped - Agent playback completed

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples

ğŸµ Testing sample 2/3: hello_there

[1A[2KğŸ“Š VAD events detected for hello_there: 1

[1A[2KğŸ“Š hello_there results:

[1A[2K  - UtteranceEnd events: 1

[1A[2K  - User stopped speaking events: 1

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UserStartedSpeaking"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UserStartedSpeaking}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UserStartedSpeaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: UserStartedSpeaking): {type: UserStartedSpeaking}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ¤ [VAD] UserStartedSpeaking message received

[1A[2K[BROWSER] ğŸ¯ [AGENT] UserStartedSpeaking from agent service - setting isUserSpeaking=true

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UserStartedSpeaking

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
[BROWSER] 22:06:54 - ğŸ¤ [AGENT] User stopped speaking at 22:06:54

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":3.4399998}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 3.4399998}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 3.4399998}

[1A[2K[BROWSER] ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 3.4399998}

[1A[2K[BROWSER] ğŸ” [DEBUG] Processing message type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 3.4399998}

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process

[1A[2K[BROWSER] 22:06:54 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected

[1A[2K[BROWSER] 22:06:54 - ğŸ¤ [AGENT] User stopped speaking at 22:06:54

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:187:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should integrate VAD events with existing functionality
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:187:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should integrate VAD events with existing functionality
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:187:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should integrate VAD events with existing functionality
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KVAD integration test completed

[1A[2K[149/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:204:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should maintain backward compatibility
[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:204:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should maintain backward compatibility
ğŸ¤ [MICROPHONE_SETUP] Setting up microphone with VAD validation...

[1A[2KğŸ¤ [MICROPHONE_SETUP] Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ“Š Results for 500ms: {
  status: [32m'failed'[39m,
  events: [ [32m'UtteranceEnd'[39m ],
  eventsDetected: [33m1[39m,
  onsetEvents: [33mfalse[39m,
  offsetEvents: [33mtrue[39m
}

[1A[2K
ğŸ”§ Testing utterance_end_ms: 1000ms

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples

ğŸµ Testing sample 3/3: hello_extended

[1A[2KğŸ“Š VAD events detected for hello_extended: 2

[1A[2KğŸ“Š hello_extended results:

[1A[2K  - UtteranceEnd events: 1

[1A[2K  - User stopped speaking events: 1

[1A[2K
ğŸ“Š Final Results:

[1A[2K  - Total UtteranceEnd events: 3

[1A[2K  - Total User stopped speaking events: 3

[1A[2KğŸ’¡ Note: Events are detected via data-testid elements, same method as final verification

[1A[2Kâ³ Checking final state via data-testid elements...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:204:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should maintain backward compatibility
ğŸ¤ [MICROPHONE_SETUP] Enabling microphone...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
âœ… VAD events detected for hello: 1

[1A[2KğŸ¤ Testing with audio sample: hello__how_are_you_today_

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:204:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should maintain backward compatibility
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:204:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should maintain backward compatibility
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/real-user-workflows.spec.js:204:5 â€º Real User Workflow Tests â€º VAD Event Integration Tests â€º should maintain backward compatibility
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ [MICROPHONE_SETUP] VAD elements visibility: {
  vadStates: [33mtrue[39m,
  userStartedSpeaking: [33mtrue[39m,
  userStoppedSpeaking: [33mtrue[39m,
  utteranceEnd: [33mtrue[39m
}

[1A[2KğŸ¤ [MICROPHONE_SETUP] Initial VAD states: { userStartedSpeaking: [32m'Not detected'[39m, utteranceEnd: [32m'Not detected'[39m }

[1A[2KBackward compatibility test completed

[1A[2K[150/178] [chromium] â€º tests/e2e/real-user-workflows.spec.js:224:5 â€º Real User Workflow Tests â€º Error Handling â€º should handle connection errors gracefully
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[151/178] [chromium] â€º tests/e2e/vad-events-core.spec.js:27:3 â€º Core VAD Events â€º should detect basic VAD events (UserStartedSpeaking, UtteranceEnd)
[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:27:3 â€º Core VAD Events â€º should detect basic VAD events (UserStartedSpeaking, UtteranceEnd)
ğŸ§ª Testing basic VAD event detection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:27:3 â€º Core VAD Events â€º should detect basic VAD events (UserStartedSpeaking, UtteranceEnd)
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:27:3 â€º Core VAD Events â€º should detect basic VAD events (UserStartedSpeaking, UtteranceEnd)
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ“Š Results for 1000ms: {
  status: [32m'failed'[39m,
  events: [ [32m'UtteranceEnd'[39m ],
  eventsDetected: [33m1[39m,
  onsetEvents: [33mfalse[39m,
  offsetEvents: [33mtrue[39m
}

[1A[2K
ğŸ”§ Testing utterance_end_ms: 2000ms

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:55:3 â€º VAD Audio Patterns â€º should detect VAD events with realistic audio patterns
âœ… VAD events detected for hello__how_are_you_today_: 2

[1A[2Kâœ… Realistic audio patterns verified

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[152/178] [chromium] â€º tests/e2e/vad-audio-patterns.spec.js:90:3 â€º VAD Audio Patterns â€º should detect VAD events with longer audio samples
[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:90:3 â€º VAD Audio Patterns â€º should detect VAD events with longer audio samples
ğŸ§ª Testing VAD with longer audio samples...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:90:3 â€º VAD Audio Patterns â€º should detect VAD events with longer audio samples
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:90:3 â€º VAD Audio Patterns â€º should detect VAD events with longer audio samples
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ Testing with longer audio sample: hello__how_are_you_today_

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:27:3 â€º Core VAD Events â€º should detect basic VAD events (UserStartedSpeaking, UtteranceEnd)
âœ… Basic VAD events detected successfully

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[153/178] [chromium] â€º tests/e2e/vad-events-core.spec.js:61:3 â€º Core VAD Events â€º should detect VAD events from both WebSocket sources (Agent + Transcription)
[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:61:3 â€º Core VAD Events â€º should detect VAD events from both WebSocket sources (Agent + Transcription)
ğŸ§ª Testing VAD events from both WebSocket sources...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâ³ +12020ms: Connection still connected

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Idle timeout reached (10000ms) - firing callback

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/user-stopped-speaking-demonstration.spec.js:174:3 â€º onUserStoppedSpeaking Demonstration â€º should demonstrate onUserStoppedSpeaking with multiple audio samples
ğŸ“Š Final VAD State:

[1A[2K  - Utterance End: Channel: [0,1], Last word end: 3.4399998s

[1A[2K  - User Stopped Speaking: 22:06:54

[1A[2Kâœ… Main validations passed - UtteranceEnd and UserStoppedSpeaking detected

[1A[2KğŸ‰ SUCCESS: Multiple samples demonstration completed via data-testid elements!

[1A[2KğŸ’¡ This demonstrates that:

[1A[2K  1. Speech detection works across multiple audio samples

[1A[2K  2. UtteranceEnd detection works across multiple audio samples

[1A[2K  3. onUserStoppedSpeaking callback works across multiple audio samples

[1A[2K  4. User speaking state updates correctly across multiple audio samples

[1A[2Kâœ… Multiple samples demonstration completed

[1A[2K[154/178] [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
âœ… VAD test environment setup complete

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:61:3 â€º Core VAD Events â€º should detect VAD events from both WebSocket sources (Agent + Transcription)
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ“Š Results for 2000ms: {
  status: [32m'failed'[39m,
  events: [ [32m'UtteranceEnd'[39m ],
  eventsDetected: [33m1[39m,
  onsetEvents: [33mfalse[39m,
  offsetEvents: [33mtrue[39m
}

[1A[2K
ğŸ”§ Testing utterance_end_ms: 3000ms

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:61:3 â€º Core VAD Events â€º should detect VAD events from both WebSocket sources (Agent + Transcription)
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
ğŸ§ª VAD Redundancy Test Suite initialized

[1A[2KğŸ§ª Testing VAD signal redundancy detection with pre-recorded audio...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] 22:07:05 - Agent state changed: idle

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:569:3 â€º Idle Timeout Behavior â€º should start idle timeout after agent finishes speaking - agent state transitions to idle
[IDLE_TIMEOUT] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâœ… Connection closed after 14023ms (expected: ~10000ms)

[1A[2K
ğŸ“Š TIMEOUT RESULT:

[1A[2K  Connection closed: true

[1A[2K  Actual timeout: 14023ms

[1A[2K  Expected timeout: 10000ms

[1A[2K
ğŸ“Š STATE CHANGE LOG:

[1A[2K  Agent state changes: 6

[1A[2K    1. 22:06:50 - Agent state changed: idle

[1A[2K    2. 22:06:52 - Agent state changed: listening

[1A[2K    3. ğŸ¯ [AGENT] Ensuring onAgentStateChange('speaking') is called for playback start

[1A[2K    4. 22:06:52 - Agent state changed: speaking

[1A[2K    5. 22:06:52 - Agent state changed: speaking

[1A[2K    6. 22:06:54 - Agent state changed: idle

[1A[2K  Playback state changes: 3

[1A[2K    1. 22:06:50 - Audio playback: stopped - Agent playback completed

[1A[2K    2. 22:06:52 - Audio playback: started

[1A[2K    3. 22:06:54 - Audio playback: stopped - Agent playback completed

[1A[2K  Idle timeout events: 122

[1A[2K    1. ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K    2. ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K    3. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K    4. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent

[1A[2K    5. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K    6. ğŸ¯ [DEBUG] Started polling for idle timeout conditions

[1A[2K    7. ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=InjectUserMessage, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=false

[1A[2K    8. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K    9. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: InjectUserMessage)

[1A[2K    10. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    11. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STARTED_SPEAKING

[1A[2K    12. ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 13

[1A[2K    13. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K    14. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K    15. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K    16. ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=listening, isPlaying=false, isUserSpeaking=true

[1A[2K    17. ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=listening, isPlaying=false, isUserSpeaking=true

[1A[2K    18. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    19. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    20. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    21. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    22. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    23. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K    24. ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K    25. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K    26. ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K    27. ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=true

[1A[2K    28. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    29. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    30. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    31. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    32. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    33. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K    34. ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K    35. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K    36. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K    37. [WebSocketManager:agent] ğŸ¯ [IDLE_TIMEOUT] Using centralized IdleTimeoutService for agent (triggered by: AgentAudioDone)

[1A[2K    38. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    39. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STOPPED_SPEAKING

[1A[2K    40. ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K    41. ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 20

[1A[2K    42. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K    43. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K    44. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    45. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    46. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    47. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    48. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    49. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    50. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    51. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    52. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    53. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K    54. ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    55. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K    56. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K    57. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K    58. ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K    59. ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    60. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    61. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    62. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    63. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    64. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    65. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    66. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    67. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    68. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    69. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    70. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    71. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    72. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    73. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    74. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    75. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    76. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    77. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    78. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    79. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    80. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    81. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    82. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    83. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    84. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    85. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    86. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    87. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    88. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    89. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    90. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    91. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    92. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    93. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    94. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    95. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    96. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    97. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    98. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    99. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    100. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    101. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    102. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    103. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    104. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    105. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    106. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    107. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    108. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    109. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    110. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    111. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    112. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    113. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Idle timeout reached (10000ms) - firing callback

[1A[2K    114. ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2K    115. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    116. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    117. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    118. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    119. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    120. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    121. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K    122. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K
âœ… Test passed: Idle timeout works correctly after agent finishes speaking!

[1A[2K[155/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
ğŸ§ª Testing Issue #262: IdleTimeoutService should start timeout countdown after agent finishes...

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:90:3 â€º VAD Audio Patterns â€º should detect VAD events with longer audio samples
âœ… VAD events detected with longer audio sample: 2

[1A[2K[156/178] [chromium] â€º tests/e2e/vad-audio-patterns.spec.js:120:3 â€º VAD Audio Patterns â€º should handle multiple audio samples in sequence
[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:120:3 â€º VAD Audio Patterns â€º should handle multiple audio samples in sequence
ğŸ§ª Testing VAD with multiple audio samples in sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] 22:07:07 - Agent state changed: speaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:07:07 - Agent state changed: speaking

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
âœ… Connection established

[1A[2KStep 1: Waiting for agent greeting (if any)...

[1A[2Kâœ… Agent greeting completed

[1A[2KStep 2: Waiting for agent state to be idle...

[1A[2Kâœ… Agent state is idle

[1A[2KStep 3: Verifying playback has finished...

[1A[2Kâœ… Playback finished

[1A[2KStep 4: Waiting for all idle conditions to be met...

[1A[2KğŸ“Š Idle state: {
  agentIdle: [33mtrue[39m,
  userIdle: [33mtrue[39m,
  audioNotPlaying: [33mtrue[39m,
  timeoutActive: [33mfalse[39m
}

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: false, isDisabled: false}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K
Step 5: Waiting for connection to close via idle timeout...

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:61:3 â€º Core VAD Events â€º should detect VAD events from both WebSocket sources (Agent + Transcription)
âœ… VAD events from both sources verified

[1A[2K[157/178] [chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:120:3 â€º VAD Audio Patterns â€º should handle multiple audio samples in sequence
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:120:3 â€º VAD Audio Patterns â€º should handle multiple audio samples in sequence
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KğŸ¤ Sending audio sample 1/2: hello

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
ğŸ§ª Testing VAD event callbacks...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UserStartedSpeaking"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UserStartedSpeaking}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UserStartedSpeaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: UserStartedSpeaking): {type: UserStartedSpeaking}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ¤ [VAD] UserStartedSpeaking message received

[1A[2K[BROWSER] ğŸ¯ [AGENT] UserStartedSpeaking from agent service - already have speech evidence, skipping

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UserStartedSpeaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:07:09 - Agent state changed: listening

[1A[2K[BROWSER] 22:07:09 - ğŸ¤ [AGENT] User stopped speaking at 22:07:09

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:07:09 - Agent state changed: thinking

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] 22:07:09 - Agent state changed: speaking

[1A[2K[BROWSER] 22:07:09 - Agent state changed: speaking

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ“Š Results for 3000ms: {
  status: [32m'failed'[39m,
  events: [ [32m'UtteranceEnd'[39m ],
  eventsDetected: [33m1[39m,
  onsetEvents: [33mfalse[39m,
  offsetEvents: [33mtrue[39m
}

[1A[2K
ğŸ”§ Testing utterance_end_ms: 5000ms

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
â³ +2003ms: Connection still connected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":1.5999999}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] ğŸ” [DEBUG] Processing message type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process

[1A[2K[BROWSER] 22:07:10 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected

[1A[2K[BROWSER] 22:07:10 - ğŸ¤ [AGENT] User stopped speaking at 22:07:10

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
ğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:70:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should detect and handle VAD signal redundancy with pre-recorded audio
ğŸ“Š VAD Event Analysis:

[1A[2K  - UserStartedSpeaking events: 7

[1A[2K  - UtteranceEnd events: 11

[1A[2K  - User stopped speaking events: 2

[1A[2K
â±ï¸ Signal Timing:

[1A[2K1. 0ms - 22:07:09 - ğŸ¤ [AGENT] User stopped speaking at 22:...

[1A[2K2. NaNms - 22:07:10 - ğŸ¤ [AGENT] User stopped speaking at 22:...

[1A[2K3. NaNms - [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onm...

[1A[2K4. NaNms - [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onm...

[1A[2K5. NaNms - [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onm...

[1A[2K6. NaNms - ğŸ” [DEBUG] handleTranscriptionMessage called with:...

[1A[2K7. NaNms - ğŸ“ [TRANSCRIPTION] Message received: {type: Uttera...

[1A[2K8. NaNms - ğŸ” [DEBUG] Processing message type: UtteranceEnd...

[1A[2K9. NaNms - ğŸ” [DEBUG] Checking type guard for data: {type: Ut...

[1A[2K10. NaNms - ğŸ¯ [SPEECH] UtteranceEnd message received - checki...

[1A[2K11. NaNms - 22:07:10 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detecte...

[1A[2K12. NaNms - ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but ski...

[1A[2K13. NaNms - [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onm...

[1A[2Kâœ… Multiple VAD signals detected for single stop event

[1A[2Kâœ… VAD signals are consistent in timing

[1A[2K[158/178] [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:102:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should handle agent state transitions for idle timeout behavior with text input
[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:102:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should handle agent state transitions for idle timeout behavior with text input
âœ… VAD test environment setup complete

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:120:3 â€º VAD Audio Patterns â€º should handle multiple audio samples in sequence
âœ… VAD events detected for sample 1: 1

[1A[2KğŸ¤ Sending audio sample 2/2: hello

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:102:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should handle agent state transitions for idle timeout behavior with text input
ğŸ§ª VAD Redundancy Test Suite initialized

[1A[2KğŸ§ª Testing agent state timeout behavior with text input...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-events-core.spec.js:101:3 â€º Core VAD Events â€º should trigger VAD event callbacks correctly
âœ… VAD event callbacks verified (via UI display)

[1A[2K[159/178] [chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
ğŸ§ª Testing interim and final transcript validation with recorded audio...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-audio-patterns.spec.js:120:3 â€º VAD Audio Patterns â€º should handle multiple audio samples in sequence
âœ… VAD events detected for sample 2: 2

[1A[2Kâœ… Multiple audio samples in sequence verified

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[160/178] [chromium] â€º tests/e2e/vad-websocket-events.spec.js:37:3 â€º WebSocket Connection Validation â€º should establish WebSocket connection to Deepgram Agent API
[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2KğŸ“Š Connection states immediately after microphone activation: {
  "agent": "connected",
  "transcription": "connected",
  "agentConnected": true,
  "transcriptionConnected": true
}

[1A[2Kâ³ Waiting for transcription service to connect (started by microphone button)...

[1A[2KğŸ“Š Connection states after wait: {
  "agent": "connected",
  "transcription": "connected",
  "agentConnected": true,
  "transcriptionConnected": true
}

[1A[2Kâœ… Transcription service is connected

[1A[2KğŸ¤ Loading and streaming pre-recorded audio sample (human speech): shopping-concierge-question...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:37:3 â€º WebSocket Connection Validation â€º should establish WebSocket connection to Deepgram Agent API
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:23:3 â€º VAD Configuration Optimization â€º should test different utterance_end_ms values for offset detection
ğŸ“Š Results for 5000ms: {
  status: [32m'failed'[39m,
  events: [ [32m'UtteranceEnd'[39m ],
  eventsDetected: [33m1[39m,
  onsetEvents: [33mfalse[39m,
  offsetEvents: [33mtrue[39m
}

[1A[2K
ğŸ“ˆ VAD Configuration Analysis:

[1A[2K500ms: failed (1 events)

[1A[2K1000ms: failed (1 events)

[1A[2K2000ms: failed (1 events)

[1A[2K3000ms: failed (1 events)

[1A[2K5000ms: failed (1 events)

[1A[2K
âœ… Successful configurations: 0

[1A[2Kâš ï¸ Partial configurations: 0

[1A[2KâŒ No successful VAD event detection with any configuration

[1A[2K[161/178] [chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
ğŸ§ª Testing different VAD event combinations...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:37:3 â€º WebSocket Connection Validation â€º should establish WebSocket connection to Deepgram Agent API
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:37:3 â€º WebSocket Connection Validation â€º should establish WebSocket connection to Deepgram Agent API
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KWebSocket test: Component connected and ready

[1A[2K[162/178] [chromium] â€º tests/e2e/vad-websocket-events.spec.js:56:3 â€º WebSocket Connection Validation â€º should handle UserStartedSpeaking events (only VAD event currently implemented)
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:56:3 â€º WebSocket Connection Validation â€º should handle UserStartedSpeaking events (only VAD event currently implemented)
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K
ğŸ¤ Testing pattern: Hello Sample

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:56:3 â€º WebSocket Connection Validation â€º should handle UserStartedSpeaking events (only VAD event currently implemented)
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:56:3 â€º WebSocket Connection Validation â€º should handle UserStartedSpeaking events (only VAD event currently implemented)
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:56:3 â€º WebSocket Connection Validation â€º should handle UserStartedSpeaking events (only VAD event currently implemented)
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KWebSocket test: UserStartedSpeaking handling ready (only VAD event currently implemented)

[1A[2K[163/178] [chromium] â€º tests/e2e/vad-websocket-events.spec.js:75:3 â€º WebSocket Connection Validation â€º should validate WebSocket connection states
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:712:3 â€º Idle Timeout Behavior â€º should start idle timeout countdown after agent finishes - reproduces voice-commerce issue
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Idle timeout reached (10000ms) - firing callback

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâœ… Connection closed after 10018ms (expected: ~10000ms)

[1A[2K
ğŸ“Š TIMEOUT RESULT:

[1A[2K  Connection closed: true

[1A[2K  Actual timeout: 10018ms

[1A[2K  Elapsed time: 10018ms

[1A[2K
ğŸ” ANALYZING IDLE_TIMEOUT_SERVICE LOGS:

[1A[2K  Total logs captured: 98

[1A[2K  "Started idle timeout" log: âœ… FOUND

[1A[2K  "Idle timeout reached" log: âœ… FOUND

[1A[2K  updateTimeoutBehavior calls: 11

[1A[2K  handleEvent calls: 10

[1A[2K
ğŸ“‹ ALL IDLE_TIMEOUT_SERVICE LOGS (chronological):

[1A[2K  1. ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K  2. ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K  3. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K  4. ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K  5. ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K  6. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: false, isDisabled: false}

[1A[2K  7. ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K  8. ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K  9. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K  10. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K  11. ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K  12. ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K  13. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K  14. ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K  15. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: speaking, isPlaying: true, isDisabled: true}

[1A[2K  16. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  17. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  18. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  19. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K  20. ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K  21. ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K  22. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K  23. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K  24. ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K  25. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K  26. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  27. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  28. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  29. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  30. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  31. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  32. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  33. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  34. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  35. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  36. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  37. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K  38. ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K  39. ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  40. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K  41. ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K  42. ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K  43. ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K  44. ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K  45. ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K  46. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K  47. ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K  48. ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K  49. ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  50. ğŸ¯ [DEBUG] updateTimeoutBehavior() called with state: {isUserSpeaking: false, agentState: idle, isPlaying: false, isDisabled: false}

[1A[2K  51. ğŸ¯ [DEBUG] updateTimeoutBehavior() - conditions met, starting timeout

[1A[2K  52. ğŸ¯ [DEBUG] startTimeout() called but timeout already running, skipping

[1A[2K  53. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  54. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  55. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  56. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  57. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  58. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  59. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  60. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  61. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  62. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  63. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  64. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  65. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  66. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  67. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  68. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  69. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  70. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  71. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  72. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  73. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  74. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  75. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  76. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  77. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  78. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  79. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  80. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  81. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  82. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  83. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  84. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  85. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  86. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  87. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  88. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  89. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  90. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  91. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  92. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  93. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  94. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  95. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  96. ğŸ¯ [IDLE_TIMEOUT_SERVICE] Idle timeout reached (10000ms) - firing callback

[1A[2K  97. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  98. ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K
âœ… IdleTimeoutService started the timeout correctly

[1A[2K   Log found: "ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)"

[1A[2K
âœ… Test passed: IdleTimeoutService correctly starts timeout countdown!

[1A[2K[164/178] [chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
ğŸ§ª Testing Issue #262/#430: Timeout should restart after USER_STOPPED_SPEAKING when agent is idle...

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:75:3 â€º WebSocket Connection Validation â€º should validate WebSocket connection states
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
ğŸ“Š Hello Sample: âŒ onset, âœ… offset (1 events detected)

[1A[2K
ğŸ¤ Testing pattern: Hello Sample (retry)

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
âœ… Connection established

[1A[2KStep 1: Waiting for agent greeting to finish...

[1A[2Kâœ… Agent greeting completed

[1A[2KStep 2: Waiting for agent to be idle and timeout to start...

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:75:3 â€º WebSocket Connection Validation â€º should validate WebSocket connection states
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: null

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] No timeout to stop (timeoutId is null)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:75:3 â€º WebSocket Connection Validation â€º should validate WebSocket connection states
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2KWebSocket test: WebSocket connection validated

[1A[2K[165/178] [chromium] â€º tests/e2e/vad-websocket-events.spec.js:94:3 â€º WebSocket Connection Validation â€º should handle WebSocket connection errors gracefully
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
âœ… Audio sample streamed: shopping-concierge-question

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâœ… Initial timeout started

[1A[2KStep 3: Sending audio sample to trigger UserStartedSpeaking...

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
ğŸ“Š Transcript count changed: 0 -> 4

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:94:3 â€º WebSocket Connection Validation â€º should handle WebSocket connection errors gracefully
WebSocket test: Error handling validated

[1A[2K[166/178] [chromium] â€º tests/e2e/vad-websocket-events.spec.js:105:3 â€º WebSocket Connection Validation â€º should note that VAD events are not yet implemented
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STARTED_SPEAKING

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 16

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=listening, isPlaying=false, isUserSpeaking=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=listening, isUserSpeaking=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=listening, isPlaying=false, isUserSpeaking=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-websocket-events.spec.js:105:3 â€º WebSocket Connection Validation â€º should note that VAD events are not yet implemented
NOTE: VAD events (UserStoppedSpeaking, UtteranceEnd, VADEvent) are not yet implemented in the component

[1A[2KOnly UserStartedSpeaking is currently handled

[1A[2KSee ISSUE-44-VAD-Events-Proposal.md for implementation plan

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:44:3 â€º VAD Transcript Analysis â€º should validate interim and final transcript receipt with recorded audio
âœ… Transcript count stabilized at 4 after 1500ms

[1A[2K
ğŸ“Š === TRANSCRIPT VALIDATION ===

[1A[2KğŸ“ Total transcripts received: [33m4[39m

[1A[2KğŸ“ Transcript breakdown:

[1A[2K  1. INTERIM | "Hello. Can you help"

[1A[2K  2. INTERIM | "Hello. Can you help me find a gift for"

[1A[2K  3. INTERIM | "Hello. Can you help me find a gift for my friend's birthday?"

[1A[2K  4. FINAL | "Hello. Can you help me find a gift for my friend's birthday?"

[1A[2KğŸ“ Final transcripts: [33m1[39m

[1A[2KğŸ“ Interim transcripts: [33m3[39m

[1A[2Kâœ… Interim transcripts validated: [33m3[39m

[1A[2Kâœ… Interim transcripts arrived before final transcripts (as expected)

[1A[2Kâœ… Final transcripts validated: [33m1[39m

[1A[2Kâœ… All transcripts contain valid text

[1A[2K
ğŸ“Š === VAD EVENT VALIDATION ===

[1A[2KğŸ¯ Total VAD events: [33m2[39m

[1A[2KğŸ¯ VAD events by type: { UserStartedSpeaking: [33m1[39m, UtteranceEnd: [33m1[39m }

[1A[2Kâœ… UserStartedSpeaking detected: [33mtrue[39m

[1A[2Kâœ… UtteranceEnd detected: [33mtrue[39m

[1A[2K
âœ… All transcript validations passed!

[1A[2K[167/178] [chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:134:3 â€º VAD Configuration Optimization â€º should test different VAD event combinations
ğŸ“Š Hello Sample (retry): âœ… onset, âœ… offset (2 events detected)

[1A[2K
ğŸ“ˆ Audio Pattern Analysis:

[1A[2KHello Sample: failed (1 events)

[1A[2KHello Sample (retry): success (2 events)

[1A[2K
âœ… Successful patterns: 1/2

[1A[2KğŸ¯ Working audio patterns found!

[1A[2K[168/178] [chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ§ª Testing transcript patterns with different audio samples...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ§ª Testing VAD event timing and sequencing...

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: âš™ï¸  specify custom .env file path with { path: '/custom/path/.env' }

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:64733) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[169/178] [chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
ğŸ§ª Starting Deepgram Protocol UX Test...

[1A[2K
ğŸ“¡ Step 1: Setup and Activate Connection via Microphone

[1A[2Kâœ… Voice agent component loaded

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâœ… UserStartedSpeaking detected

[1A[2KWaiting for timeout to be stopped by polling...

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
âœ… Timeout stopped when user started speaking

[1A[2KStep 4: Waiting for user to stop speaking...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing
ğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns

ğŸ¤ Testing with: Short Hello (sample_hello.json)

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection ready (Settings â†’ Welcome handshake completed)

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
âœ… WebSocket connection status: connected

[1A[2K
ğŸ’¬ Step 2: Verify Agent Greeting (Protocol Welcome)

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
âœ… Agent greeting received and played

[1A[2Kâœ… Agent greeting displayed: "Hello! How can I assist you today?..."

[1A[2K
ğŸ“¤ Step 3: Send User Text Message via UI

[1A[2Kâœ… Message sent and input cleared: "Hello, this is an E2E protocol test message"

[1A[2K
ğŸ“¥ Step 4: Verify Agent Response

[1A[2Kâœ… Agent responded: "Hello! How can I assist you today?..."

[1A[2K
ğŸ”— Step 5: Verify Connection Stability

[1A[2Kâœ… Connection remained stable throughout interaction

[1A[2K
ğŸ”„ Step 6: Verify User Message Display (Protocol Echo)

[1A[2Kâœ… User message received from server: "Hello, this is an E2E protocol test message..."

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:32:3 â€º Deepgram Protocol UX Validation â€º should complete full protocol flow through UI interactions
âœ… Sent second message: "Second test message"

[1A[2Kâœ… Connection stable after multiple interactions

[1A[2K
ğŸ‰ PROTOCOL UX TEST PASSED!

[1A[2Kâœ… Auto-connect established (Settings â†’ Welcome)

[1A[2Kâœ… Agent greeting received

[1A[2Kâœ… User messages sent via UI

[1A[2Kâœ… Agent responses received

[1A[2Kâœ… Multi-turn conversation working

[1A[2Kâœ… Connection stable throughout

[1A[2K[170/178] [chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
ğŸ¤ Starting Microphone Protocol State Test...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-configuration-optimization.spec.js:225:3 â€º VAD Configuration Optimization â€º should test VAD event timing and sequencing

â±ï¸ VAD Event Timing Analysis:

[1A[2KNo timing data captured

[1A[2K
ğŸ“‹ Event Sequence: No events detected

[1A[2K
ğŸ“Š Event Analysis:

[1A[2KOnset events: 0 ()

[1A[2KOffset events: 0 ()

[1A[2KTotal events detected: 1

[1A[2Kâœ… VAD event timing test completed

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ“Š Short Hello Results:

[1A[2K  VAD Events: 1 (UtteranceEnd)

[1A[2K  Transcripts: 0

[1A[2K
ğŸ¤ Testing with: Medium Hello There (sample_hello_there.json)

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[dotenv@17.2.3] injecting env (0) from ../.env -- tip: âš™ï¸  override existing env vars with { override: true }

[1A[2KPlaywright baseURL: http://localhost:5173

[1A[2KPW_ENABLE_AUDIO: [33mfalse[39m

[1A[2K(node:64966) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.
(Use `node --trace-warnings ...` to show where the warning was created)

[1A[2K[171/178] [chromium] â€º tests/e2e/protocol-validation-modes.spec.js:18:3 â€º Protocol Validation - Mock API Mode â€º should work with mocked WebSocket when no API key provided
[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
ğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/protocol-validation-modes.spec.js:18:3 â€º Protocol Validation - Mock API Mode â€º should work with mocked WebSocket when no API key provided
ğŸš€ Testing with MOCKED WebSocket (no API key)...

[1A[2Kâœ… Error state loaded (expected for missing API key)

[1A[2Kâœ… App correctly shows error state

[1A[2Kâœ… Error message is displayed

[1A[2Kâœ… Mock WebSocket installed to prevent real API calls

[1A[2KğŸ‰ MOCK API MODE TEST PASSED!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[172/178] [chromium] â€º tests/e2e/protocol-validation-modes.spec.js:55:3 â€º Protocol Validation - Mock Mode â€º should work with mocked WebSocket (no API key)
[1A[2K[chromium] â€º tests/e2e/protocol-validation-modes.spec.js:55:3 â€º Protocol Validation - Mock Mode â€º should work with mocked WebSocket (no API key)
ğŸš€ Testing with MOCKED WebSocket...

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Microphone activated successfully

[1A[2Kâœ… Mic status confirmed: Enabled

[1A[2Kâœ… Microphone button is visible and enabled

[1A[2Kâœ… Clicked microphone button to disable

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/protocol-validation-modes.spec.js:55:3 â€º Protocol Validation - Mock Mode â€º should work with mocked WebSocket (no API key)
âœ… Error state loaded (expected for missing API key)

[1A[2Kâœ… App correctly shows error state

[1A[2Kâœ… Error message is displayed

[1A[2Kâœ… Mock WebSocket installed to prevent real API calls

[1A[2KğŸ‰ MOCK MODE TEST PASSED!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:126:3 â€º Deepgram Protocol UX Validation â€º should handle microphone protocol states
âœ… Mic status after disable: Disabled

[1A[2KğŸ‰ MICROPHONE PROTOCOL STATE TEST PASSED!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[173/178] [chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
âš¡ Starting Rapid Interaction Protocol Test...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ“Š Medium Hello There Results:

[1A[2K  VAD Events: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2K  Transcripts: 0

[1A[2K
ğŸ¤ Testing with: Long Pause Response (sample_long_pause_response.json)

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 5: Waiting for agent greeting completion...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
ğŸ¤ [MICROPHONE_HELPER] Greeting status: true

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established

[1A[2KğŸ“¤ Sending multiple rapid messages...

[1A[2Kâœ… Sent: "First rapid message"

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
âœ… Sent: "Second rapid message"

[1A[2Kâœ… Sent: "Third rapid message"

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=speaking, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=true, agentState=speaking, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=speaking, isPlaying=true, isUserSpeaking=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:264:3 â€º VAD Transcript Analysis â€º should analyze different audio samples for transcript patterns
ğŸ“Š Long Pause Response Results:

[1A[2K  VAD Events: 2 (UserStartedSpeaking, UtteranceEnd)

[1A[2K  Transcripts: 0

[1A[2K
âœ… Multiple audio samples analyzed successfully

[1A[2K[174/178] [chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:369:3 â€º VAD Transcript Analysis â€º should test utterance_end_ms configuration impact
[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:369:3 â€º VAD Transcript Analysis â€º should test utterance_end_ms configuration impact
ğŸ§ª Testing utterance_end_ms configuration impact...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: AGENT_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] AGENT_STATE_CHANGED: state=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=true, isUserSpeaking=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 44

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: MEANINGFUL_USER_ACTIVITY

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] MEANINGFUL_USER_ACTIVITY: activity=AgentAudioDone, agentState=idle, isPlaying=false, isUserSpeaking=false, isDisabled=true

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STOPPED_SPEAKING

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: USER_STOPPED_SPEAKING

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=true, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] stopTimeout() called - timeoutId: 47

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Stopped idle timeout

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2KStep 5: Checking if timeout restarted after USER_STOPPED_SPEAKING...

[1A[2Kâœ… Timeout restarted after USER_STOPPED_SPEAKING

[1A[2KStep 6: Waiting for timeout to fire...

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:369:3 â€º VAD Transcript Analysis â€º should test utterance_end_ms configuration impact
ğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/deepgram-ux-protocol.spec.js:169:3 â€º Deepgram Protocol UX Validation â€º should maintain protocol during rapid interactions
âœ… Connection stable after rapid interactions

[1A[2Kâœ… Agent still responding after rapid messages

[1A[2KğŸ‰ RAPID INTERACTION PROTOCOL TEST PASSED!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:369:3 â€º VAD Transcript Analysis â€º should test utterance_end_ms configuration impact
ğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2Kâœ… Connection established and microphone enabled

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] ğŸ¯ [DEBUG] handleEvent called with event type: PLAYBACK_STATE_CHANGED

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] PLAYBACK_STATE_CHANGED: isPlaying=false, agentState=idle, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Started idle timeout (10000ms)

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] updateStateDirectly() called: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:369:3 â€º VAD Transcript Analysis â€º should test utterance_end_ms configuration impact
ğŸ“Š Current utterance_end_ms setting: configured

[1A[2KğŸ¤ Testing with long pause response sample...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâ³ +1004ms: Connection still connected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-transcript-analysis.spec.js:369:3 â€º VAD Transcript Analysis â€º should test utterance_end_ms configuration impact
â³ Waiting for UtteranceEnd with extended timeout...

[1A[2K
ğŸ“Š === UTTERANCE_END_MS ANALYSIS ===

[1A[2KğŸ¯ VAD Events: UserStartedSpeaking, UtteranceEnd

[1A[2KğŸ“ Transcripts received: [33m0[39m

[1A[2KğŸ‰ SUCCESS: UtteranceEnd detected!

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâ³ +6022ms: Connection still connected

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K  5) [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:102:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should handle agent state transitions for idle timeout behavior with text input 

    [31mTest timeout of 30000ms exceeded.[39m

    Error: page.waitForFunction: Test timeout of 30000ms exceeded.

      119 |     
      120 |     // Wait for agent response instead of console logs (more reliable)
    > 121 |     await page.waitForFunction(() => {
          |                ^
      122 |       const agentResponse = document.querySelector('[data-testid="agent-response"]');
      123 |       return agentResponse && agentResponse.textContent && 
      124 |              agentResponse.textContent !== '(Waiting for agent response...)';
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/vad-redundancy-and-agent-timeout.spec.js:121:16

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/vad-redundancy-and-agent-t-72c0e-ut-behavior-with-text-input-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/vad-redundancy-and-agent-t-72c0e-ut-behavior-with-text-input-chromium/error-context.md


[1A[2K[175/178] [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:176:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should prove AgentThinking disables idle timeout resets by injecting message
[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:176:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should prove AgentThinking disables idle timeout resets by injecting message
âœ… VAD test environment setup complete

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:176:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should prove AgentThinking disables idle timeout resets by injecting message
ğŸ§ª VAD Redundancy Test Suite initialized

[1A[2KğŸ§ª Testing AgentThinking functionality by injecting message...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:176:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should prove AgentThinking disables idle timeout resets by injecting message
[BROWSER] âœ… AgentThinking disables idle timeout resets (verified in code)

[1A[2Kâœ… AgentThinking functionality verified:

[1A[2K  - Component has handleAgentMessage function

[1A[2K  - AgentThinking case calls manageIdleTimeoutResets("disable", "AgentThinking")

[1A[2K  - manageIdleTimeoutResets function exists and works

[1A[2K  - Issue #86 implementation is complete

[1A[2KğŸ‰ AgentThinking functionality proven to exist in code!

[1A[2K[176/178] [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:221:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should debug agent response flow and state transitions
[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:221:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should debug agent response flow and state transitions
âœ… VAD test environment setup complete

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:221:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should debug agent response flow and state transitions
ğŸ§ª VAD Redundancy Test Suite initialized

[1A[2KğŸ” Debugging agent response flow and state transitions...

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:221:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should debug agent response flow and state transitions
[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UserStartedSpeaking"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UserStartedSpeaking}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UserStartedSpeaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: UserStartedSpeaking): {type: UserStartedSpeaking}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ¤ [VAD] UserStartedSpeaking message received

[1A[2K[BROWSER] ğŸ¯ [AGENT] UserStartedSpeaking from agent service - setting isUserSpeaking=true

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UserStartedSpeaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:07:44 - Agent state changed: listening

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:221:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should debug agent response flow and state transitions
[BROWSER] 22:07:44 - Agent state changed: speaking

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:221:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should debug agent response flow and state transitions
[BROWSER] 22:07:44 - Agent state changed: speaking

[1A[2KğŸ” All Agent-Related Logs:

[1A[2KğŸ” Agent Response: Sure!

[1A[2KğŸ” Current Agent State: speaking

[1A[2KğŸ” Audio Playing Status: true

[1A[2KğŸ” WebSocket Messages:

[1A[2KğŸ” Agent Configuration: {
  "hasAgentOptions": true,
  "agentOptions": null,
  "agentManagerExists": true
}

[1A[2Kâœ… Agent response debug completed

[1A[2K[177/178] [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:317:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should verify agent state transitions using state inspection
[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:317:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should verify agent state transitions using state inspection
âœ… VAD test environment setup complete

[1A[2K[chromium] â€º tests/e2e/idle-timeout-behavior.spec.js:887:3 â€º Idle Timeout Behavior â€º should restart timeout after USER_STOPPED_SPEAKING when agent is idle - reproduces Issue #262/#430
[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Idle timeout reached (10000ms) - firing callback

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT] Idle timeout reached - closing agent connection

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2K[IDLE_TIMEOUT_SERVICE] ğŸ¯ [IDLE_TIMEOUT_SERVICE] checkAndStartTimeoutIfNeeded() - synced state from component: agentState=idle, isPlaying=false, isUserSpeaking=false

[1A[2Kâœ… Connection closed after 11042ms (expected: ~10000ms)

[1A[2K
âœ… Test passed: Timeout correctly restarts after USER_STOPPED_SPEAKING!

[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:317:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should verify agent state transitions using state inspection
ğŸ§ª VAD Redundancy Test Suite initialized

[1A[2KğŸ§ª Testing agent state transitions with state inspection...

[1A[2K  6) [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:317:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should verify agent state transitions using state inspection 

    [31mTest timeout of 30000ms exceeded.[39m

    Error: page.waitForFunction: Test timeout of 30000ms exceeded.

      332 |     
      333 |     // Wait for agent response first (more reliable than state transitions)
    > 334 |     await page.waitForFunction(() => {
          |                ^
      335 |       const agentResponse = document.querySelector('[data-testid="agent-response"]');
      336 |       return agentResponse && agentResponse.textContent && 
      337 |              agentResponse.textContent !== '(Waiting for agent response...)';
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/vad-redundancy-and-agent-timeout.spec.js:334:16

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/vad-redundancy-and-agent-t-f5c9b-ions-using-state-inspection-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/vad-redundancy-and-agent-t-f5c9b-ions-using-state-inspection-chromium/error-context.md


[1A[2K[178/178] [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:380:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should maintain consistent idle timeout state machine
[1A[2K[chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:380:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should maintain consistent idle timeout state machine
âœ… VAD test environment setup complete

[1A[2KğŸ§ª VAD Redundancy Test Suite initialized

[1A[2KğŸ§ª Testing idle timeout state machine consistency with pre-recorded audio...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Starting microphone activation sequence...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 1: Setting up test page...

[1A[2K[BROWSER] 22:08:15 - Agent state changed: idle

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 2: Waiting for component to be ready...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Component is ready

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 3: Clicking microphone button to trigger lazy initialization...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Microphone button clicked

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 4: Waiting for agent connection...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection status: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 6: Checking microphone status...

[1A[2KğŸ¤ [MICROPHONE_HELPER] Initial mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] Connection after click: connected

[1A[2KğŸ¤ [MICROPHONE_HELPER] Step 7: Waiting for microphone enablement...

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone enabled successfully!

[1A[2KğŸ¤ [MICROPHONE_HELPER] Final mic status: Enabled

[1A[2KğŸ¤ [MICROPHONE_HELPER] âœ… Microphone activation sequence completed successfully!

[1A[2K[BROWSER] 22:08:17 - Agent state changed: speaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:08:17 - Agent state changed: speaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UserStartedSpeaking"}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UserStartedSpeaking}

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UserStartedSpeaking

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ” [DEBUG] Received agent message (type: UserStartedSpeaking): {type: UserStartedSpeaking}

[1A[2K[BROWSER] [DeepgramVoiceInteraction] ğŸ¤ [VAD] UserStartedSpeaking message received

[1A[2K[BROWSER] ğŸ¯ [AGENT] UserStartedSpeaking from agent service - already have speech evidence, skipping

[1A[2K[BROWSER] [WebSocketManager:agent] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UserStartedSpeaking

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:08:19 - Agent state changed: listening

[1A[2K[BROWSER] 22:08:19 - ğŸ¤ [AGENT] User stopped speaking at 22:08:19

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Enabled idle timeout resets - returning to idle

[1A[2K[BROWSER] ğŸ¯ [IDLE_TIMEOUT_SERVICE] Disabled idle timeout resets - activity detected

[1A[2K[BROWSER] 22:08:19 - Agent state changed: thinking

[1A[2K[BROWSER] 22:08:20 - Agent state changed: speaking

[1A[2K[BROWSER] 22:08:20 - Agent state changed: speaking

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Raw string message: {"type":"UtteranceEnd","channel":[0,1],"last_word_end":1.5999999}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Parsed JSON message: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] About to emit message event with type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] handleTranscriptionMessage called with: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] ğŸ“ [TRANSCRIPTION] Message received: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] ğŸ” [DEBUG] Processing message type: UtteranceEnd

[1A[2K[BROWSER] ğŸ” [DEBUG] Checking type guard for data: {type: UtteranceEnd, channel: Array(2), last_word_end: 1.5999999}

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd message received - checking if should process

[1A[2K[BROWSER] 22:08:20 - ğŸ”š [TRANSCRIPTION] UtteranceEnd detected

[1A[2K[BROWSER] 22:08:20 - ğŸ¤ [AGENT] User stopped speaking at 22:08:20

[1A[2K[BROWSER] ğŸ¯ [SPEECH] UtteranceEnd callbacks called, but skipping internal state (speech_final=true already received)

[1A[2K[BROWSER] [WebSocketManager:transcription] ğŸ“¨ [WEBSOCKET.onmessage] Emit completed for message type: UtteranceEnd

[1A[2K
ğŸ“Š Agent State Analysis:

[1A[2K  - Agent state changes: 18

[1A[2K  - Timeout actions: 7

[1A[2K  - Enable actions: 0

[1A[2K  - Disable actions: 0

[1A[2K
ğŸ“Š STATE MACHINE ANALYSIS:

[1A[2KTotal state changes: 18

[1A[2KTotal timeout actions: 7

[1A[2KEnable actions: 0

[1A[2KDisable actions: 0

[1A[2KâŒ State machine missing enable/disable actions

[1A[2K  7) [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:380:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should maintain consistent idle timeout state machine 

    Error: [2mexpect([22m[31mreceived[39m[2m).[22mtoBe[2m([22m[32mexpected[39m[2m) // Object.is equality[22m

    Expected: [32mtrue[39m
    Received: [31mfalse[39m

      405 |     
      406 |     // Assert the validation results in test context (be lenient - at least one type should be present)
    > 407 |     expect(validationResults.hasEnableActions || validationResults.hasDisableActions).toBe(true);
          |                                                                                       ^
      408 |     if (validationResults.hasEnableActions) {
      409 |       console.log('âœ… Enable actions detected');
      410 |     }
        at /Users/davidmcgee/Development/dg_react_agent/test-app/tests/e2e/vad-redundancy-and-agent-timeout.spec.js:407:87

    attachment #1: screenshot (image/png) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    test-results/vad-redundancy-and-agent-t-b3794--idle-timeout-state-machine-chromium/test-failed-1.png
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    Error Context: test-results/vad-redundancy-and-agent-t-b3794--idle-timeout-state-machine-chromium/error-context.md


[1A[2K  7 failed
    [chromium] â€º tests/e2e/function-calling-e2e.spec.js:51:3 â€º Function Calling E2E Tests â€º should trigger client-side function call and execute it 
    [chromium] â€º tests/e2e/function-calling-e2e.spec.js:365:3 â€º Function Calling E2E Tests â€º should verify functions are included in Settings message 
    [chromium] â€º tests/e2e/function-calling-e2e.spec.js:852:3 â€º Function Calling E2E Tests â€º should test minimal function with explicit required array 
    [chromium] â€º tests/e2e/idle-timeout-during-agent-speech.spec.js:35:3 â€º Idle Timeout During Agent Speech â€º should NOT timeout while agent is actively speaking 
    [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:102:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should handle agent state transitions for idle timeout behavior with text input 
    [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:317:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should verify agent state transitions using state inspection 
    [chromium] â€º tests/e2e/vad-redundancy-and-agent-timeout.spec.js:380:3 â€º VAD Redundancy and Agent State Timeout Behavior â€º should maintain consistent idle timeout state machine 
  11 skipped
  160 passed (3.8m)

To open last HTML report run:

  npx playwright show-report

